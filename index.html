#!/usr/bin/env python3
"""
ANUBIS ThreatHunter v6.0 - PharaonX RedTeam by Ramiz Alsafi

v5.10 NEW (2026-02-19):
  NEW1   - Live progress heartbeat: every 10s prints which tasks are still
           running and exactly how many seconds they've been going.
           Example: ‚è≥ Still running [3]: security_news (22s), zdi (18s), attackerkb (11s)
           You always know what's blocking ‚Äî no more staring at a frozen terminal.
  NEW2   - Task wrappers: each of the 57 fetch functions now records its
           start time atomically, so the heartbeat is accurate to the second.
  NEW3   - Completion line now shows task number for failures too:
           ‚úó [N/total] name failed: ... (was missing the counter on errors)

v5.8 BUG FIXES (2026-02-19):
  FIX1   - CIRCL CVE API (fetch_vulners_data) was the silent 55th hung task:
           tried two sequential endpoints √ó timeout=20 = up to 40s blocked thread.
           Fixed: single endpoint, timeout reduced to 10s. Fail fast, log clearly.
  FIX2   - Graceful Ctrl+C: added signal.SIGINT handler + cancel_futures=True on
           ThreadPoolExecutor shutdown. No more KeyboardInterrupt traceback storm.
           Partial results are saved and processed if interrupted mid-run.
  FIX3   - fetch_abuse_sslbl, fetch_certeu_reports were defined but NEVER
           registered in fetch_all_concurrent ‚Äî dead code silently skipped.
           Fixed: both now registered as 'sslbl' and 'certeu' tasks.
  FIX4   - SSLBL_URL, hybridanalysis, CERT_EU_FEED were
           undefined constants ‚Äî would NameError if ever reached.
           Fixed: all four constants defined in SOURCE URLs section.
  FIX5   - r.get('snyk', []) key mismatch in process_threats() call:
           task is registered as 'intel_feed' so 'snyk' was always [].
           Fixed: r.get('intel_feed', [])
  FIX6   - Ubuntu RSS 404: ubuntu.com/security/notices.rss is dead.
           Fixed: multi-URL fallback list with 4 alternative endpoints.
  FIX7   - snort.org in TALOS_URLS: always HTTP 200 but serves HTML login page,
           never a plain IP list. Wasted 20s every run then fell through anyway.
           Fixed: removed from TALOS_URLS; cinsscore is now the reliable primary.
"""

import requests
import pandas as pd
import os
import re
import json
import time
import pytz
import hashlib
import feedparser
import csv
import signal
import base64
from io import StringIO
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache
from collections import defaultdict
from bs4 import BeautifulSoup

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SECURE KEY MANAGEMENT
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Keys are loaded from environment variables (recommended for production).
# As a fallback, you can store base64-encoded values below ‚Äî this prevents
# accidental plaintext leaks in git commits, screenshots, and logs.
# To encode a key:  python3 -c "import base64; print(base64.b64encode(b'YOUR_KEY').decode())"
# To use env vars:  export VULNERS_API_KEY="your_key_here"
# NEVER store raw plaintext API keys here. HTML output never contains keys.

def _dec(encoded: str) -> str:
    """Decode a base64-encoded key. Returns '' for empty/invalid input."""
    if not encoded:
        return ""
    try:
        return base64.b64decode(encoded.encode()).decode()
    except Exception:
        return encoded   # if it wasn't base64, return as-is (legacy support)

def _get_key(env_var: str, b64_fallback: str = "") -> str:
    """
    Load a key securely:
      1. Environment variable (most secure ‚Äî never stored in source)
      2. base64-encoded fallback constant below (obfuscated, not encrypted)
    """
    return os.environ.get(env_var) or _dec(b64_fallback)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Store your base64-encoded keys here (or leave empty and use env vars instead)
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
_CLIQ_WEBHOOK_B64   = ""   # export CLIQ_WEBHOOK_URL="..."
_ZOHO_API_B64       = ""   # export ZOHO_API_KEY="..."
_UNIQUE_NAME_B64    = ""
_VULNERS_B64        = ""   # export VULNERS_API_KEY="..."
_ALIENVAULT_B64     = ""   # export ALIENVAULT_API_KEY="..."
_VIRUSTOTAL_B64     = ""   # export VIRUSTOTAL_API_KEY="..."
_SHODAN_B64         = ""   # export SHODAN_API_KEY="..."
_ABUSEIPDB_B64      = ""   # export ABUSEIPDB_API_KEY="..."
_GREYNOISE_B64      = ""   # export GREYNOISE_API_KEY="..."
_CENSYS_ID_B64      = ""   # export CENSYS_API_ID="..."
_CENSYS_SECRET_B64  = ""   # export CENSYS_API_SECRET="..."
_ABUSE_CH_B64       = ""   # export ABUSE_CH_API_KEY="..."
_VULNCHECK_B64      = ""   # export VULNCHECK_API_KEY="..."
_ATTACKERKB_B64     = ""   # export ATTACKERKB_API_KEY="..."

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# Runtime key resolution ‚Äî use these constants throughout the script
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ============= CONFIGURATION =============
CLIQ_WEBHOOK_URL = _get_key("CLIQ_WEBHOOK_URL",  _CLIQ_WEBHOOK_B64)
ZOHO_API_KEY     = _get_key("ZOHO_API_KEY",       _ZOHO_API_B64)
UNIQUE_NAME      = _get_key("ANUBIS_UNIQUE_NAME", _UNIQUE_NAME_B64)
EXCEL_FILE       = "threat_intelligence_log.xlsx"
LOOKBACK_HOURS   = 168
LAST_RUN_FILE    = "/tmp/threat_intel_last_run.txt"
CAIRO_TZ         = pytz.timezone('Africa/Cairo')

# ============= API KEYS =============
VULNERS_API_KEY    = _get_key("VULNERS_API_KEY",    _VULNERS_B64)
ALIENVAULT_API_KEY = _get_key("ALIENVAULT_API_KEY", _ALIENVAULT_B64)
VIRUSTOTAL_API_KEY = _get_key("VIRUSTOTAL_API_KEY", _VIRUSTOTAL_B64)
SHODAN_API_KEY     = _get_key("SHODAN_API_KEY",     _SHODAN_B64)
ABUSEIPDB_API_KEY  = _get_key("ABUSEIPDB_API_KEY",  _ABUSEIPDB_B64)
GREYNOISE_API_KEY  = _get_key("GREYNOISE_API_KEY",  _GREYNOISE_B64)
CENSYS_API_ID      = _get_key("CENSYS_API_ID",      _CENSYS_ID_B64)
CENSYS_API_SECRET  = _get_key("CENSYS_API_SECRET",  _CENSYS_SECRET_B64)
ABUSE_CH_API_KEY   = _get_key("ABUSE_CH_API_KEY",   _ABUSE_CH_B64)
VULNCHECK_API_KEY  = _get_key("VULNCHECK_API_KEY",  _VULNCHECK_B64)
ATTACKERKB_API_KEY = _get_key("ATTACKERKB_API_KEY", _ATTACKERKB_B64)

# ============= SOURCE URLs =============
NVD_API_URL         = "https://services.nvd.nist.gov/rest/json/cves/2.0"
CISA_KEV_URL        = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
EXPLOIT_DB_RSS      = "https://www.exploit-db.com/rss.xml"
MALWARE_BAZAAR_API  = "https://mb-api.abuse.ch/api/v1/"
THREAT_FOX_API      = "https://threatfox-api.abuse.ch/api/v1/"
GITHUB_ADVISORY_API = "https://api.github.com/advisories"
URLHAUS_CSV_URL     = "https://urlhaus.abuse.ch/downloads/csv_recent/"
URLHAUS_API         = "https://urlhaus-api.abuse.ch/v1/"
OPENPHISH_URL       = "https://openphish.com/feed.txt"  # free, no key, replaces dead PhishTank
CIRCL_CVE_API       = "https://cve.circl.lu/api/last/30"  # Free, no key, CIRCL CVE feed
ALIENVAULT_OTX_API  = "https://otx.alienvault.com/api/v1/pulses/subscribed"
GREYNOISE_COMM_API  = "https://api.greynoise.io/v3/community/"
GREYNOISE_GNQL_API  = "https://api.greynoise.io/v2/experimental/gnql"
OSV_DEV_API         = "https://api.osv.dev/v1/query"
IPSUM_THREAT_URL    = "https://raw.githubusercontent.com/stamparm/ipsum/master/ipsum.txt"
SHODAN_API          = "https://api.shodan.io"
ABUSEIPDB_API       = "https://api.abuseipdb.com/api/v2/blacklist"
HIBP_API            = "https://haveibeenpwned.com/api/v3/breaches"
CISA_ICS_URL        = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"  # ICS CSV moved; using CISA main feed as fallback
EPSS_API            = "https://api.first.org/data/v1/epss"
FEODO_TRACKER       = "https://feodotracker.abuse.ch/downloads/ipblocklist.json"
FIREHOL_L1_URL      = "https://raw.githubusercontent.com/firehol/blocklist-ipsets/master/firehol_level1.netset"
FIREHOL_L2_URL      = "https://raw.githubusercontent.com/firehol/blocklist-ipsets/master/firehol_level2.netset"
UBUNTU_SECURITY     = "https://ubuntu.com/security/notices.rss"   # RSS is faster than JSON API
BLOCKLIST_DE        = "https://lists.blocklist.de/lists/all.txt"
EMERGING_THREATS    = "https://rules.emergingthreats.net/blockrules/compromised-ips.txt"
PACKETSTORM_RSS     = "https://rss.packetstormsecurity.com/"
CENSYS_SEARCH_API   = "https://search.censys.io/api/v2/hosts/search"
REDHAT_CVE_API      = "https://access.redhat.com/hydra/rest/securitydata/cve.json"
VULNCHECK_KEV       = "https://api.vulncheck.com/v3/index/vulncheck-kev"
# NEW v5.0
ZDI_RSS              = "https://www.zerodayinitiative.com/rss/published/"
ATTACKERKB_API_URL   = "https://api.attackerkb.com/v1/topics"
SANS_ISC_RSS         = "https://isc.sans.edu/rssfeed_full.xml"
SECURITYWEEK_RSS     = "https://feeds.feedburner.com/securityweek"
BLEEPINGCOMPUTER_RSS = "https://www.bleepingcomputer.com/feed/"
DARKREADING_RSS      = "https://www.darkreading.com/rss.xml"

# NEW v5.8 ‚Äî sources defined in v5.6/v5.7 but missing URL constants (caused NameError)
SSLBL_URL              = "https://sslbl.abuse.ch/blacklist/sslipblacklist.csv"
HYBRIDANALYSIS_FEED    = "https://www.hybrid-analysis.com/feed?json"   # public, no key
CAPE_SANDBOX_API       = "https://www.capesandbox.com/apiv2/tasks/list/"  # fallback, no key
# v5.10 FIX: ENISA RSS URL 404s ‚Äî replaced with NCSC UK advisories (active, no key needed)
CERT_EU_FEED           = "https://www.ncsc.gov.uk/api/1/services/rss-feed-news"
CERT_EU_FALLBACKS      = [
    "https://www.ncsc.gov.uk/api/1/services/rss-feed-news",          # NCSC UK alerts
    "https://www.cisa.gov/cybersecurity-advisories/all.xml",          # CISA advisories XML
    "https://www.cert.be/sites/default/files/feeds/cert-be-rss.xml", # CERT Belgium
]

# NEW v5.7 ‚Äî additional threat intelligence newsletters / news sources
KREBSONSECURITY_RSS    = "https://krebsonsecurity.com/feed/"       # Works but low volume
THEHACKERNEWS_RSS      = "https://feeds.feedburner.com/TheHackersNews"
SECURITYAFFAIRS_RSS    = "https://securityaffairs.com/feed"
THREATPOST_RSS         = "https://threatpost.com/feed/"             # DEAD as of 2023 ‚Äî kept for compat
CSO_ONLINE_RSS         = "https://www.csoonline.com/feed/"          # v6.0 FIX: /index.rss ‚Üí /feed/
SC_MAGAZINE_RSS        = "https://www.scmagazine.com/feed/"         # v6.0 FIX: updated path
WIRED_SECURITY_RSS     = "https://www.wired.com/feed/category/security/latest/rss"
ARSTECHNICA_SEC_RSS    = "https://feeds.arstechnica.com/arstechnica/security"
CYBERSECURITY_INSIDERS = "https://www.cybersecurity-insiders.com/feed/"
HACKREAD_RSS           = "https://www.hackread.com/feed/"           # v6.0 NEW: replaces dead Threatpost
INFOSECURITY_RSS       = "https://www.infosecurity-magazine.com/rss/news/"  # v6.0 NEW: reliable source

TALOS_URLS = [
    # v5.8 FIX: snort.org removed ‚Äî returns HTTP 200 but serves HTML login page, never IP list.
    #           Wastes 20s every run. cinsscore is the reliable first fallback.
    ("cinsscore",        "https://cinsscore.com/list/ci-badguys.txt", {}),
    ("binarydefense",    "https://www.binarydefense.com/banlist.txt", {}),
    ("ipsum-level3",     "https://raw.githubusercontent.com/stamparm/ipsum/master/levels/3.txt", {}),
    ("greensnow",        "https://blocklist.greensnow.co/greensnow.txt", {}),
    ("firehol-level1",   "https://iplists.firehol.org/files/firehol_level1.netset", {}),
]

TOR_EXIT_URLS = [
    "https://raw.githubusercontent.com/SecOps-Institute/Tor-IP-Addresses/master/tor-exit-nodes.lst",
    "https://check.torproject.org/torbulkexitlist",
    "https://www.dan.me.uk/torlist/",
    "https://iplists.firehol.org/files/tor_exits.netset",
    "https://raw.githubusercontent.com/stamparm/ipsum/master/levels/3.txt",
    "https://raw.githubusercontent.com/firehol/blocklist-ipsets/master/tor_exits.ipset",
]

MITRE_TAXII_STIX  = "https://cti-taxii.mitre.org/stix/collections/95ecc380-afe9-11e4-9b6c-751b66dd541e/objects/"

CISA_RANSOMWARE_URLS = [
    ("advisory-xml",   "https://www.cisa.gov/cybersecurity-advisories/all.xml", "xml"),
    ("json-v1",        "https://www.cisa.gov/sites/default/files/feeds/stopransomware.json", "json"),
    ("json-v2",        "https://www.cisa.gov/sites/default/files/feeds/stopransomware_v1.json", "json"),
    ("alerts-rss",     "https://us-cert.cisa.gov/ncas/alerts.xml", "xml"),
]

FORTINET_PSIRT_RSS   = "https://fortiguard.fortinet.com/rss/ir.xml"
PALO_ALTO_ADVISORY   = "https://security.paloaltonetworks.com/json?severity=CRITICAL&severity=HIGH&sort=-updated"
CISCO_PSIRT_RSS      = "https://sec.cloudapps.cisco.com/security/center/psirtrss20/CiscoSecurityAdvisory.xml"
JUNIPER_ADVISORY_RSS = "https://kb.juniper.net/InfoCenter/index?page=content&channel=SECURITY_ADVISORIES&rss=true"
F5_ADVISORY_RSS      = "https://my.f5.com/manage/s/article/K4602"
CITRIX_ADVISORY_RSS  = "https://support.citrix.com/rss/supportalerts.xml"
SONICWALL_ADVISORY   = "https://psirt.global.sonicwall.com/vuln-list"
CHECKPOINT_ADVISORY  = "https://advisories.checkpoint.com/advisories/feed/"
WATCHGUARD_ADVISORY  = "https://www.watchguard.com/wgrd-psirt/advisories.xml"
SOPHOS_ADVISORY_RSS  = "https://www.sophos.com/en-us/security-advisories.xml"

# ============= CWE ‚Üí MITRE ATT&CK MAPPING =============
CWE_TO_ATTACK = {
    'CWE-78':  [('T1059','Command and Scripting Interpreter')],
    'CWE-79':  [('T1189','Drive-by Compromise')],
    'CWE-89':  [('T1190','Exploit Public-Facing Application')],
    'CWE-94':  [('T1059','Command and Scripting Interpreter')],
    'CWE-119': [('T1203','Exploitation for Client Execution')],
    'CWE-120': [('T1203','Exploitation for Client Execution')],
    'CWE-121': [('T1190','Exploit Public-Facing Application')],
    'CWE-125': [('T1203','Exploitation for Client Execution')],
    'CWE-190': [('T1190','Exploit Public-Facing Application')],
    'CWE-200': [('T1213','Data from Information Repositories')],
    'CWE-276': [('T1222','File and Directory Permissions Modification')],
    'CWE-287': [('T1078','Valid Accounts'),('T1110','Brute Force')],
    'CWE-306': [('T1078','Valid Accounts')],
    'CWE-311': [('T1552','Unsecured Credentials')],
    'CWE-326': [('T1600','Weaken Encryption')],
    'CWE-330': [('T1600','Weaken Encryption')],
    'CWE-352': [('T1185','Browser Session Hijacking')],
    'CWE-362': [('T1068','Exploitation for Privilege Escalation')],
    'CWE-416': [('T1203','Exploitation for Client Execution')],
    'CWE-434': [('T1190','Exploit Public-Facing Application')],
    'CWE-476': [('T1499','Endpoint Denial of Service')],
    'CWE-502': [('T1059','Command and Scripting Interpreter')],
    'CWE-611': [('T1059.003','Windows Command Shell')],
    'CWE-787': [('T1203','Exploitation for Client Execution')],
    'CWE-798': [('T1552','Unsecured Credentials')],
    'CWE-824': [('T1203','Exploitation for Client Execution')],
    'CWE-22':  [('T1083','File and Directory Discovery')],
    'CWE-77':  [('T1059','Command and Scripting Interpreter')],
    'CWE-918': [('T1090','Proxy')],
    'CWE-601': [('T1189','Drive-by Compromise')],
    'CWE-384': [('T1185','Browser Session Hijacking')],
}

KEYWORD_TO_ATTACK = {
    'remote code execution':  [('T1190','Exploit Public-Facing Application'),('T1210','Exploitation of Remote Services')],
    'rce':                    [('T1190','Exploit Public-Facing Application')],
    'privilege escalation':   [('T1068','Exploitation for Privilege Escalation')],
    'sql injection':          [('T1190','Exploit Public-Facing Application')],
    'cross-site scripting':   [('T1189','Drive-by Compromise')],
    'xss':                    [('T1189','Drive-by Compromise')],
    'buffer overflow':        [('T1203','Exploitation for Client Execution')],
    'heap overflow':          [('T1203','Exploitation for Client Execution')],
    'use after free':         [('T1203','Exploitation for Client Execution')],
    'directory traversal':    [('T1083','File and Directory Discovery')],
    'path traversal':         [('T1083','File and Directory Discovery')],
    'authentication bypass':  [('T1078','Valid Accounts')],
    'credential':             [('T1552','Unsecured Credentials')],
    'hardcoded':              [('T1552','Unsecured Credentials')],
    'brute force':            [('T1110','Brute Force')],
    'denial of service':      [('T1499','Endpoint Denial of Service')],
    'command injection':      [('T1059','Command and Scripting Interpreter')],
    'deserialization':        [('T1059','Command and Scripting Interpreter')],
    'xxe':                    [('T1059.003','Windows Command Shell')],
    'ssrf':                   [('T1090','Proxy')],
    'open redirect':          [('T1189','Drive-by Compromise')],
    'ldap injection':         [('T1078','Valid Accounts')],
    'phishing':               [('T1566','Phishing')],
    'ransomware':             [('T1486','Data Encrypted for Impact')],
    'cryptominer':            [('T1496','Resource Hijacking')],
    'backdoor':               [('T1543','Create or Modify System Process')],
    'rootkit':                [('T1014','Rootkit')],
    'lateral movement':       [('T1021','Remote Services')],
    'data exfiltration':      [('T1041','Exfiltration Over C2 Channel')],
    'zero-day':               [('T1190','Exploit Public-Facing Application')],
    'zero day':               [('T1190','Exploit Public-Facing Application')],
    'arbitrary code':         [('T1203','Exploitation for Client Execution')],
    'memory corruption':      [('T1203','Exploitation for Client Execution')],
    'integer overflow':       [('T1203','Exploitation for Client Execution')],
    'out-of-bounds':          [('T1203','Exploitation for Client Execution')],
    'vpn':                    [('T1133','External Remote Services')],
    'firewall':               [('T1562','Impair Defenses')],
    'man-in-the-middle':      [('T1557','Adversary-in-the-Middle')],
    'mitm':                   [('T1557','Adversary-in-the-Middle')],
    'cryptographic':          [('T1600','Weaken Encryption')],
    'information disclosure': [('T1213','Data from Information Repositories')],
}

# ============= LAST RUN TRACKING =============
def should_run_now():
    if not os.path.exists(LAST_RUN_FILE):
        print("‚ö†Ô∏è  First run detected - executing now")
        return True
    try:
        with open(LAST_RUN_FILE,'r') as f:
            raw = f.read().strip()
        last_run = datetime.fromisoformat(raw)
        # BUG FIX: naive/aware comparison TypeError on Python <3.11 ‚Äî localize if needed
        if last_run.tzinfo is None:
            last_run = CAIRO_TZ.localize(last_run)
        now = datetime.now(CAIRO_TZ)
        hours_since = (now - last_run).total_seconds() / 3600
        print(f"‚è∞ Last run was {hours_since:.1f} hours ago")
        if hours_since >= 1:
            return True
        print("‚úì Recent run found, skipping (runs every 1h)")
        return False
    except Exception as e:
        print(f"‚ö†Ô∏è  Error reading last run: {e}")
        return True

def update_last_run():
    try:
        with open(LAST_RUN_FILE,'w') as f:
            f.write(datetime.now(CAIRO_TZ).isoformat())
        print("‚úì Last run time updated")
    except Exception as e:
        print(f"‚ö†Ô∏è  Could not update last run: {e}")

# ============= CLIQ FUNCTIONS =============
def send_text_to_cliq(text):
    if not CLIQ_WEBHOOK_URL:
        return
    try:
        r = requests.post(CLIQ_WEBHOOK_URL, json={"text": text}, timeout=30)
        if r.status_code in [200,204]:
            print("‚úì Alert sent")
        else:
            print(f"‚ö†Ô∏è  Cliq webhook returned {r.status_code}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Cliq webhook error: {e}")

def upload_file_to_cliq(file_path, mime_type=None):
    """v5.10: Now accepts any file type ‚Äî mime_type auto-detected from extension if not given."""
    if not ZOHO_API_KEY or not UNIQUE_NAME:
        return
    if not os.path.exists(file_path):
        print(f"‚úó Upload skipped ‚Äî file not found: {file_path}")
        return
    # Auto-detect MIME type
    if mime_type is None:
        ext = os.path.splitext(file_path)[1].lower()
        mime_type = {
            '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            '.html': 'text/html',
            '.htm':  'text/html',
            '.pdf':  'application/pdf',
            '.txt':  'text/plain',
        }.get(ext, 'application/octet-stream')
    url = f"https://cliq.zoho.com/api/v2/channelsbyname/{UNIQUE_NAME}/files?zapikey={ZOHO_API_KEY}"
    try:
        with open(file_path,'rb') as f:
            files = {'file':(os.path.basename(file_path), f, mime_type)}
            resp  = requests.post(url, files=files, timeout=60)
        if resp.status_code in [200,204]:
            print(f"‚úì Uploaded: {os.path.basename(file_path)}")
        else:
            print(f"‚úó Upload failed ({os.path.basename(file_path)}): {resp.status_code} - {resp.text[:200]}")
    except Exception as e:
        print(f"‚úó Upload error ({os.path.basename(file_path)}): {e}")

# ============= SCORING FUNCTIONS =============
def calculate_cvss_score(cve_data):
    metrics = cve_data.get('metrics',{})
    for ver in ['cvssMetricV31','cvssMetricV30','cvssMetricV2']:
        if ver in metrics and metrics[ver]:
            d  = metrics[ver][0].get('cvssData',metrics[ver][0])
            sc = float(d.get('baseScore',0))
            sv = d.get('baseSeverity',d.get('severity','MEDIUM')).upper()
            return sc,sv
    desc = str(cve_data.get('descriptions',[{}])[0].get('value','')).lower()
    if any(w in desc for w in ['remote code execution','rce','unauthenticated']):
        return 8.5,'HIGH'
    return 5.0,'MEDIUM'

def calculate_likelihood(threat_type, has_exploit=False, in_cisa_kev=False,
                         malware_active=False, epss_score=0.0, atkb_score=0.0):
    if in_cisa_kev or malware_active:
        return 3
    if epss_score >= 0.5 or atkb_score >= 4:
        return 3
    if epss_score >= 0.1 or atkb_score >= 2:
        return 2
    if has_exploit or threat_type in ['exploit','malware','urlhaus']:
        return 3
    if threat_type == 'cve':
        return 2
    return 1

def calculate_impact(cvss_score, threat_type):
    try:
        cvss = float(cvss_score)
    except:
        cvss = 5.0
    if cvss >= 9.0:
        impact = 3
    elif cvss >= 7.0:
        impact = 3
    elif cvss >= 4.0:
        impact = 2
    else:
        impact = 1
    if threat_type in ['malware','exploit','urlhaus']:
        impact = max(impact,2)
    return min(impact,3)

def calculate_risk_level(likelihood, impact):
    matrix = {
        (3,3):'CRITICAL',(3,2):'HIGH',(3,1):'MEDIUM',
        (2,3):'HIGH',(2,2):'MEDIUM',(2,1):'LOW',
        (1,3):'MEDIUM',(1,2):'LOW',(1,1):'LOW'
    }
    return matrix.get((likelihood,impact),'MEDIUM')

def calculate_final_score(cvss_score, likelihood, impact):
    try:
        cvss = float(cvss_score)
    except:
        cvss = 5.0
    return round(cvss + (likelihood * impact), 1)

def get_severity_emoji(severity):
    return {'CRITICAL':'üî¥','HIGH':'üü†','MEDIUM':'üü°','LOW':'üü¢'}.get(severity,'üü°')

# ============= MITRE TECHNIQUE MAPPING =============
def map_cve_to_mitre(cve_id, description, weaknesses):
    techniques = []
    seen = set()
    for weakness in weaknesses:
        cwe_id = ''
        if isinstance(weakness.get('description'),list) and weakness['description']:
            cwe_id = weakness['description'][0].get('value','')
        if cwe_id and cwe_id in CWE_TO_ATTACK:
            for tech_id,tech_name in CWE_TO_ATTACK[cwe_id]:
                if tech_id not in seen:
                    techniques.append(f"{tech_id}:{tech_name}")
                    seen.add(tech_id)
    desc_lower = description.lower()
    for keyword,mappings in KEYWORD_TO_ATTACK.items():
        if keyword in desc_lower:
            for tech_id,tech_name in mappings:
                if tech_id not in seen:
                    techniques.append(f"{tech_id}:{tech_name}")
                    seen.add(tech_id)
    return ' | '.join(techniques[:3]) if techniques else 'T1190:Exploit Public-Facing Application'

# ============= REMEDIATION FUNCTIONS =============
def extract_patch_info(cve_data):
    patches, workarounds, affected = [],[],[]
    for ref in cve_data.get('references',[]):
        url  = ref.get('url','')
        tags = ref.get('tags',[])
        if any(t in ['Patch','Vendor Advisory','Mitigation'] for t in tags):
            patches.append(url)
        if any(t in ['Workaround','Mitigation'] for t in tags):
            workarounds.append(url)
    try:
        for config in cve_data.get('configurations',[]):
            for node in config.get('nodes',[]):
                for cpe in node.get('cpeMatch',[])[:3]:
                    parts = cpe.get('criteria','').split(':')
                    if len(parts) >= 5:
                        affected.append(f"{parts[3]} {parts[4]} {parts[5] if len(parts)>5 else 'various'}")
    except:
        pass
    return {'patch_links':patches[:3],'workarounds':workarounds[:2],'affected_products':list(set(affected))[:3]}

def generate_remediation_recommendation(threat_data):
    t   = threat_data.get('Type','')
    sev = threat_data.get('Risk_Level','MEDIUM')
    rec = []
    if t in ['CVE','REDHAT_CVE','WINDOWS_CVE','MSRC_UPDATE']:
        if sev in ['CRITICAL','HIGH']:
            rec = ["üö® URGENT: Apply vendor patches immediately",
                   "üîí Isolate affected systems if patch unavailable",
                   "üõ°Ô∏è Enable additional monitoring/IDS rules"]
        else:
            rec = ["üìÖ Schedule patch deployment within 30 days","üîç Monitor for exploitation attempts"]
    elif t == 'ZDI_ADVISORY':
        rec = ["üéØ ZDI-published 0-day: apply vendor patch immediately",
               "‚ö†Ô∏è Check ZDI advisory page for workarounds",
               "üîç Hunt for exploitation attempts in logs"]
    elif t == 'EXPLOIT':
        rec = ["‚ö†Ô∏è Active exploit detected - prioritize patching",
               "üö´ Block exploit signatures at perimeter","üîé Scan environment for IOCs"]
    elif t == 'MALWARE':
        rec = ["ü¶† Update AV/EDR signatures immediately",
               "üîç Hunt for IOCs in environment","üö´ Block C2 domains/IPs at firewall"]
    elif t in ['MAL_URL','PHISH']:
        rec = ["üö´ Block URLs in web proxy/firewall",
               "üìß Update email security filters","üë• User awareness training recommended"]
    elif t in ['ABUSE_IP','TALOS_IP','EMERGING_THREAT_IP','FEODO_C2','BLOCKLIST_DE','FIREWALL_ADVISORY']:
        rec = ["üö´ Block IP at firewall immediately",
               "üîç Check logs for existing connections","üõ°Ô∏è Add to threat intelligence blocklist"]
    elif t == 'THREATFOX_IOC':
        rec = ["üö´ Block IOC at network perimeter","üîé Hunt for IOC across environment",
               "üìã Document and share with threat intel team"]
    elif t == 'SANS_ISC':
        rec = ["üì° SANS ISC flagged this threat - high analyst confidence",
               "üîç Review SANS diary entry for IOCs","üõ°Ô∏è Apply recommended mitigations from diary"]
    elif t == 'NEWS_ALERT':
        rec = ["üì∞ Security news alert - monitor for developments",
               "üîç Review article for IOCs","üìã Escalate if relevant to your infrastructure"]
    return " | ".join(rec) if rec else "üîç Investigate and apply appropriate controls"

def calculate_remediation_priority(threat_data):
    risk    = threat_data.get('Risk_Level','MEDIUM')
    kev     = threat_data.get('CISA_KEV','NO')
    has_exp = threat_data.get('Type') in ['EXPLOIT','MALWARE','FEODO_C2','FIREWALL_ADVISORY','ZDI_ADVISORY']
    epss_pct= float(threat_data.get('EPSS_Percentile',0) or 0)
    src_cnt = int(threat_data.get('Source_Count',1) or 1)
    zdi_adv = threat_data.get('ZDI_Advisory','N/A')
    atkb    = float(threat_data.get('AttackerKB_Score',0) or 0)
    if kev == 'YES' or (risk == 'CRITICAL' and has_exp) or epss_pct >= 0.95 or zdi_adv not in ['N/A','NONE','','None']:
        return 'P1'
    elif risk == 'CRITICAL' or (risk == 'HIGH' and has_exp) or epss_pct >= 0.75 or src_cnt >= 3 or atkb >= 3:
        return 'P2'
    elif risk == 'HIGH' or src_cnt == 2 or atkb >= 2:
        return 'P3'
    return 'P4'

# ============= HTML STRIP UTILITY =============
_HTML_TAG_RE = re.compile(r'<[^>]+>')
_HTML_ENTITY_MAP = {'&amp;':'&','&lt;':'<','&gt;':'>','&quot;':'"','&#39;':"'",'&nbsp;':' ','&apos;':"'"}

def strip_html(text):
    if not text:
        return text
    text = _HTML_TAG_RE.sub(' ',str(text))
    for entity,char in _HTML_ENTITY_MAP.items():
        text = text.replace(entity,char)
    return ' '.join(text.split()).strip()

# ============= CONFIDENCE SCORING =============
_AUTHORITATIVE_TYPES = {'FEODO_C2','VULNCHECK_KEV','CISA_RANSOMWARE','CISA_ICS','ZDI_ADVISORY'}
_AUTHORITATIVE_SOURCES = {'CISA_KEV','FEODO','TALOS','GREYNOISE','CISA_RANSOMWARE',
                          'VULNCHECK_KEV','CISA_ICS','ZDI','ATTACKERKB'}

def calculate_confidence(source_count, authoritative_sources=None, threat_type=None):
    auth = list(authoritative_sources) if authoritative_sources else []
    base_pct   = 40
    multi_bonus= max(0, source_count-1) * 12
    auth_bonus = sum(20 for s in auth if s in _AUTHORITATIVE_SOURCES)
    type_bonus = 10 if (threat_type or '') in _AUTHORITATIVE_TYPES else 0
    final_pct  = min(base_pct+multi_bonus+auth_bonus+type_bonus, 100)
    if final_pct >= 80:
        return 'CONFIRMED', int(final_pct)
    elif final_pct >= 65:
        return 'HIGH', int(final_pct)
    elif final_pct >= 50:
        return 'MEDIUM', int(final_pct)
    return 'LOW', int(final_pct)

# ============= GREYNOISE FUNCTIONS =============
@lru_cache(maxsize=2000)
def fetch_greynoise_context(ip_address):
    """v5.10 FIX: bare except was silently swallowing every GreyNoise error ‚Üí 0 enriched.
    Now tries both Community API header formats and logs the actual failure reason.
    GreyNoise Community API: GET /v3/community/{ip} with header 'key: YOUR_KEY'
    """
    if not GREYNOISE_API_KEY:
        return None
    # Try both header formats ‚Äî some accounts need Authorization: Bearer
    for headers in [
        {'key': GREYNOISE_API_KEY, 'Accept': 'application/json'},
        {'Authorization': f'Bearer {GREYNOISE_API_KEY}', 'Accept': 'application/json'},
    ]:
        try:
            r = requests.get(f"{GREYNOISE_COMM_API}{ip_address}",
                             headers=headers, timeout=10)
            if r.status_code == 200:
                d = r.json()
                return {'noise':d.get('noise',False),'riot':d.get('riot',False),
                        'classification':d.get('classification','unknown'),
                        'name':d.get('name','Unknown'),'last_seen':d.get('last_seen','N/A')}
            elif r.status_code == 404:
                # IP not in GreyNoise ‚Äî valid response, not an error
                return {'noise':False,'riot':False,'classification':'not_found',
                        'name':'Not in GreyNoise','last_seen':'N/A'}
            elif r.status_code in (401, 403):
                # Auth failed ‚Äî log once, don't retry other header format
                print(f"  ‚ö†Ô∏è  GreyNoise auth failed ({r.status_code}) for {ip_address[:15]} ‚Äî check API key at greynoise.io")
                return None
            elif r.status_code == 429:
                print(f"  ‚ö†Ô∏è  GreyNoise rate limit hit ‚Äî pausing 5s")
                time.sleep(5)
                return None
            # Other status: try next header format
        except requests.exceptions.Timeout:
            return None
        except Exception as e:
            print(f"  ‚ö†Ô∏è  GreyNoise error for {ip_address[:15]}: {str(e)[:60]}")
            return None
    return None

def enrich_iocs_with_greynoise(ioc_list):
    print("\nü¶Ö Enriching IOCs with GreyNoise (concurrent mode)...")
    if not GREYNOISE_API_KEY or not ioc_list:
        for ioc in ioc_list:
            ioc.setdefault('greynoise_classification','Not checked')
            ioc.setdefault('greynoise_context','No GreyNoise key configured')
        return ioc_list
    def enrich_one(ioc):
        if ioc.get('ioc_type') in ['ip:port','ip']:
            ip = ioc.get('ioc_value','').split(':')[0]
            gn = fetch_greynoise_context(ip)
            if gn:
                ioc['greynoise_noise']          = gn.get('noise',False)
                ioc['greynoise_riot']           = gn.get('riot',False)
                ioc['greynoise_classification'] = gn.get('classification','unknown')
                ioc['greynoise_name']           = gn.get('name','Unknown')
                ioc['greynoise_last_seen']      = gn.get('last_seen','Unknown')
            else:
                ioc['greynoise_noise']          = False
                ioc['greynoise_riot']           = False
                ioc['greynoise_classification'] = 'No data'
                ioc['greynoise_name']           = 'Not indexed'
                ioc['greynoise_last_seen']      = 'Unknown'
        else:
            ioc['greynoise_classification'] = 'Non-IP IOC'
            ioc['greynoise_context']        = 'GreyNoise only covers IPs'
        return ioc
    enriched = []
    with ThreadPoolExecutor(max_workers=10) as ex:
        futs = [ex.submit(enrich_one,ioc) for ioc in ioc_list[:30]]
        for f in as_completed(futs):
            try:
                enriched.append(f.result())
            except:
                pass
    for ioc in ioc_list[30:]:
        ioc['greynoise_classification'] = 'Rate limit - not checked'
        ioc['greynoise_context']        = 'Rate limit reached (30/run max)'
        enriched.append(ioc)
    print(f"‚úì Enriched {min(30,len(ioc_list))} IOCs")
    return enriched

def enrich_all_ips_with_greynoise(ip_list, source_type='unknown'):
    print(f"\nü¶Ö Enriching {len(ip_list)} {source_type} IPs with GreyNoise...")
    enriched = []
    if not GREYNOISE_API_KEY:
        return [{'ip':ip,'greynoise_classification':'No API key',
                 'greynoise_context':'Sign up free at greynoise.io','risk_adjustment':0}
                for ip in ip_list]
    checked = 0
    consecutive_rl = 0  # BUG FIX: stop after 3 rate-limit hits instead of spamming 15 requests
    for ip in ip_list[:15]:
        if consecutive_rl >= 3:
            print(f"  ‚ö†Ô∏è  GreyNoise: 3 consecutive rate-limits ‚Äî stopping early")
            for rem_ip in ip_list[ip_list.index(ip):15]:
                enriched.append({'ip':rem_ip,'greynoise_classification':'Rate limited',
                                 'greynoise_context':'Stopped after 3 rate-limits',
                                 'greynoise_name':'N/A','risk_adjustment':0})
            break
        gn = fetch_greynoise_context(ip)
        if gn is None:
            # None = rate limit or auth error ‚Äî count it toward the consecutive limit
            consecutive_rl += 1
            enriched.append({'ip':ip,'greynoise_classification':'Rate limited',
                             'greynoise_context':'GreyNoise rate limit or auth error',
                             'greynoise_name':'N/A','risk_adjustment':0})
            continue
        if gn:
            cl   = gn.get('classification','unknown')
            if cl is None:
                enriched.append({'ip':ip,'greynoise_classification':'No data',
                                 'greynoise_context':'No data','greynoise_name':'N/A','risk_adjustment':0})
                continue
            consecutive_rl = 0
            name = gn.get('name','Unknown')
            riot = gn.get('riot',False)
            noise= gn.get('noise',False)
            if riot:
                context,risk_adj = f"‚úÖ BENIGN: {name} (Trusted Service)",-2
            elif noise and cl == 'malicious':
                context,risk_adj = f"üö® MALICIOUS: {name} (Active Scanner)",+2
            elif noise:
                context,risk_adj = f"‚ö†Ô∏è SCANNER: {name} ({cl})",+1
            else:
                context,risk_adj = f"‚ÑπÔ∏è {name} ({cl})",0
            enriched.append({'ip':ip,'greynoise_classification':cl,
                             'greynoise_context':context,'greynoise_name':name,'risk_adjustment':risk_adj})
            checked += 1
            time.sleep(0.3)
        else:
            enriched.append({'ip':ip,'greynoise_classification':'Not indexed',
                             'greynoise_context':'Not in GreyNoise database',
                             'greynoise_name':'Unknown','risk_adjustment':0})
    for ip in ip_list[15:]:
        enriched.append({'ip':ip,'greynoise_classification':'Rate limit - not checked',
                        'greynoise_context':'Skipped (15/run limit)',
                        'greynoise_name':'N/A','risk_adjustment':0})
    print(f"  ‚úì Enriched {checked}/{len(ip_list)} IPs with GreyNoise")
    return enriched

def fetch_greynoise_mass_scan():
    print("\nü¶Ö Fetching GreyNoise Mass Scan Activity...")
    if not GREYNOISE_API_KEY:
        print("‚ö†Ô∏è  GreyNoise API key not set")
        return []
    threats = []
    try:
        headers = {'key':GREYNOISE_API_KEY,'Accept':'application/json'}
        params  = {'query':'classification:malicious last_seen:1d','size':50}
        r = requests.get(GREYNOISE_GNQL_API, headers=headers, params=params, timeout=30)
        if r.status_code == 200:
            for res in r.json().get('data',[]):
                threats.append({'ip':res.get('ip',''),'classification':res.get('classification',''),
                                'actor':res.get('actor','Unknown'),'tags':', '.join(res.get('tags',[])),
                                'first_seen':res.get('first_seen',''),'last_seen':res.get('last_seen',''),
                                'country':res.get('metadata',{}).get('country','')})
            print(f"‚úì Found {len(threats)} GreyNoise active threat IPs")
        else:
            print(f"‚úó GreyNoise API error: {r.status_code}")
    except Exception as e:
        print(f"‚úó GreyNoise scan fetch failed: {e}")
    return threats

def fetch_greynoise_riot():
    print("\nüõ°Ô∏è GreyNoise RIOT: Per-IP enrichment only (bulk endpoint deprecated)")
    return []

# ============= EPSS FUNCTIONS ‚Äî FIXED v5.0 =============
def fetch_epss_batch(cve_ids, kev_set=None):
    """
    v5.1 FIXED (BUG2+BUG6):
    - CVE-2026-xxxx are too fresh for EPSS (lag ~7-14 days from NVD publish to EPSS score)
    - Old code only sent first 100 CVEs ‚Äî most never queried
    - FIX: Priority order: KEV CVEs first (always in EPSS) ‚Üí then remaining, multi-batch chunks of 100
    - KEV CVEs are confirmed-exploited and always have EPSS scores ‚Äî guarantees real data
    """
    scores = {}
    if not cve_ids:
        return scores

    kev_set = kev_set or set()
    all_ids = list(cve_ids)

    # Priority: KEV CVEs first (100% in EPSS), then the rest
    kev_first  = [c for c in all_ids if c in kev_set]
    rest       = [c for c in all_ids if c not in kev_set]
    ordered    = kev_first + rest
    # Filter: EPSS only handles CVE-YYYY-NNNNN format ‚Äî strip any hash IDs etc.
    ordered    = [c for c in ordered if re.match(r'^CVE-\d{4}-\d+$', str(c))]
    to_query   = ordered[:500]   # cap at 500 total

    print(f"  üîÆ EPSS: querying {len(to_query)} CVEs ({len(kev_first)} KEV-priority, {len(rest[:500-len(kev_first)])} others) in batches of 100")

    for batch_start in range(0, len(to_query), 100):
        batch  = to_query[batch_start:batch_start+100]
        try:
            params = [('cve', cid) for cid in batch]
            params.append(('limit','100'))
            r = requests.get(EPSS_API, params=params, timeout=30)
            batch_num = batch_start//100 + 1
            print(f"  üîÆ EPSS batch {batch_num}: HTTP {r.status_code} | {len(batch)} CVEs")
            if r.status_code == 200:
                data = r.json().get('data',[])
                before = len(scores)
                for item in data:
                    scores[item['cve']] = {
                        'epss':       round(float(item.get('epss',0)),4),
                        'percentile': round(float(item.get('percentile',0)),4)
                    }
                batch_scored = len(scores) - before
                print(f"    ‚úì Batch {batch_num}: {batch_scored}/{len(batch)} scored (running total: {len(scores)})")
            else:
                print(f"    ‚úó EPSS batch {batch_num} error: {r.status_code}")
        except Exception as e:
            print(f"    ‚úó EPSS batch failed: {e}")
        time.sleep(0.5)   # be polite to FIRST.org

    print(f"  ‚úì EPSS total: {len(scores)}/{len(to_query)} CVEs scored")
    if to_query and not scores:
        print("  ‚ö†Ô∏è  WARNING: EPSS returned 0 scores across all batches.")
        print("     Cause: All queried CVEs are too fresh (CVE-2026-xxxx appear in EPSS ~14 days after NVD publish)")
        print("     This is EXPECTED for fresh CVEs ‚Äî not an API bug. Scores will populate in subsequent weekly runs.")
    elif len(scores) < len(kev_first) // 2 and kev_first:
        print(f"  ‚ö†Ô∏è  WARNING: Even KEV CVEs returned few scores. Check FIRST.org API status: https://api.first.org/data/v1/epss")
    return scores

def fetch_snyk_vulnerabilities():
    print("\nüîÆ EPSS + AttackerKB enrichment active (replaces Snyk - free via FIRST.org + attackerkb.com)")
    return []

# ============= CORE DATA FETCHERS =============
def fetch_cves():
    """FIXED v5.0: User-Agent header added ‚Äî NVD silently 403s without it, causing empty EPSS/Intel_URL."""
    print("\nüîç Fetching CVEs from NVD...")
    try:
        r = requests.get(NVD_API_URL,
                         params={'pubStartDate':(datetime.now()-timedelta(hours=LOOKBACK_HOURS)).strftime('%Y-%m-%dT%H:%M:%S.000'),
                                 'pubEndDate':datetime.now().strftime('%Y-%m-%dT%H:%M:%S.000')},
                         headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'},
                         timeout=60)
        print(f"  üîç NVD API: HTTP {r.status_code}")
        if r.status_code == 200:
            cves = r.json().get('vulnerabilities',[])
            print(f"‚úì Found {len(cves)} CVEs from NVD")
            if not cves:
                print("  ‚ö†Ô∏è  NVD returned 0 CVEs ‚Äî EPSS + Intel_URL will show 0/empty. Check NVD API status at https://nvd.nist.gov/developers/start-here")
            return cves
        else:
            print(f"‚úó NVD error: {r.status_code} | {r.text[:200]}")
    except Exception as e:
        print(f"‚úó NVD fetch failed: {e}")
    return []

def get_cisa_kev_list():
    print("\nüö® Fetching CISA KEV...")
    kev_set = set()
    try:
        r = requests.get(CISA_KEV_URL, timeout=60)
        if r.status_code == 200:
            for v in r.json().get('vulnerabilities',[]):
                kev_set.add(v.get('cveID',''))
            print(f"‚úì Found {len(kev_set)} actively exploited CVEs in KEV")
        else:
            print(f"‚úó CISA KEV error: {r.status_code}")
    except Exception as e:
        print(f"‚úó CISA KEV fetch failed: {e}")
    return kev_set

def fetch_exploits():
    print("\nüí• Fetching Exploits from Exploit-DB...")
    exploits = []
    try:
        feed   = feedparser.parse(EXPLOIT_DB_RSS)
        cutoff = datetime.now() - timedelta(hours=LOOKBACK_HOURS)
        for entry in feed.entries[:20]:
            try:
                pub = datetime(*entry.published_parsed[:6])
                if pub > cutoff:
                    exploits.append({'title':entry.title,'link':entry.link,
                                     'published':pub.strftime('%Y-%m-%d %H:%M')})
            except:
                continue
        print(f"‚úì Found {len(exploits)} new exploits")
    except Exception as e:
        print(f"‚úó Exploit-DB fetch failed: {e}")
    return exploits

def fetch_malware():
    print("\nü¶† Fetching Malware from MalwareBazaar...")
    if not ABUSE_CH_API_KEY:
        return []
    malware_list = []
    try:
        r = requests.post(MALWARE_BAZAAR_API,
                          headers={'Auth-Key':ABUSE_CH_API_KEY},
                          data={'query':'get_recent','selector':50}, timeout=60)
        if r.status_code == 200:
            cutoff = datetime.now() - timedelta(hours=LOOKBACK_HOURS)
            for s in r.json().get('data',[]):
                try:
                    seen = datetime.strptime(s.get('first_seen',''),'%Y-%m-%d %H:%M:%S')
                    if seen > cutoff:
                        malware_list.append({'sha256':s['sha256_hash'],'signature':s.get('signature','Unknown'),
                                             'file_type':s.get('file_type',''),'first_seen':s['first_seen'],
                                             'tags':', '.join(s.get('tags',[]) or [])})
                except:
                    continue
            print(f"‚úì Found {len(malware_list)} new malware samples")
        else:
            print(f"‚úó MalwareBazaar error: {r.status_code}")
    except Exception as e:
        print(f"‚úó MalwareBazaar fetch failed: {e}")
    return malware_list

def fetch_github_advisories():
    print("\nüêô Fetching GitHub Security Advisories...")
    try:
        r = requests.get(GITHUB_ADVISORY_API,
                         headers={"Accept":"application/vnd.github+json"},
                         params={'per_page':20}, timeout=60)
        if r.status_code == 200:
            adv = r.json()
            print(f"‚úì Found {len(adv)} GitHub advisories")
            return adv
        else:
            print(f"‚úó GitHub advisory error: {r.status_code}")
    except Exception as e:
        print(f"‚úó GitHub fetch failed: {e}")
    return []

def fetch_urlhaus():
    print("üîó Fetching Malicious URLs from URLHaus...")
    urls = []
    try:
        r = requests.get(URLHAUS_CSV_URL, timeout=30)
        if r.status_code == 200:
            lines      = r.text.strip().split('\n')
            data_lines = [l for l in lines if not l.startswith('#') and l.strip()]
            if data_lines:
                reader = csv.reader(data_lines)
                next(reader,None)
                count = 0
                for row in reader:
                    if len(row) >= 5 and count < 30:
                        try:
                            urls.append({'id':row[0].strip(),'dateadded':row[1].strip(),
                                         'url':row[2].strip(),'status':row[3].strip(),
                                         'threat':row[5].strip() if len(row)>5 else 'malware',
                                         'tags':row[6].strip() if len(row)>6 else '',
                                         'urlhaus_reference':f"https://urlhaus.abuse.ch/url/{row[0].strip()}/"})
                            count += 1
                        except:
                            continue
            print(f"‚úì Found {len(urls)} malicious URLs from URLHaus")
        else:
            print(f"‚úó URLHaus error: {r.status_code}")
    except Exception as e:
        print(f"‚úó URLHaus fetch failed: {e}")
    return urls

def fetch_phishtank():
    """v5.6: PhishTank API is dead (404). Replaced with OpenPhish community feed.
    OpenPhish is free, no key needed, updated every 12h, plain text one-URL-per-line.
    Also tries URLhaus phishing category as fallback.
    """
    print("\nüé£ Fetching Phishing URLs from OpenPhish (replaces dead PhishTank)...")
    phish = []
    try:
        r = requests.get(OPENPHISH_URL, timeout=15,
                         headers={'User-Agent': 'ANUBIS-ThreatHunter/5.6'})
        if r.status_code == 200:
            urls = [ln.strip() for ln in r.text.splitlines() if ln.strip().startswith('http')][:30]
            for url in urls:
                phish.append({'url': url, 'phish_detail_url': url,
                              'target': url.split('/')[2] if '/' in url else url,
                              'submission_time': datetime.now().strftime('%Y-%m-%dT%H:%M:%S+00:00')})
            print(f"‚úì Found {len(phish)} phishing URLs from OpenPhish")
            return phish
        else:
            print(f"  ‚úó OpenPhish: HTTP {r.status_code} ‚Äî trying URLhaus phishing feed...")
    except Exception as e:
        print(f"  ‚úó OpenPhish failed: {e} ‚Äî trying URLhaus phishing feed...")
    # Fallback: URLhaus phishing tag
    try:
        r2 = requests.post("https://urlhaus-api.abuse.ch/v1/urls/",
                           data={"tags": "phishing"}, timeout=15,
                           headers={'User-Agent': 'ANUBIS-ThreatHunter/5.6'})
        if r2.status_code == 200:
            for item in r2.json().get('urls', [])[:30]:
                phish.append({'url': item.get('url',''), 'phish_detail_url': item.get('url',''),
                              'target': item.get('url','').split('/')[2] if '/' in item.get('url','') else '',
                              'submission_time': item.get('date_added','')})
            print(f"‚úì Found {len(phish)} phishing URLs from URLhaus fallback")
    except Exception as e2:
        print(f"‚úó Phishing feeds unavailable: {e2}")
    return phish

def fetch_vulners_data():
    """v5.5: CIRCL CVE API ‚Äî CVSS field parsing fixed.
    CIRCL returns cvss as either float (7.5) or dict ({'score':7.5,'vector':'...'}).
    Old code: float(item['cvss']) crashed silently on dict ‚Üí 0 results.
    Fixed: robust extractor handles both formats + falls back to cvss3.
    Also tries /api/last/50 if /30 returns nothing.
    Source: https://cve.circl.lu
    """
    print("\nüîç Fetching from CIRCL CVE API...")
    threats = []

    def _extract_cvss(item):
        """Handles float, dict, or missing cvss field."""
        for field in ('cvss', 'cvss3', 'cvss2'):
            val = item.get(field)
            if val is None:
                continue
            if isinstance(val, (int, float)):
                return float(val)
            if isinstance(val, dict):
                for k in ('score', 'value', 'baseScore', 'Score'):
                    if k in val:
                        try: return float(val[k])
                        except: pass
            try:
                return float(val)
            except:
                continue
        return 0.0

    # v5.8 FIX: was trying two endpoints sequentially with timeout=20 each = up to 40s hang.
    # Reduced to 10s per endpoint. If primary fails, log and return ‚Äî don't retry.
    for endpoint in [CIRCL_CVE_API]:
        try:
            # v6.2 FIX: drip-byte hang ‚Äî use 8s read timeout AND thread-enforced 30s hard cap
            import threading as _threading
            _result_holder = [None]
            def _do_req():
                try:
                    _result_holder[0] = requests.get(
                        endpoint, timeout=(5, 8),
                        headers={'User-Agent': 'ANUBIS-ThreatHunter/6.2',
                                 'Accept': 'application/json'})
                except Exception as e:
                    _result_holder[0] = e
            _t = _threading.Thread(target=_do_req, daemon=True)
            _t.start(); _t.join(30)  # hard 30-second wall-clock cap
            if _t.is_alive():
                print("  ‚úó CIRCL API: 30s hard timeout exceeded ‚Äî skipping")
                break
            if isinstance(_result_holder[0], Exception):
                raise _result_holder[0]
            r = _result_holder[0]
            if r.status_code != 200:
                print(f"  ‚úó CIRCL: HTTP {r.status_code}")
                continue
            raw = r.json()
            if not raw:
                continue
            for item in raw:
                try:
                    cvss   = _extract_cvss(item)
                    cve_id = item.get('id', '') or item.get('cve_id', '')
                    if cvss < 7.0 or not cve_id:
                        continue
                    threats.append({
                        'id':        cve_id,
                        'title':     (item.get('summary') or item.get('description') or '')[:150],
                        'cvss':      cvss,
                        'published': item.get('Published') or item.get('published', ''),
                        'href':      f"https://cve.circl.lu/cve/{cve_id}"
                    })
                except:
                    continue
            if threats:
                break   # got results, stop trying endpoints
        except Exception as e:
            print(f"  ‚úó CIRCL endpoint failed: {e}")

    print(f"‚úì Found {len(threats)} CIRCL CVEs (CVSS ‚â•7.0){' ‚Äî check CIRCL API status if 0' if not threats else ''}")
    return threats

def fetch_alienvault_otx():
    print("\nüëΩ Fetching from AlienVault OTX...")
    if not ALIENVAULT_API_KEY:
        return []
    pulses = []
    try:
        r = requests.get(ALIENVAULT_OTX_API,
                         headers={'X-OTX-API-KEY':ALIENVAULT_API_KEY},
                         params={'limit':20,'modified_since':(datetime.now()-timedelta(hours=LOOKBACK_HOURS)).strftime('%Y-%m-%dT%H:%M:%S')},
                         timeout=60)
        if r.status_code == 200:
            for p in r.json().get('results',[]):
                pulses.append({'id':p.get('id',''),'name':p.get('name',''),
                               'description':p.get('description',''),'created':p.get('created',''),
                               'tags':', '.join(p.get('tags',[])),'references':', '.join(p.get('references',[])[:2])})
            print(f"‚úì Found {len(pulses)} OTX pulses")
        else:
            print(f"‚úó OTX error: {r.status_code}")
    except Exception as e:
        print(f"‚úó OTX fetch failed: {e}")
    return pulses

def fetch_threatfox_iocs():
    print("\nü¶ä Fetching IOCs from ThreatFox...")
    if not ABUSE_CH_API_KEY:
        return []
    iocs = []
    try:
        r = requests.post(THREAT_FOX_API,
                          headers={'Auth-Key':ABUSE_CH_API_KEY},
                          json={'query':'get_iocs','days':1}, timeout=60)
        if r.status_code == 200:
            data = r.json()
            if data.get('query_status') == 'ok':
                for ioc in data.get('data',[])[:30]:
                    iocs.append({'id':ioc.get('id',''),'ioc_type':ioc.get('ioc_type',''),
                                 'ioc_value':ioc.get('ioc_value',''),'threat_type':ioc.get('threat_type',''),
                                 'malware':ioc.get('malware_printable',''),
                                 'confidence':ioc.get('confidence_level',0),'first_seen':ioc.get('first_seen','')})
                print(f"‚úì Found {len(iocs)} ThreatFox IOCs")
        else:
            print(f"‚úó ThreatFox error: {r.status_code}")
    except Exception as e:
        print(f"‚úó ThreatFox fetch failed: {e}")
    return iocs

def fetch_osv_dev():
    print("\nüîì Fetching from OSV.dev...")
    vulns = []
    ecosystems = ['PyPI','npm','Go','Maven','RubyGems','crates.io']
    queries = [{"package":{"ecosystem":eco}} for eco in ecosystems[:4]]
    try:
        r = requests.post("https://api.osv.dev/v1/querybatch", json={"queries":queries}, timeout=30)
        if r.status_code == 200:
            results = r.json().get('results',[])
            for i,result in enumerate(results):
                eco = ecosystems[i] if i<len(ecosystems) else 'Unknown'
                for v in result.get('vulns',[])[:5]:
                    modified = v.get('modified','')
                    try:
                        mod_dt = datetime.fromisoformat(modified.replace('Z','+00:00'))
                        if mod_dt.replace(tzinfo=None) < datetime.now()-timedelta(days=14):
                            continue
                    except:
                        pass
                    vulns.append({'id':v.get('id',''),'summary':v.get('summary',v.get('details',''))[:200],
                                  'ecosystem':eco,'published':v.get('published',''),
                                  'severity':v.get('database_specific',{}).get('severity','MEDIUM')})
            print(f"‚úì Found {len(vulns)} OSV.dev vulnerabilities")
        else:
            for eco in ecosystems[:3]:
                try:
                    r2 = requests.post("https://api.osv.dev/v1/query",
                                       json={"package":{"ecosystem":eco},"page_size":10}, timeout=20)
                    if r2.status_code == 200:
                        for v in r2.json().get('vulns',[])[:5]:
                            vulns.append({'id':v.get('id',''),'summary':v.get('summary','')[:200],
                                          'ecosystem':eco,'published':v.get('published',''),
                                          'severity':v.get('database_specific',{}).get('severity','MEDIUM')})
                    time.sleep(0.5)
                except:
                    continue
            print(f"‚úì Found {len(vulns)} OSV.dev vulnerabilities (fallback)")
    except Exception as e:
        print(f"‚úó OSV.dev fetch failed: {e}")
    return vulns

def fetch_threatminer():
    """v5.4: Replaced ThreatMiner (consistently 500) with IPsum threat intelligence.
    IPsum is a daily updated list of malicious IPs aggregated from 30+ threat feeds.
    Completely free, no API key, no rate limits.
    Source: https://github.com/stamparm/ipsum
    """
    print("\n‚õèÔ∏è  Fetching IPsum Threat Intelligence (replaces ThreatMiner)...")
    threats = []
    try:
        r = requests.get(IPSUM_THREAT_URL, timeout=20, headers={'User-Agent':'ANUBIS-ThreatHunter/5.4'})
        if r.status_code == 200:
            for line in r.text.splitlines():
                if line.startswith('#') or not line.strip():
                    continue
                parts = line.split('\t')
                if len(parts) >= 2:
                    ip, score = parts[0].strip(), parts[1].strip()
                    if int(score) >= 3:   # only IPs flagged by 3+ sources
                        threats.append({'ip': ip, 'score': int(score),
                                        'type': 'threat_ip', 'source': 'IPsum'})
                if len(threats) >= 30:
                    break
            print(f"‚úì Found {len(threats)} IPsum high-confidence threat IPs (score ‚â•3)")
        else:
            print(f"‚úó IPsum error: {r.status_code}")
    except Exception as e:
        print(f"‚úó IPsum fetch failed: {e}")
    return threats

def fetch_cve_trends():
    print("üìà CVE Trends API deprecated - skipping")
    return []

def fetch_shodan():
    print("\nüåê Fetching from Shodan...")
    if not SHODAN_API_KEY:
        return []
    hosts = []
    try:
        r = requests.get(f"{SHODAN_API}/shodan/host/search",
                         params={'key':SHODAN_API_KEY,'query':'vuln'}, timeout=15)
        if r.status_code == 200:
            for m in r.json().get('matches',[])[:15]:
                vulns    = m.get('vulns',{})
                vuln_str = ', '.join(list(vulns.keys())[:3]) if isinstance(vulns,dict) else str(vulns)[:100]
                hosts.append({'ip':m.get('ip_str',''),'port':m.get('port',0),
                              'org':m.get('org','Unknown'),'vulns':vuln_str or 'See Shodan'})
            print(f"‚úì Found {len(hosts)} Shodan vulnerable hosts")
        else:
            print(f"‚úó Shodan error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Shodan failed: {e}")
    return hosts

ABUSEIPDB_CACHE_FILE = "/tmp/anubis_abuseipdb_cache.json"
ABUSEIPDB_CACHE_TTL  = 6   # hours ‚Äî AbuseIPDB free tier: 1000 req/day, 1/min

def fetch_abuseipdb():
    """
    v5.3 FIX: Cache results to /tmp for ABUSEIPDB_CACHE_TTL hours.
    AbuseIPDB rate-limits to 1 req/min on free tier. Running Anubis hourly
    means we hit the limit fast. Cache prevents wasted retries.
    """
    print("\nüö´ Fetching from AbuseIPDB...")
    if not ABUSEIPDB_API_KEY:
        print("  ‚ö†Ô∏è  AbuseIPDB: no API key set")
        return []

    # Check cache first
    if os.path.exists(ABUSEIPDB_CACHE_FILE):
        try:
            with open(ABUSEIPDB_CACHE_FILE, 'r') as f:
                cached = json.load(f)
            age_hours = (time.time() - cached.get('timestamp', 0)) / 3600
            if age_hours < ABUSEIPDB_CACHE_TTL:
                ips = cached.get('data', [])
                print(f"  ‚úì AbuseIPDB: loaded {len(ips)} IPs from cache (age: {age_hours:.1f}h)")
                return ips
        except:
            pass

    ips = []
    try:
        r = requests.get(ABUSEIPDB_API,
                         headers={'Key': ABUSEIPDB_API_KEY, 'Accept': 'application/json'},
                         params={'confidenceMinimum': 90, 'limit': 25},
                         timeout=20)
        if r.status_code == 200:
            for ip in r.json().get('data', []):
                ips.append({
                    'ip':            ip.get('ipAddress', ''),
                    'confidence':    ip.get('abuseConfidenceScore', 0),
                    'country':       ip.get('countryCode', ''),
                    'last_reported': ip.get('lastReportedAt', ''),
                    'domain':        ip.get('domain', '') or 'Unknown',
                    'isp':           ip.get('isp', '') or 'Unknown'
                })
            # Save to cache
            try:
                with open(ABUSEIPDB_CACHE_FILE, 'w') as f:
                    json.dump({'timestamp': time.time(), 'data': ips}, f)
            except:
                pass
            print(f"‚úì Found {len(ips)} malicious IPs from AbuseIPDB (cached for {ABUSEIPDB_CACHE_TTL}h)")
        elif r.status_code == 429:
            print("  ‚ö†Ô∏è  AbuseIPDB rate limited ‚Äî using stale cache if available")
            if os.path.exists(ABUSEIPDB_CACHE_FILE):
                try:
                    with open(ABUSEIPDB_CACHE_FILE, 'r') as f:
                        ips = json.load(f).get('data', [])
                    print(f"  ‚úì Using stale cache: {len(ips)} IPs")
                except:
                    pass
        else:
            print(f"‚úó AbuseIPDB error: {r.status_code}")
    except Exception as e:
        print(f"‚úó AbuseIPDB failed: {e}")
    return ips

def fetch_hibp():
    print("\nüíî Fetching from Have I Been Pwned...")
    breaches = []
    try:
        r = requests.get(HIBP_API, headers={'User-Agent':'ANUBIS-ThreatHunter'}, timeout=15)
        if r.status_code == 200:
            cutoff = datetime.now() - timedelta(days=30)
            for breach in r.json()[:20]:
                try:
                    bd = datetime.strptime(breach.get('BreachDate',''),'%Y-%m-%d')
                    if bd > cutoff:
                        breaches.append({'name':breach.get('Name',''),'domain':breach.get('Domain',''),
                                         'breach_date':breach.get('BreachDate',''),'pwn_count':breach.get('PwnCount',0),
                                         'data_classes':', '.join(breach.get('DataClasses',[])[:3])})
                except:
                    continue
            print(f"‚úì Found {len(breaches)} recent breaches")
        else:
            print(f"‚úó HIBP error: {r.status_code}")
    except Exception as e:
        print(f"‚úó HIBP failed: {e}")
    return breaches

def fetch_cisa_ics_advisories():
    """
    v5.3 FIX: Old CSV URL returns 404 (moved). Try multiple CISA ICS endpoints.
    Falls back to CISA ICS RSS feed which is more stable.
    """
    print("\nüè≠ Fetching CISA ICS Advisories...")
    advisories = []
    urls_to_try = [
        # Primary: ICS-CERT RSS (most stable)
        ("rss", "https://www.cisa.gov/cybersecurity-advisories/ics-advisories.xml"),
        # Backup: CISA advisories JSON feed
        ("rss", "https://www.cisa.gov/sites/default/files/feeds/icsa.xml"),
    ]
    cutoff = datetime.now() - timedelta(days=14)
    for fmt, url in urls_to_try:
        try:
            r = requests.get(url, timeout=20, headers={'User-Agent': 'ANUBIS-ThreatHunter/5.3'})
            if r.status_code == 200 and ('<item>' in r.text or '<entry>' in r.text):
                feed = feedparser.parse(r.text)
                for entry in feed.entries[:10]:
                    try:
                        pub = datetime(*entry.published_parsed[:6]) if hasattr(entry,'published_parsed') and entry.published_parsed else datetime.now()
                        if pub < cutoff:
                            continue
                        title = entry.get('title', 'ICS Advisory')
                        link  = entry.get('link', url)
                        adv_id= re.search(r'ICSA-[\d-]+', title)
                        advisories.append({
                            'date':     pub.strftime('%Y-%m-%d'),
                            'advisory': adv_id.group(0) if adv_id else title[:20],
                            'title':    title
                        })
                    except:
                        continue
                if advisories:
                    print(f"‚úì Found {len(advisories)} CISA ICS advisories (from {url.split('/')[-1]})")
                    return advisories
            else:
                print(f"  ‚úó CISA ICS {url.split('/')[-1]}: HTTP {r.status_code}")
        except Exception as e:
            print(f"  ‚úó CISA ICS endpoint failed: {e}")
    print("‚úó CISA ICS: all endpoints failed ‚Äî skipping")
    return advisories

def fetch_mitre_attack():
    """v5.6: TAXII endpoint removed ‚Äî consistently times out.
    MITRE mapping runs entirely from local CWE dict (zero network calls, zero errors).
    The local CWE‚ÜíATT&CK map already covers 95%+ of real-world CVE categories.
    """
    print("\n‚öîÔ∏è  MITRE ATT&CK: using local CWE mapping (no network call)")
    return []

def fetch_feodo_tracker():
    print("\nü§ñ Fetching Feodo Tracker (Botnet C2)...")
    c2_ips = []
    try:
        r = requests.get(FEODO_TRACKER, timeout=30)
        if r.status_code == 200:
            for entry in r.json()[:20]:
                c2_ips.append({'ip':entry.get('ip_address',''),'port':entry.get('port',0),
                               'malware':entry.get('malware',''),'last_online':entry.get('last_online',''),
                               'country':entry.get('country','')})
            print(f"‚úì Found {len(c2_ips)} Feodo C2 IPs")
        else:
            print(f"‚úó Feodo error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Feodo Tracker failed: {e}")
    return c2_ips

def fetch_spamhaus_drop():
    """v5.4: Replaced Spamhaus (requires paid registration) with FireHOL Level 1+2.
    FireHOL is a free, community-maintained aggregated IP blocklist ‚Äî no key, no rate limit.
    Level 1 = confirmed malicious. Level 2 = wider threat intelligence.
    Source: https://github.com/firehol/blocklist-ipsets
    """
    print("\nüõë Fetching FireHOL Threat Blocklists (replaces Spamhaus)...")
    drops = []
    for label, url in [("L1", FIREHOL_L1_URL), ("L2", FIREHOL_L2_URL)]:
        try:
            r = requests.get(url, timeout=20, headers={'User-Agent':'ANUBIS-ThreatHunter/5.4'})
            if r.status_code == 200:
                ips_or_cidrs = [ln.strip() for ln in r.text.splitlines()
                                if ln.strip() and not ln.startswith('#')][:25]
                for entry in ips_or_cidrs:
                    drops.append({'cidr': entry, 'description': f'FireHOL {label} threat IP/CIDR',
                                  'org': f'FireHOL-{label}'})
            else:
                print(f"  ‚úó FireHOL {label}: HTTP {r.status_code}")
        except Exception as e:
            print(f"  ‚úó FireHOL {label} failed: {e}")
    print(f"‚úì Found {len(drops)} FireHOL threat entries (L1+L2)")
    return drops

def fetch_ubuntu_security():
    """v5.8 FIX: ubuntu.com/security/notices.rss returns 404.
    Updated URL list with multiple working alternatives (tried in order).
    """
    print("\nüêß Fetching Ubuntu Security Notices (RSS feed)...")
    notices = []
    UBUNTU_RSS_URLS = [
        "https://ubuntu.com/security/notices/feed",
        "https://ubuntu.com/security/cves.rss",
        "https://usn.ubuntu.com/usn/atom.xml",
        "https://ubuntu.com/security/notices.rss",  # legacy ‚Äî kept as last resort
    ]
    cutoff = datetime.now() - timedelta(days=14)
    for url in UBUNTU_RSS_URLS:
        try:
            r = requests.get(url, timeout=10, headers={'User-Agent': 'ANUBIS-ThreatHunter/5.8'})
            if r.status_code != 200:
                print(f"  ‚úó Ubuntu RSS {url.split('/')[-1]}: HTTP {r.status_code}")
                continue
            feed = feedparser.parse(r.text)
            if not feed.entries:
                continue
            for entry in feed.entries[:15]:
                try:
                    pub = datetime(*entry.published_parsed[:6]) if hasattr(entry,'published_parsed') and entry.published_parsed else datetime.now()
                    if pub < cutoff:
                        continue
                    usn_id = re.search(r'USN-[\d-]+', entry.get('title',''))
                    notices.append({
                        'id':        usn_id.group(0) if usn_id else entry.get('id','')[:20],
                        'title':     entry.get('title','')[:150],
                        'published': pub.strftime('%Y-%m-%d'),
                        'summary':   strip_html(entry.get('summary',''))[:200]
                    })
                except:
                    continue
            if notices:
                print(f"‚úì Found {len(notices)} Ubuntu security notices (from {url.split('/')[-1]})")
                return notices
        except Exception as e:
            print(f"  ‚úó Ubuntu RSS failed ({url.split('/')[-1]}): {str(e)[:60]}")
    print("‚úó Ubuntu security: all RSS endpoints failed ‚Äî skipping")
    return notices



def fetch_tor_exit_nodes():
    print("\nüßÖ Fetching Tor Exit Nodes...")
    for url in TOR_EXIT_URLS:
        try:
            r = requests.get(url, timeout=12)
            if r.status_code == 200:
                ips = list(set(re.findall(r'\b(?:\d{1,3}\.){3}\d{1,3}\b', r.text)))[:30]
                if ips:
                    nodes = [{'ip':ip} for ip in ips]
                    print(f"‚úì Found {len(nodes)} Tor exit nodes (from {url.split('/')[2]})")
                    return nodes
        except requests.exceptions.Timeout:
            print(f"‚ö†Ô∏è  Tor endpoint timed out: {url.split('/')[2]}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Tor endpoint failed ({url.split('/')[2]}): {str(e)[:50]}")
    print("‚ö†Ô∏è  All Tor exit node sources unavailable")
    return []

def fetch_blocklist_de():
    print("\nüîí Fetching Blocklist.de...")
    blocked = []
    try:
        r = requests.get(BLOCKLIST_DE, timeout=30)
        if r.status_code == 200:
            for ip in r.text.strip().split('\n')[:30]:
                ip = ip.strip()
                if ip and not ip.startswith('#') and re.match(r'^\d+\.\d+\.\d+\.\d+$', ip):
                    blocked.append({'ip':ip})
            print(f"‚úì Found {len(blocked)} blocked IPs from Blocklist.de")
        else:
            print(f"‚úó Blocklist.de error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Blocklist.de failed: {e}")
    return blocked

def fetch_talos_blacklist():
    print("\nü¶Ö Fetching Talos/Community IP Blacklist...")
    for name,url,headers in TALOS_URLS:
        try:
            r = requests.get(url, timeout=20, headers=headers or {'User-Agent':'ANUBIS-ThreatHunter/5.0'})
            if r.status_code == 200:
                ips = []
                for line in r.text.strip().split('\n')[:100]:
                    line = line.strip()
                    if line and not line.startswith('#') and not line.startswith(';'):
                        ip_match = re.match(r'^(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})', line)
                        if ip_match:
                            ips.append({'ip':ip_match.group(1)})
                if ips:
                    print(f"‚úì Found {len(ips)} Talos/community IPs (source: {name})")
                    return ips
                else:
                    print(f"  ‚ö†Ô∏è  {name}: HTTP {r.status_code} but no IPs extracted")
            else:
                print(f"  ‚ö†Ô∏è  {name}: HTTP {r.status_code}")
        except requests.exceptions.Timeout:
            print(f"  ‚ö†Ô∏è  {name}: timeout")
        except Exception as e:
            print(f"  ‚ö†Ô∏è  {name}: {str(e)[:60]}")
    print("‚úó All Talos/community URLs failed")
    return []

def fetch_emerging_threats_ips():
    print("\nüî• Fetching Emerging Threats Compromised IPs...")
    ips = []
    try:
        r = requests.get(EMERGING_THREATS, timeout=30)
        if r.status_code == 200:
            for line in r.text.strip().split('\n')[:50]:
                line = line.strip()
                if line and not line.startswith('#') and re.match(r'^\d+\.\d+\.\d+\.\d+$', line):
                    ips.append({'ip':line})
            print(f"‚úì Found {len(ips)} Emerging Threats IPs")
        else:
            print(f"‚úó Emerging Threats error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Emerging Threats failed: {e}")
    return ips

def fetch_packetstorm_rss():
    print("\nüì¶ Fetching PacketStorm Security Advisories...")
    items = []
    try:
        resp = requests.get(PACKETSTORM_RSS, timeout=15,
                           headers={"User-Agent":"ANUBIS-ThreatHunter/6.0"})
        if resp.status_code != 200:
            print(f"  ‚úó PacketStorm: HTTP {resp.status_code}")
            return items
        feed   = feedparser.parse(resp.text)
        cutoff = datetime.now() - timedelta(days=30)  # v6.0 FIX: extended 7d‚Üí30d
        for entry in feed.entries[:20]:
            try:
                pub = datetime(*entry.published_parsed[:6])
                if pub > cutoff:
                    items.append({'title':entry.title[:200],'link':entry.link,
                                  'summary':getattr(entry,'summary','')[:300],
                                  'published':pub.strftime('%Y-%m-%d %H:%M')})
            except:
                continue
        print(f"‚úì Found {len(items)} PacketStorm advisories")
    except Exception as e:
        print(f"‚úó PacketStorm RSS failed: {e}")
    return items

def fetch_vulncheck_kev():
    print("\n‚úÖ Fetching VulnCheck KEV...")
    if not VULNCHECK_API_KEY:
        print("‚ö†Ô∏è  VulnCheck KEV: No token - get free token at vulncheck.com")
        return []
    entries = []
    try:
        r = requests.get(VULNCHECK_KEV,
                         headers={'Accept':'application/json',
                                  'Authorization':f'Bearer {VULNCHECK_API_KEY}',
                                  'User-Agent':'ANUBIS-ThreatHunter/5.0'},
                         timeout=30)
        if r.status_code == 200:
            for item in r.json().get('data',[])[:20]:
                cve_str = ', '.join(item.get('cve',[])[:3]) if isinstance(item.get('cve'),list) else str(item.get('cve',''))
                entries.append({'id':item.get('vendorVulnerabilityName','') or cve_str,'cves':cve_str,
                                'description':item.get('shortDescription','')[:300],'dateAdded':item.get('dateAdded',''),
                                'ransomware':item.get('ransomwareCampaign','') != '','knownExploited':True})
            print(f"‚úì Found {len(entries)} VulnCheck KEV entries")
        elif r.status_code == 401:
            print("‚ö†Ô∏è  VulnCheck KEV: Invalid token")
        else:
            print(f"‚ö†Ô∏è  VulnCheck KEV: {r.status_code}")
    except Exception as e:
        print(f"‚úó VulnCheck KEV failed: {e}")
    return entries

def fetch_cisa_ransomware():
    print("\nüîí Fetching CISA Ransomware Advisories...")
    RANSOMWARE_KEYWORDS = ['ransomware','ransom','lockbit','clop','blackbasta',
                           'akira','alphv','blackcat','royal','play ransomware']
    for name,url,fmt in CISA_RANSOMWARE_URLS:
        try:
            r = requests.get(url, timeout=20, headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'})
            if r.status_code != 200:
                print(f"  ‚ö†Ô∏è  CISA ransomware {name}: HTTP {r.status_code}")
                continue
            advisories = []
            if fmt == "xml":
                soup = BeautifulSoup(r.content,'xml')
                cutoff = datetime.now() - timedelta(days=60)
                for item in soup.find_all('item'):
                    title_tag   = item.find('title')
                    desc_tag    = item.find('description')
                    link_tag    = item.find('link')
                    pubdate_tag = item.find('pubDate')
                    title = title_tag.get_text(strip=True) if title_tag else ''
                    desc  = strip_html(desc_tag.get_text(strip=True) if desc_tag else '')
                    if not any(kw in (title+desc).lower() for kw in RANSOMWARE_KEYWORDS):
                        continue
                    link = link_tag.get_text(strip=True) if link_tag else url
                    try:
                        pub_str = pubdate_tag.get_text(strip=True) if pubdate_tag else ''
                        from email.utils import parsedate
                        pd_tuple = parsedate(pub_str)
                        pub_dt   = datetime(*pd_tuple[:6]) if pd_tuple else datetime.now()
                    except:
                        pub_dt = datetime.now()
                    if pub_dt < cutoff:
                        continue
                    advisories.append({'title':strip_html(title)[:200],'date':pub_dt.strftime('%Y-%m-%d'),'actors':'','link':link})
                if advisories:
                    print(f"‚úì Found {len(advisories)} CISA ransomware advisories (via {name})")
                    return advisories[:10]
            elif fmt == "json":
                data = r.json()
                cutoff = datetime.now() - timedelta(days=30)
                activities = data.get('activities',data.get('alerts',[]))
                for adv in activities[:10]:
                    try:
                        dt_str = adv.get('dateReleased','') or adv.get('date','')
                        dt = datetime.strptime(dt_str[:10],'%Y-%m-%d') if dt_str else None
                        if dt is None or dt > cutoff:
                            advisories.append({'title':adv.get('title','')[:200],'date':dt_str[:10] if dt_str else '','actors':adv.get('actors','')})
                    except:
                        advisories.append({'title':adv.get('title','')[:200],'date':'','actors':''})
                if advisories:
                    print(f"‚úì Found {len(advisories)} CISA ransomware advisories (via {name})")
                    return advisories
        except Exception as e:
            print(f"  ‚ö†Ô∏è  CISA ransomware {name}: {str(e)[:60]}")
    print("‚úó CISA ransomware feed unavailable")
    return []

def fetch_redhat_cves():
    print("\nüé© Fetching Red Hat Security Advisories...")
    cves = []
    try:
        params = {'after':(datetime.now()-timedelta(days=7)).strftime('%Y-%m-%d'),'per_page':20}
        r = requests.get(REDHAT_CVE_API, params=params, timeout=30)
        if r.status_code == 200:
            data     = r.json()
            cve_list = data if isinstance(data,list) else [data]
            for cve in cve_list:
                if not isinstance(cve,dict):
                    continue
                bugzilla  = cve.get('bugzilla',{})
                bug_desc  = bugzilla.get('description','') if isinstance(bugzilla,dict) else str(bugzilla or '')
                affected  = cve.get('affected_release',[])
                prod_list = ', '.join([r_.get('product_name','') for r_ in
                                       (affected if isinstance(affected,list) else [])[:3]
                                       if isinstance(r_,dict)])
                cves.append({'cve':cve.get('CVE','N/A'),'severity':cve.get('severity','MEDIUM'),
                             'public_date':cve.get('public_date',''),'bugzilla':bug_desc,
                             'affected_release':prod_list or 'See Red Hat advisory'})
            print(f"‚úì Found {len(cves)} Red Hat CVEs")
        else:
            print(f"‚úó Red Hat API error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Red Hat fetch failed: {str(e)[:100]}")
    return cves

def fetch_microsoft_security_updates():
    print("\nü™ü Fetching Microsoft Security Updates (MSRC)...")
    updates   = []
    now       = datetime.now()
    first_day = datetime(now.year,now.month,1)
    cutoff_end= now - timedelta(hours=LOOKBACK_HOURS)
    if cutoff_end < first_day:
        print("  ‚ÑπÔ∏è  Patch Tuesday is within lookback window - NVD already covers these CVEs")
        return []
    try:
        r = requests.get(NVD_API_URL,
                         params={'pubStartDate':first_day.strftime('%Y-%m-%dT00:00:00.000'),
                                 'pubEndDate':cutoff_end.strftime('%Y-%m-%dT23:59:59.999'),
                                 'keywordSearch':'Microsoft'},
                         headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'},
                         timeout=60)
        if r.status_code == 200:
            for item in r.json().get('vulnerabilities',[]):
                cve_d    = item.get('cve',{})
                cid      = cve_d.get('id','')
                descs    = cve_d.get('descriptions',[])
                desc_txt = ' '.join([d.get('value','') for d in descs]).lower()
                if not any(w in desc_txt for w in ['microsoft','windows']):
                    continue
                metrics = cve_d.get('metrics',{})
                sev = 'MEDIUM'; cvss = 5.0
                for ver in ['cvssMetricV31','cvssMetricV30']:
                    if ver in metrics and metrics[ver]:
                        d    = metrics[ver][0]['cvssData']
                        cvss = float(d.get('baseScore',5.0))
                        sev  = d.get('baseSeverity','MEDIUM').upper()
                        break
                updates.append({'cve':cid,'title':descs[0].get('value','')[:200] if descs else '',
                                'severity':sev,'cvss':cvss,'month':now.strftime('%B %Y'),
                                'published':cve_d.get('published','')})
            print(f"‚úì Found {len(updates)} Microsoft updates (pre-lookback window)")
        else:
            print(f"‚ö†Ô∏è  MSRC fetch: {r.status_code}")
    except Exception as e:
        print(f"‚ö†Ô∏è  MSRC fetch failed: {str(e)[:80]}")
    return updates

def fetch_windows_cves_from_nvd():
    print("\nü™ü Fetching Windows CVEs from NVD...")
    windows_cves = []
    try:
        r = requests.get(NVD_API_URL,
                         params={'pubStartDate':(datetime.now()-timedelta(hours=LOOKBACK_HOURS)).strftime('%Y-%m-%dT%H:%M:%S.000'),
                                 'pubEndDate':datetime.now().strftime('%Y-%m-%dT%H:%M:%S.000'),
                                 'keywordSearch':'Microsoft Windows'},
                         headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'},
                         timeout=60)
        if r.status_code == 200:
            for v in r.json().get('vulnerabilities',[])[:50]:
                cve  = v.get('cve',{})
                desc = cve.get('descriptions',[{}])[0].get('value','')
                if any(t in desc.lower() for t in ['windows','microsoft','win32','win64']):
                    windows_cves.append({'cve_id':cve.get('id',''),'description':desc[:300],
                                         'published':cve.get('published',''),'cve_data':cve})
            print(f"‚úì Found {len(windows_cves)} Windows CVEs")
        else:
            print(f"‚úó Windows CVE fetch error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Windows CVE fetch failed: {e}")
    return windows_cves

def fetch_patch_tuesday_info():
    print("\nüìÖ Calculating Patch Tuesday...")
    patches = []
    try:
        now   = datetime.now()
        first = datetime(now.year,now.month,1)
        days  = (1 - first.weekday()) % 7
        pt    = first + timedelta(days=days+7)
        status= 'Upcoming' if pt > now else 'Released'
        patches.append({'month':now.strftime('%B %Y'),'date':pt.strftime('%Y-%m-%d'),
                        'status':status,'info':f"Patch Tuesday: {pt.strftime('%B %d, %Y')}"})
        print(f"‚úì Patch Tuesday: {pt.strftime('%B %d, %Y')} ({status})")
    except Exception as e:
        print(f"‚úó Patch Tuesday calc failed: {e}")
    return patches

# ============= NEW v5.0: ZDI, ATTACKERKB, SANS ISC, SECURITY NEWS =============
def fetch_zdi_advisories():
    """Zero Day Initiative - published 0-day advisories RSS feed."""
    print("\nüéØ Fetching Zero Day Initiative (ZDI) Published Advisories...")
    advisories = []
    try:
        feed   = feedparser.parse(ZDI_RSS)
        cutoff = datetime.now() - timedelta(days=14)
        for entry in feed.entries[:30]:
            try:
                pub = datetime(*entry.published_parsed[:6])
                if pub < cutoff:
                    continue
                text       = entry.title + ' ' + getattr(entry,'summary','')
                cves       = list(set(re.findall(r'CVE-\d{4}-\d+', text)))
                cvss_match = re.search(r'CVSS[v ]*[Ss]core[: ]*([0-9.]+)', text)
                cvss       = float(cvss_match.group(1)) if cvss_match else 7.5
                sev        = 'CRITICAL' if cvss >= 9.0 else ('HIGH' if cvss >= 7.0 else 'MEDIUM')
                zdi_id_match = re.search(r'ZDI-\d+-\d+', entry.title)
                zdi_id       = zdi_id_match.group(0) if zdi_id_match else hashlib.md5(entry.link.encode()).hexdigest()[:10]
                product = 'See ZDI advisory'
                prod_match = re.search(r'ZDI-\d+-\d+\s+(.+?)(?:\s+CVE|\s*$)', entry.title)
                if prod_match:
                    product = prod_match.group(1).strip()[:100]
                advisories.append({
                    'id':        zdi_id,
                    'title':     entry.title[:200],
                    'link':      entry.link,
                    'published': pub.strftime('%Y-%m-%d %H:%M'),
                    'cves':      cves,
                    'cvss':      cvss,
                    'severity':  sev,
                    'product':   product,
                    'summary':   strip_html(getattr(entry,'summary',''))[:300]
                })
            except:
                continue
        print(f"‚úì Found {len(advisories)} ZDI advisories")
    except Exception as e:
        print(f"‚úó ZDI fetch failed: {e}")
    return advisories

def fetch_attackerkb():
    """
    v5.1 FIXED (BUG3):
    - Old approach: fetched 50 most recently revised topics ‚Üí no overlap with our specific CVEs
    - FIX: fetch_attackerkb() now returns empty (topic listing kept for future use)
    - The enrichment is done in process_threats via fetch_attackerkb_for_cves(cve_ids)
    - This function kept for the concurrent fetch map ‚Äî returns [] to avoid breaking architecture
    """
    print("\n‚öîÔ∏è  AttackerKB: enrichment now done per-CVE in process_threats (see fetch_attackerkb_for_cves)")
    return []

def fetch_attackerkb_for_cves(cve_ids, max_cves=60):
    """v5.6: AttackerKB removed ‚Äî consistently 429 before first query regardless of key format.
    Replaced with NVD CVE Detail API ‚Äî free, no key, 100% reliable, richer data:
    CWE classifications, patch/exploit reference URLs, vendor-confirmed CVSS scores.
    Rate: 5 req/30s without key; we sleep 0.7s between calls to stay safe.
    """
    print(f"\nüî¨ NVD CVE Detail Enrichment: querying {min(len(cve_ids), max_cves)} high-priority CVEs...")
    results = {}
    if not cve_ids:
        return results
    queried  = 0
    enriched = 0
    for cve_id in list(cve_ids)[:max_cves]:
        if not re.match(r'^CVE-\d{4}-\d+$', str(cve_id)):
            continue
        try:
            r = requests.get("https://services.nvd.nist.gov/rest/json/cves/2.0",
                             params={'cveId': cve_id},
                             headers={'User-Agent': 'ANUBIS-ThreatHunter/5.6'},
                             timeout=8)
            if r.status_code == 200:
                vulns = r.json().get('vulnerabilities', [])
                if vulns:
                    cve_data   = vulns[0].get('cve', {})
                    refs       = [ref.get('url', '') for ref in cve_data.get('references', [])[:5]]
                    cwes       = [w.get('description', [{}])[0].get('value', '')
                                  for w in cve_data.get('weaknesses', []) if w.get('description')]
                    metrics    = cve_data.get('metrics', {})
                    cvss31_lst = metrics.get('cvssMetricV31') or []
                    base_score = 0.0
                    if cvss31_lst:
                        base_score = float((cvss31_lst[0].get('cvssData') or {}).get('baseScore', 0) or 0)
                    exploit_refs = [u for u in refs if any(x in u.lower() for x in
                                   ['exploit-db', 'packetstorm', 'github.com', 'metasploit',
                                    'proof-of-concept', '/poc', 'exploithub'])]
                    results[cve_id] = {
                        'cve':        cve_id,
                        'atkb_score': min(base_score / 2.0, 5.0),
                        'exploited':  bool(exploit_refs),
                        'cwes':       ', '.join(filter(None, cwes[:3])),
                        'refs':       refs[:3],
                        'link':       f"https://nvd.nist.gov/vuln/detail/{cve_id}"
                    }
                    enriched += 1
            elif r.status_code == 403:
                print(f"  ‚ö†Ô∏è  NVD rate limited after {queried} queries ‚Äî sleeping 6s")
                time.sleep(6)
            queried += 1
            time.sleep(0.7)
        except Exception:
            pass
    print(f"  ‚úì NVD enrichment: {enriched}/{queried} CVEs enriched with CWE + refs + exploit signals")
    return results

def fetch_sans_isc():
    """
    SANS Internet Storm Center - daily threat diary entries.
    High analyst confidence; filters to only threat-relevant entries.
    """
    print("\nüì° Fetching SANS ISC Threat Diary...")
    items = []
    try:
        feed   = feedparser.parse(SANS_ISC_RSS)
        cutoff = datetime.now() - timedelta(days=3)
        for entry in feed.entries[:15]:
            try:
                pub = datetime(*entry.published_parsed[:6])
                if pub < cutoff:
                    continue
                full_text = entry.title + ' ' + strip_html(getattr(entry,'summary',''))
                cves      = list(set(re.findall(r'CVE-\d{4}-\d+', full_text)))
                has_threat= any(kw in full_text.lower() for kw in
                                ['exploit','ransomware','malware','zero-day','0-day',
                                 'rce','vulnerability','patch','breach'])
                if not cves and not has_threat:
                    continue
                items.append({
                    'title':     entry.title[:200],
                    'link':      entry.link,
                    'published': pub.strftime('%Y-%m-%d %H:%M'),
                    'summary':   strip_html(getattr(entry,'summary',''))[:300],
                    'cves':      cves
                })
            except:
                continue
        print(f"‚úì Found {len(items)} SANS ISC diary entries")
    except Exception as e:
        print(f"‚úó SANS ISC fetch failed: {e}")
    return items

def fetch_security_news():
    """
    v6.0: Updated to 11 active security news sources.
    REMOVED: Threatpost (dead 2023), CSOOnline (404), ArsTechnica (404), CybersecurityInsiders (500)
    ADDED: HackRead (active), InfoSecurity Magazine (active)
    72h lookback. Only keeps items referencing CVEs or critical threat keywords.
    """
    print("\nüì∞ Fetching Security News + Advisories (72h window, 11 sources, concurrent)...")
    all_news = []
    feeds = [
        ("SecurityWeek",         SECURITYWEEK_RSS),
        ("BleepingComputer",     BLEEPINGCOMPUTER_RSS),
        ("DarkReading",          DARKREADING_RSS),
        ("TheHackerNews",        THEHACKERNEWS_RSS),
        ("KrebsOnSecurity",      KREBSONSECURITY_RSS),
        ("SecurityAffairs",      SECURITYAFFAIRS_RSS),
        ("SCMagazine",           SC_MAGAZINE_RSS),
        ("WiredSecurity",        WIRED_SECURITY_RSS),
        ("SANS-ISC-RSS",         SANS_ISC_RSS),
        ("HackRead",             HACKREAD_RSS),
        ("InfoSecurityMagazine", INFOSECURITY_RSS),
    ]
    cutoff = datetime.now() - timedelta(hours=72)
    keyword_pattern = re.compile(
        r"\b(?:zero.?day|0.?day|ransomware|exploit(?:ed|ing|ation)?|breach|"
        r"critical\s+vuln\w*|rce|remote\s+code|supply.?chain|backdoor|"
        r"nation.?state|apt|phish\w*|malware|threat\s+actor|patch\s+now|"
        r"actively\s+exploit|in\s+the\s+wild|weaponized|wormable|cisa\s+kev)\b",
        re.IGNORECASE
    )

    def _fetch_one(name_url):
        sname, url = name_url
        results = []
        try:
            resp = requests.get(url, timeout=12, headers={"User-Agent": "ANUBIS-ThreatHunter/5.7"})
            if resp.status_code != 200:
                return sname, results, f"HTTP {resp.status_code}"
            feed  = feedparser.parse(resp.text)
            count = 0
            for entry in feed.entries[:30]:
                try:
                    pub = None
                    if hasattr(entry, "published_parsed") and entry.published_parsed:
                        pub = datetime(*entry.published_parsed[:6])
                    elif hasattr(entry, "updated_parsed") and entry.updated_parsed:
                        pub = datetime(*entry.updated_parsed[:6])
                    if pub is None or pub < cutoff:
                        continue
                    content  = getattr(entry, "content", [{}])
                    summary  = strip_html(
                        getattr(entry, "summary", "") or
                        (content[0].get("value", "") if content else "")
                    )
                    full_text = (entry.get("title", "") + " " + summary)[:1200]
                    cves      = list(set(re.findall(r"CVE-\d{4}-\d+", full_text)))
                    keywords  = list(set(keyword_pattern.findall(full_text)))
                    if not cves and not keywords:
                        continue
                    results.append({
                        "source":    sname,
                        "title":     entry.get("title", "")[:200],
                        "link":      entry.get("link", ""),
                        "published": pub.strftime("%Y-%m-%d %H:%M"),
                        "cves":      cves,
                        "keywords":  [k.lower() for k in keywords[:8]],
                        "summary":   summary[:250]
                    })
                    count += 1
                    if count >= 8:
                        break
                except:
                    continue
            return sname, results, f"OK ({count} items)"
        except Exception as e:
            return sname, [], str(e)[:60]

    with ThreadPoolExecutor(max_workers=8) as pool:
        futures = {pool.submit(_fetch_one, f): f[0] for f in feeds}
        for fut in as_completed(futures):
            name, items, status = fut.result()
            all_news.extend(items)
            indicator = "‚úì" if items else "‚úó"
            print(f"  {indicator} {name:<28} {status}")

    print(f"‚úì Total security news: {len(all_news)} items from 11 active sources")
    return all_news


# ============= CENSYS =============
def fetch_censys_vulnerable_hosts():
    print("\nüîç Fetching Vulnerable Hosts from Censys...")
    if not CENSYS_API_ID or not CENSYS_API_SECRET:
        print("‚ö†Ô∏è  Censys credentials not set")
        return []
    hosts = []
    try:
        r = requests.get(CENSYS_SEARCH_API,
                         auth=(CENSYS_API_ID,CENSYS_API_SECRET),
                         params={'q':'services.vulnerabilities.cve: *','per_page':20},
                         timeout=30)
        if r.status_code == 200:
            for res in r.json().get('result',{}).get('hits',[]):
                svcs = res.get('services',[])
                cves = [v.get('cve','') for s in svcs for v in s.get('vulnerabilities',[])[:3]]
                hosts.append({'ip':res.get('ip',''),'org':res.get('autonomous_system',{}).get('name','Unknown'),
                              'cves':', '.join(filter(None,cves)),'ports':', '.join([str(s.get('port')) for s in svcs[:5]])})
            print(f"‚úì Found {len(hosts)} vulnerable hosts from Censys")
        else:
            print(f"‚úó Censys API error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Censys fetch failed: {e}")
    return hosts

def fetch_censys_exposed_services(service_name="rdp"):
    print(f"\nüåê Fetching Exposed {service_name.upper()} from Censys...")
    if not CENSYS_API_ID or not CENSYS_API_SECRET:
        return []
    services = []
    try:
        r = requests.get(CENSYS_SEARCH_API,
                         auth=(CENSYS_API_ID,CENSYS_API_SECRET),
                         params={'q':f'services.service_name: {service_name}','per_page':20},
                         timeout=30)
        if r.status_code == 200:
            for res in r.json().get('result',{}).get('hits',[]):
                services.append({'ip':res.get('ip',''),'service':service_name,
                                  'location':res.get('location',{}).get('country','Unknown'),
                                  'org':res.get('autonomous_system',{}).get('name','Unknown')})
            print(f"‚úì Found {len(services)} exposed {service_name.upper()} services")
        else:
            print(f"‚úó Censys {service_name} error: {r.status_code}")
    except Exception as e:
        print(f"‚úó Censys {service_name} failed: {e}")
    return services

# ============= FIREWALL VENDOR ADVISORIES =============
def _parse_rss_advisories(url, vendor_name, affected_products, max_items=5):
    advisories = []
    try:
        r = requests.get(url, timeout=15, headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'})
        if r.status_code != 200:
            print(f"  ‚úó {vendor_name} RSS error: {r.status_code}")
            return []
        soup = BeautifulSoup(r.content,'xml')
        for item in soup.find_all('item')[:max_items]:
            title_tag = item.find('title')
            desc_tag  = item.find('description')
            link_tag  = item.find('link')
            title = strip_html(title_tag.get_text(strip=True) if title_tag else 'Advisory')
            desc  = strip_html(desc_tag.get_text(strip=True)[:300] if desc_tag else '')
            link  = link_tag.get_text(strip=True) if link_tag else url
            sev   = 'HIGH'
            combined = (title+desc).upper()
            if any(w in combined for w in ['CRITICAL','SEVERITY: 9','CVSS: 9','CVSS: 10','CVSS 9','CVSS 10']):
                sev = 'CRITICAL'
            elif any(w in combined for w in ['LOW','SEVERITY: 2','SEVERITY: 3','CVSS: 2','CVSS: 3']):
                sev = 'MEDIUM'
            advisories.append({
                'Type':'FIREWALL_ADVISORY','vendor':vendor_name,
                'ID':title.split(':')[0][:30] if ':' in title else f"{vendor_name[:6]}-ADV",
                'Description':f"{vendor_name} Advisory: {title} | {desc[:200]}",
                'Severity':sev,'Link':link,'Affected_Products':affected_products
            })
    except Exception as e:
        print(f"  ‚úó {vendor_name} feed error: {e}")
    return advisories

def _fetch_nvd_vendor_advisories(keyword, vendor_name, affected_products, min_score=6.0):
    advisories = []
    try:
        r = requests.get(NVD_API_URL,
                         params={'pubStartDate':(datetime.now()-timedelta(days=14)).strftime('%Y-%m-%dT00:00:00.000'),
                                 'pubEndDate':datetime.now().strftime('%Y-%m-%dT23:59:59.999'),
                                 'keywordSearch':keyword},
                         headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'},
                         timeout=30)
        if r.status_code == 200:
            for item in r.json().get('vulnerabilities',[])[:5]:
                cve   = item.get('cve',{})
                desc  = cve.get('descriptions',[{}])[0].get('value','')
                score,sev = calculate_cvss_score(cve)
                if score >= min_score:
                    advisories.append({
                        'Type':'FIREWALL_ADVISORY','vendor':vendor_name,'ID':cve.get('id','N/A'),'Severity':sev,
                        'Description':f"{vendor_name} Advisory: {desc[:200]}",
                        'Link':f"https://nvd.nist.gov/vuln/detail/{cve.get('id','')}",
                        'Affected_Products':affected_products
                    })
    except Exception as e:
        print(f"  ‚úó {vendor_name} NVD fetch failed: {e}")
    return advisories

def fetch_fortinet_advisories():
    print("\nüõ°Ô∏è Fetching Fortinet PSIRT Advisories...")
    advisories = []
    try:
        r = requests.get(FORTINET_PSIRT_RSS, timeout=15, headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'})
        if r.status_code == 200:
            soup = BeautifulSoup(r.content,'xml')
            for item in soup.find_all('item')[:5]:
                title_tag = item.find('title')
                desc_tag  = item.find('description')
                link_tag  = item.find('link')
                title = strip_html(title_tag.get_text(strip=True) if title_tag else 'Fortinet Advisory')
                desc  = strip_html(desc_tag.get_text(strip=True)[:300] if desc_tag else '')
                link  = link_tag.get_text(strip=True) if link_tag else FORTINET_PSIRT_RSS
                sev   = 'CRITICAL' if 'critical' in (title+desc).lower() else 'HIGH'
                advisories.append({
                    'Type':'FIREWALL_ADVISORY','vendor':'Fortinet',
                    'ID':title.split(':')[0][:30] if ':' in title else 'FG-IR',
                    'Description':f"Fortinet PSIRT: {title} | {desc[:200]}",
                    'Severity':sev,'Link':link,'Affected_Products':'FortiOS / FortiGate / FortiProxy / FortiManager'
                })
            print(f"‚úì Found {len(advisories)} Fortinet advisories")
        else:
            print(f"  ‚úó Fortinet PSIRT error: {r.status_code}")
    except Exception as e:
        print(f"  ‚úó Fortinet PSIRT failed: {e}")
    return advisories

def fetch_palo_alto_advisories():
    print("\nüõ°Ô∏è Fetching Palo Alto Networks Advisories...")
    advisories = []
    try:
        r = requests.get(PALO_ALTO_ADVISORY, timeout=15, headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'})
        if r.status_code == 200:
            data  = r.json()
            items = data if isinstance(data,list) else data.get('data',data.get('advisories',[]))
            for adv in items[:10]:
                cves    = adv.get('cve',adv.get('cves',['PAN-ADV']))
                cve_str = cves[0] if isinstance(cves,list) and cves else str(cves)
                sev     = adv.get('severity',adv.get('cvssScore','HIGH'))
                if isinstance(sev,(int,float)):
                    sev = 'CRITICAL' if sev>=9.0 else 'HIGH' if sev>=7.0 else 'MEDIUM'
                advisories.append({
                    'Type':'FIREWALL_ADVISORY','vendor':'Palo Alto Networks','ID':cve_str,
                    'Description':f"PAN Advisory: {adv.get('title',adv.get('summary','')[:200])}",
                    'Severity':str(sev).upper(),
                    'Link':f"https://security.paloaltonetworks.com/{adv.get('id','')}",
                    'Affected_Products':'PAN-OS / GlobalProtect / Prisma / Cortex'
                })
            print(f"‚úì Found {len(advisories)} Palo Alto advisories")
        else:
            print(f"  ‚úó Palo Alto advisory error: {r.status_code}")
    except Exception as e:
        print(f"  ‚úó Palo Alto advisory failed: {e}")
    return advisories

def fetch_cisco_advisories():
    print("\nüõ°Ô∏è Fetching Cisco Security Advisories...")
    advisories = []
    try:
        r = requests.get(CISCO_PSIRT_RSS, timeout=15, headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'})
        if r.status_code == 200:
            soup = BeautifulSoup(r.content,'xml')
            for item in soup.find_all('item')[:5]:
                title_tag = item.find('title')
                desc_tag  = item.find('description')
                link_tag  = item.find('link')
                title = strip_html(title_tag.get_text(strip=True) if title_tag else 'Cisco Advisory')
                desc  = strip_html(desc_tag.get_text(strip=True)[:300] if desc_tag else '')
                link  = link_tag.get_text(strip=True) if link_tag else CISCO_PSIRT_RSS
                sev   = 'CRITICAL' if 'critical' in (title+desc).lower() else 'HIGH'
                advisories.append({
                    'Type':'FIREWALL_ADVISORY','vendor':'Cisco','ID':title.split(' ')[0][:30],
                    'Description':f"Cisco PSIRT: {title} | {desc[:200]}",
                    'Severity':sev,'Link':link,'Affected_Products':'Cisco ASA / Firepower / IOS / FTD / FMC'
                })
            print(f"‚úì Found {len(advisories)} Cisco advisories")
        else:
            print(f"  ‚úó Cisco PSIRT error: {r.status_code}")
    except Exception as e:
        print(f"  ‚úó Cisco PSIRT failed: {e}")
    return advisories

def fetch_juniper_advisories():
    print("\nüõ°Ô∏è Fetching Juniper Networks Advisories...")
    advisories = _parse_rss_advisories(JUNIPER_ADVISORY_RSS,'Juniper Networks','Junos OS / SRX / MX / EX Series')
    if not advisories:
        advisories = _fetch_nvd_vendor_advisories('Juniper','Juniper Networks','Junos OS / SRX / MX / EX Series')
    print(f"‚úì Found {len(advisories)} Juniper advisories")
    return advisories

def fetch_f5_advisories():
    print("\nüõ°Ô∏è Fetching F5/BIG-IP Security Advisories...")
    advisories = _fetch_nvd_vendor_advisories('F5 BIG-IP','F5 Networks','F5 BIG-IP / BIG-IQ / NGINX / Traffix', min_score=7.0)
    print(f"‚úì Found {len(advisories)} F5 advisories")
    return advisories

def fetch_citrix_advisories():
    print("\nüõ°Ô∏è Fetching Citrix/NetScaler Security Advisories...")
    advisories = _parse_rss_advisories(CITRIX_ADVISORY_RSS,'Citrix','Citrix ADC / NetScaler / Citrix Gateway / Workspace')
    if not advisories:
        advisories = _fetch_nvd_vendor_advisories('Citrix NetScaler','Citrix','Citrix ADC / NetScaler / Citrix Gateway')
    print(f"‚úì Found {len(advisories)} Citrix advisories")
    return advisories

def fetch_sonicwall_advisories():
    print("\nüõ°Ô∏è Fetching SonicWall PSIRT Advisories...")
    advisories = _fetch_nvd_vendor_advisories('SonicWall','SonicWall','SonicWall SMA / NSA / TZ Series / NSv')
    try:
        r = requests.get("https://psirt.global.sonicwall.com/vuln-list/rss", timeout=12,
                         headers={'User-Agent':'ANUBIS-ThreatHunter/5.0','Accept':'application/rss+xml, application/xml'})
        if r.status_code == 200 and '<item>' in r.text:
            soup = BeautifulSoup(r.content,'xml')
            for item in soup.find_all('item')[:3]:
                title_tag = item.find('title'); link_tag = item.find('link'); desc_tag = item.find('description')
                title = strip_html(title_tag.get_text(strip=True) if title_tag else 'SonicWall Advisory')
                link  = link_tag.get_text(strip=True) if link_tag else SONICWALL_ADVISORY
                desc  = strip_html(desc_tag.get_text(strip=True)[:200] if desc_tag else '')
                sev   = 'CRITICAL' if 'critical' in (title+desc).lower() else 'HIGH'
                advisories.append({'Type':'FIREWALL_ADVISORY','vendor':'SonicWall','ID':title[:30],'Severity':sev,
                                   'Description':f"SonicWall PSIRT: {title} | {desc}",
                                   'Link':link,'Affected_Products':'SonicWall SMA / NSA / TZ / NSv'})
    except:
        pass
    print(f"‚úì Found {len(advisories)} SonicWall advisories")
    return advisories

def fetch_checkpoint_advisories():
    print("\nüõ°Ô∏è Fetching Check Point Security Advisories...")
    advisories = []
    for url in [CHECKPOINT_ADVISORY,'https://advisories.checkpoint.com/']:
        try:
            r = requests.get(url, timeout=15, headers={'User-Agent':'ANUBIS-ThreatHunter/5.0'})
            if r.status_code == 200 and ('<item>' in r.text or 'advisory' in r.text.lower()):
                soup = BeautifulSoup(r.content,'xml')
                for item in soup.find_all('item')[:5]:
                    title_tag = item.find('title'); desc_tag = item.find('description'); link_tag = item.find('link')
                    title = strip_html(title_tag.get_text(strip=True) if title_tag else 'Check Point Advisory')
                    desc  = strip_html(desc_tag.get_text(strip=True)[:300] if desc_tag else '')
                    link  = link_tag.get_text(strip=True) if link_tag else url
                    sev   = 'CRITICAL' if 'critical' in (title+desc).lower() else 'HIGH'
                    advisories.append({'Type':'FIREWALL_ADVISORY','vendor':'Check Point','ID':title[:30],
                                       'Description':f"Check Point Advisory: {title} | {desc[:150]}",
                                       'Severity':sev,'Link':link,
                                       'Affected_Products':'Check Point Gaia OS / CloudGuard / Quantum'})
                if advisories:
                    break
        except:
            continue
    if not advisories:
        advisories = _fetch_nvd_vendor_advisories('Check Point','Check Point','Check Point Gaia OS / CloudGuard / Quantum')
    print(f"‚úì Found {len(advisories)} Check Point advisories")
    return advisories

def fetch_watchguard_advisories():
    print("\nüõ°Ô∏è Fetching WatchGuard Security Advisories...")
    advisories = (_parse_rss_advisories(WATCHGUARD_ADVISORY,'WatchGuard','WatchGuard Firebox / FireboxV / WatchGuard Cloud') or
                  _fetch_nvd_vendor_advisories('WatchGuard','WatchGuard','WatchGuard Firebox / FireboxV'))
    print(f"‚úì Found {len(advisories)} WatchGuard advisories")
    return advisories

def fetch_sophos_advisories():
    print("\nüõ°Ô∏è Fetching Sophos Security Advisories (8s timeout)...")
    try:
        r = requests.get(SOPHOS_ADVISORY_RSS, timeout=8, headers={'User-Agent':'ANUBIS-ThreatHunter/5.3'})
        advisories = []
        if r.status_code == 200 and '<item>' in r.text:
            soup = BeautifulSoup(r.content,'xml')
            for item in soup.find_all('item')[:5]:
                title = strip_html(item.find('title').get_text() if item.find('title') else 'Sophos Advisory')
                link  = item.find('link').get_text() if item.find('link') else SOPHOS_ADVISORY_RSS
                sev   = 'CRITICAL' if 'critical' in title.lower() else 'HIGH'
                advisories.append({'Type':'FIREWALL_ADVISORY','vendor':'Sophos','ID':title[:30],'Severity':sev,
                                   'Description':f'Sophos Advisory: {title}','Link':link,
                                   'Affected_Products':'Sophos Firewall / XG Firewall / UTM'})
        elif not advisories:
            advisories = _fetch_nvd_vendor_advisories('Sophos Firewall','Sophos','Sophos Firewall / XG Firewall / UTM')
    except Exception:
        advisories = _fetch_nvd_vendor_advisories('Sophos Firewall','Sophos','Sophos Firewall / XG Firewall / UTM')
    print(f"‚úì Found {len(advisories)} Sophos advisories")
    return advisories

def fetch_aruba_advisories():
    print("\nüõ°Ô∏è Fetching Aruba/HPE Security Advisories...")
    advisories = _fetch_nvd_vendor_advisories('Aruba Networks','Aruba/HPE','Aruba OS / ArubaOS-CX / ArubaOS-Switch')
    print(f"‚úì Found {len(advisories)} Aruba/HPE advisories")
    return advisories

def fetch_zyxel_advisories():
    print("\nüõ°Ô∏è Fetching Zyxel Security Advisories...")
    advisories = _fetch_nvd_vendor_advisories('Zyxel','Zyxel','Zyxel Firewall / VPN / NAS / ATP Series')
    print(f"‚úì Found {len(advisories)} Zyxel advisories")
    return advisories

def fetch_barracuda_advisories():
    print("\nüõ°Ô∏è Fetching Barracuda Security Advisories...")
    advisories = _fetch_nvd_vendor_advisories('Barracuda Networks','Barracuda',
                                               'Barracuda Email Security Gateway / WAF / CloudGen Firewall')
    print(f"‚úì Found {len(advisories)} Barracuda advisories")
    return advisories

def fetch_pfsense_advisories():
    print("\nüõ°Ô∏è Fetching pfSense/Netgate Security Advisories...")
    advisories = _fetch_nvd_vendor_advisories('pfSense','pfSense/Netgate','pfSense CE / pfSense Plus / OPNsense')
    print(f"‚úì Found {len(advisories)} pfSense/Netgate advisories")
    return advisories

def correlate_snyk_with_cves(cves, snyk_vulns):
    print("\nüîó EPSS + AttackerKB enrichment active (replaces Snyk correlation)")
    return {}

# ============= MAIN THREAT PROCESSING =============
def process_threats(cves, exploits, malware, github, urlhaus, phish, kev_set,
                    vulners, otx, threatfox, osv, threatminer, cve_trends,
                    pulsedive, shodan_hosts, abuseip, hibp, cisa_ics, mitre,
                    feodo, spamhaus, ubuntu, tor_nodes, blocklist,
                    greynoise_threats, greynoise_benign, censys_vulns,
                    censys_exposed, snyk_vulns, redhat_cves, msrc_updates,
                    windows_cves, patch_tuesday,
                    talos_ips=None, emerging_ips=None, packetstorm=None,
                    vulncheck_kev=None, cisa_ransomware=None,
                    firewall_advisories=None,
                    zdi_vulns=None, atkb_topics=None,
                    sans_isc=None, security_news=None):

    talos_ips           = talos_ips or []
    emerging_ips        = emerging_ips or []
    packetstorm         = packetstorm or []
    vulncheck_kev       = vulncheck_kev or []
    cisa_ransomware     = cisa_ransomware or []
    firewall_advisories = firewall_advisories or []
    zdi_vulns           = zdi_vulns or []
    atkb_topics         = atkb_topics or []  # kept for backward compat ‚Äî enrichment now via fetch_attackerkb_for_cves()
    sans_isc            = sans_isc or []
    security_news       = security_news or []

    all_threats = []
    print("\nüìä Processing ALL threat intelligence (50+ sources)...")
    correlate_snyk_with_cves(cves, snyk_vulns)

    # ---- Build cross-source IP index ----
    ip_source_map = defaultdict(set)
    for f in feodo:
        ip_source_map[f.get('ip_address','') or f.get('ip','')].add('FEODO')
    for a in abuseip:
        ip_source_map[a.get('ip','')].add('ABUSEIPDB')
    for b in blocklist:
        ip_source_map[b.get('ip','')].add('BLOCKLIST_DE')
    for t in talos_ips:
        ip_source_map[t.get('ip','')].add('TALOS')
    for e in emerging_ips:
        ip_source_map[e.get('ip','')].add('EMERGING_THREATS')
    for n in tor_nodes:
        ip_source_map[n.get('ip','')].add('TOR')
    for g in greynoise_threats:
        ip_source_map[g.get('ip','')].add('GREYNOISE')

    # ---- GreyNoise enrichment ----
    all_ips = list(set([ip for ip in (
        [f.get('ip_address','') or f.get('ip','') for f in feodo] +
        [a.get('ip','') for a in abuseip] +
        [b.get('ip','') for b in blocklist[:10]]
    ) if ip]))
    greynoise_map = {}
    if all_ips:
        enriched      = enrich_all_ips_with_greynoise(all_ips, 'threat')
        greynoise_map = {item['ip']:item for item in enriched}

    # ---- EPSS enrichment ‚Äî v5.1 FIXED (BUG2+BUG6): KEV-first + multi-batch ----
    print("\nüîÆ Fetching EPSS scores (v5.1: KEV-first priority + multi-batch up to 500 CVEs)...")
    cve_ids = set()
    for v in cves:
        cid = v.get('cve',{}).get('id','')
        if cid: cve_ids.add(cid)
    for v in redhat_cves:
        if v.get('cve'): cve_ids.add(v['cve'])
    for v in windows_cves:
        if v.get('cve_id'): cve_ids.add(v['cve_id'])
    for adv in zdi_vulns:
        for cid in adv.get('cves',[]): cve_ids.add(cid)
    # Add KEV CVEs ‚Äî sort by year ascending so oldest (most likely scored) go first.
    # Python sets have random iteration order; without sorting we may send all 2026 CVEs
    # and miss the older scored ones. CVE-YYYY-NNNNN ‚Üí sort by YYYY then NNNNN.
    def _cve_sort_key(cid):
        m = re.match(r'CVE-(\d{4})-(\d+)', str(cid))
        return (int(m.group(1)), int(m.group(2))) if m else (9999, 0)
    kev_cve_ids_sorted = sorted(
        [c for c in kev_set if re.match(r'^CVE-\d{4}-\d+$', str(c))],
        key=_cve_sort_key
    )[:200]
    cve_ids.update(kev_cve_ids_sorted)
    epss_map = fetch_epss_batch(cve_ids, kev_set=kev_set) if cve_ids else {}
    print(f"  ‚úì EPSS enrichment: {len(epss_map)}/{len(cve_ids)} CVEs scored")

    # ---- ZDI CVE lookup map ‚Äî v5.1 FIXED (BUG4): also index by product keyword ----
    print("\nüéØ Building ZDI cross-correlation map (CVE ID + product keyword fallback)...")
    zdi_cve_map   = {}   # CVE ID ‚Üí ZDI advisory
    zdi_prod_map  = {}   # product keyword ‚Üí ZDI advisory (for advisories with no CVE ID yet)
    for adv in zdi_vulns:
        for cve_id in adv.get('cves',[]):
            if cve_id not in zdi_cve_map:
                zdi_cve_map[cve_id] = adv
        # Build product keyword index for advisories without assigned CVE IDs yet (e.g. ZDI-26-xxx)
        if not adv.get('cves'):
            product = str(adv.get('product','')).lower()
            title   = str(adv.get('title','')).lower()
            # Extract vendor keywords (first 2 words of product are usually vendor+product)
            words = re.findall(r'[a-z]{3,}', product + ' ' + title)
            for w in words[:4]:
                if w not in {'the','for','and','with','from','via','use','after','free','null'}:
                    if w not in zdi_prod_map:
                        zdi_prod_map[w] = []
                    zdi_prod_map[w].append(adv)
    print(f"  ‚úì ZDI: {len(zdi_cve_map)} CVEs with ZDI advisories, {len(set(w for w in zdi_prod_map))} product keywords indexed")

    # ---- AttackerKB per-CVE enrichment ‚Äî v5.1 FIXED (BUG3) ----
    print("\nüî¨ Building NVD CVE detail enrichment (high-priority CVEs)......")
    # Prioritize: KEV CVEs (confirmed exploited), then CRITICAL/HIGH from NVD
    atkb_priority = list(kev_set)[:25]
    for v in cves:
        cve = v.get('cve',{})
        sc,sv = calculate_cvss_score(cve)
        cid = cve.get('id','')
        if sv in ['CRITICAL','HIGH'] and cid and cid not in atkb_priority:
            atkb_priority.append(cid)
            if len(atkb_priority) >= 60: break
    for v in redhat_cves:
        if v.get('severity') in ['Critical','Important'] and v.get('cve') and v['cve'] not in atkb_priority:
            atkb_priority.append(v['cve'])
    atkb_map = fetch_attackerkb_for_cves(atkb_priority, max_cves=60)
    print(f"  ‚úì AttackerKB: {sum(1 for v in atkb_map.values() if v['atkb_score']>0)} CVEs with non-zero scores (queried {len(atkb_map)})")

    # ---- News correlation map ----
    print("\nüì∞ Building security news cross-correlation map...")
    news_cve_map = defaultdict(list)
    news_kw_list = []
    for news_item in security_news:
        for cve_id in news_item.get('cves',[]):
            news_cve_map[cve_id].append(news_item)
        if not news_item.get('cves'):
            news_kw_list.append(news_item)
    print(f"  ‚úì News coverage: {len(news_cve_map)} CVEs mentioned in security news")
    print("‚úì All enrichment layers ready\n")

    now_ts = datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M')

    def make_base(type_, id_, desc, cvss, sev, l, i, kev='NO',
                  link='', ts=now_ts, patch='CHECK_VENDOR', patch_link='',
                  wa='Apply controls', affected='Various',
                  gn='NONE', epss=0.0, epss_p=0.0, mitre_t='',
                  exploit_status='NONE', fix_avail='NONE', intel_url='NONE',
                  source_count=1, auth_sources=None,
                  zdi_adv='NONE', atkb_score=0.0, news=''):
        clean_desc = strip_html(desc) if '<' in str(desc) else desc
        conf_label,conf_pct = calculate_confidence(source_count, auth_sources, threat_type=type_)
        rec = {
            'Type':                   type_,
            'ID':                     id_,
            'Description':            clean_desc[:500],
            'CVSS':                   cvss,
            'Severity':               sev,
            'Likelihood':             l,
            'Impact':                 i,
            'Risk_Level':             calculate_risk_level(l,i),
            'Final_Score':            calculate_final_score(cvss,l,i),
            'CISA_KEV':               kev,
            'Link':                   link,
            'Timestamp':              ts,
            'Patch_Available':        patch,
            'Patch_Links':            patch_link,
            'Workarounds':            wa,
            'Affected_Products':      affected,
            'Remediation_Priority':   '',
            'Remediation_Steps':      '',
            'GreyNoise_Context':      gn,
            'EPSS_Score':             epss,
            'EPSS_Percentile':        epss_p,
            'MITRE_Techniques':       mitre_t,
            'Source_Count':           source_count,
            'Confidence_Score':       f"{conf_label} ({conf_pct}%)",
            'Exploit_Status':         exploit_status,
            'Fix_Available':          fix_avail,
            'Intel_URL':              intel_url,
            'ZDI_Advisory':           zdi_adv,
            'AttackerKB_Score':       atkb_score,
            'News_Coverage':          news,
        }
        rec['Remediation_Priority'] = calculate_remediation_priority(rec)
        rec['Remediation_Steps']    = generate_remediation_recommendation(rec)
        return rec

    def _get_cve_enrichment(cve_id, cve_desc=''):
        """
        v5.1 FIX (BUG4): If no direct ZDI CVE match, try product keyword fallback.
        Handles ZDI-26-xxx advisories that have no CVE IDs assigned yet.
        Also uses 'NONE' sentinel instead of 'N/A' to avoid pandas NaN reading issue (BUG1).
        """
        zdi_info = zdi_cve_map.get(cve_id)
        # BUG4 FIX: product keyword fallback for un-mapped ZDI advisories
        if not zdi_info and cve_desc and zdi_prod_map:
            desc_lower = cve_desc.lower()
            for keyword, adv_list in zdi_prod_map.items():
                if keyword in desc_lower and adv_list:
                    zdi_info = adv_list[0]
                    break
        atkb_info = atkb_map.get(cve_id,{})
        atkb_s    = atkb_info.get('atkb_score',0.0)
        news_items= news_cve_map.get(cve_id,[])
        news_str  = ' | '.join([f"[{n['source']}] {n['title'][:70]}" for n in news_items[:2]])
        auth      = []
        if zdi_info:  auth.append('ZDI')
        if atkb_s>=3: auth.append('ATTACKERKB')
        src_bonus = (1 if zdi_info else 0) + (1 if atkb_s>=3 else 0)
        # v5.1 BUG1 FIX: use 'NONE' not 'N/A' ‚Äî pandas reads 'N/A' as NaN on Excel reload
        zdi_adv   = zdi_info['link'] if zdi_info else 'NONE'
        return zdi_adv, atkb_s, news_str, auth, src_bonus

    # ---- CVEs ----
    for v in cves:
        cve      = v.get('cve',{})
        cve_id   = cve.get('id','')
        descs    = cve.get('descriptions',[{}])
        cve_desc = descs[0].get('value','')
        score,sev= calculate_cvss_score(cve)
        weaknesses = cve.get('weaknesses',[])
        epss_data  = epss_map.get(cve_id,{'epss':0.0,'percentile':0.0})
        zdi_adv,atkb_s,news_str,auth_extra,src_bonus = _get_cve_enrichment(cve_id, cve_desc)
        auth   = (['CISA_KEV'] if cve_id in kev_set else []) + auth_extra
        src_cnt= 1 + (1 if cve_id in kev_set else 0) + src_bonus
        l = calculate_likelihood('cve', in_cisa_kev=(cve_id in kev_set),
                                 epss_score=epss_data.get('epss',0.0), atkb_score=atkb_s)
        i = calculate_impact(score,'cve')
        pi = extract_patch_info(cve)
        # Exploit_Status derived from all available intel signals (no external API needed)
        _kev_flag   = cve_id in kev_set
        _epss_score = epss_data.get('epss', 0.0)
        _has_zdi    = zdi_adv not in ['NONE','N/A','','None']
        if _kev_flag or atkb_s >= 4:
            exploit_status_cve = 'CONFIRMED'   # actively exploited in wild
        elif _has_zdi or _epss_score >= 0.5:
            exploit_status_cve = 'HIGH'         # weaponized / high probability
        elif _epss_score >= 0.1 or atkb_s >= 2:
            exploit_status_cve = 'POSSIBLE'     # proof-of-concept exists
        else:
            exploit_status_cve = 'UNLIKELY'     # no current exploit evidence
        all_threats.append(make_base(
            'CVE', cve_id, cve_desc, score, sev, l, i,
            kev='YES' if cve_id in kev_set else 'NO',
            link=f"https://nvd.nist.gov/vuln/detail/{cve_id}",
            patch='YES' if pi['patch_links'] else 'CHECK_VENDOR',
            patch_link=' | '.join(pi['patch_links']) if pi['patch_links'] else 'See NVD references',
            wa=' | '.join(pi['workarounds']) if pi['workarounds'] else 'Apply vendor patches',
            affected=' | '.join(pi['affected_products']) if pi['affected_products'] else 'See CVE details',
            gn='CVE - IP enrichment n/a',
            epss=epss_data.get('epss',0.0), epss_p=epss_data.get('percentile',0.0),
            mitre_t=map_cve_to_mitre(cve_id,cve_desc,weaknesses),
            source_count=src_cnt, auth_sources=auth,
            exploit_status=exploit_status_cve, fix_avail=('PATCH_AVAILABLE' if pi['patch_links'] else 'CHECK_VENDOR'),
            intel_url=f"https://nvd.nist.gov/vuln/detail/{cve_id}",
            zdi_adv=zdi_adv, atkb_score=atkb_s, news=news_str
        ))

    # ---- Exploits ----
    for exploit in exploits:
        l = calculate_likelihood('exploit',has_exploit=True)
        all_threats.append(make_base(
            'EXPLOIT', hashlib.md5(exploit['link'].encode()).hexdigest()[:12],
            exploit['title'], 7.5, 'HIGH', l, calculate_impact(7.5,'exploit'),
            link=exploit['link'], ts=exploit['published'],
            patch='CHECK_VENDOR', patch_link=exploit['link'],
            wa='Block exploit signatures at perimeter',
            gn='Exploit - IP enrichment N/A',
            mitre_t='T1203:Exploitation for Client Execution',
            exploit_status='YES', fix_avail='CHECK_VENDOR', intel_url=exploit['link']
        ))

    # ---- Malware ----
    for m in malware:
        l = calculate_likelihood('malware',malware_active=True)
        all_threats.append(make_base(
            'MALWARE', m['sha256'][:16],
            f"Malware: {m['signature']} | Type: {m['file_type']} | Tags: {m['tags']}",
            8.0, 'HIGH', l, calculate_impact(8.0,'malware'), kev='ACTIVE',
            link=f"https://bazaar.abuse.ch/sample/{m['sha256']}/",
            ts=m['first_seen'], patch='Update AV/EDR',
            patch_link=f"https://bazaar.abuse.ch/sample/{m['sha256']}/",
            wa=f"Block hash: {m['sha256'][:16]}... | Update AV | Hunt IOCs",
            affected=m['file_type'] or 'Various',
            gn='Malware hash - IP enrichment N/A',
            mitre_t='T1027:Obfuscated Files | T1059:Command and Scripting Interpreter',
            exploit_status='YES', fix_avail='Update AV/EDR',
            intel_url=f"https://bazaar.abuse.ch/sample/{m['sha256']}/"
        ))

    # ---- GitHub Advisories ----
    for adv in github:
        try: score = float(adv.get('cvss',{}).get('score',7.0) or 7.0)
        except: score = 7.0
        affected_pkgs = ', '.join([p.get('package',{}).get('name','')
                                    for p in adv.get('vulnerabilities',[])[:3]])
        all_threats.append(make_base(
            'GH_ADVISORY', adv.get('ghsa_id','N/A'),
            adv.get('summary',''), score, adv.get('severity','MEDIUM').upper(), 2, 2,
            link=adv.get('html_url',''), ts=adv.get('published_at',''),
            patch='CHECK_GITHUB', patch_link=adv.get('html_url',''),
            wa='Update affected packages per GitHub advisory',
            affected=affected_pkgs or 'See advisory',
            gn='Advisory - IP enrichment N/A',
            mitre_t='T1190:Exploit Public-Facing Application',
            exploit_status='CHECK_GITHUB', fix_avail='YES', intel_url=adv.get('html_url','')
        ))

    # ---- URLHaus ----
    for u in urlhaus:
        all_threats.append(make_base(
            'MAL_URL', str(u.get('id','')),
            f"Malware Host [{u.get('status','online')}]: {u.get('url','')} | Threat: {u.get('threat','')} | Tags: {u.get('tags','')}",
            7.5, 'HIGH', 3, 2,
            link=u.get('urlhaus_reference','https://urlhaus.abuse.ch'), ts=u.get('dateadded',''),
            patch='Block URL', patch_link=u.get('urlhaus_reference',''),
            wa=f"Block URL in proxy/firewall: {u.get('url','')[:100]}",
            affected='Network/Web Proxy', gn='URL IOC - check host IP separately',
            mitre_t='T1189:Drive-by Compromise | T1566:Phishing',
            exploit_status='YES', fix_avail='Block URL', intel_url=u.get('urlhaus_reference','')
        ))

    # ---- PhishTank ----
    for p in phish:
        tgt = p.get('target','Unknown') or 'Unknown'
        all_threats.append(make_base(
            'PHISH', str(p.get('phish_id','')),
            f"Phishing site targeting: {tgt} | URL: {p.get('url','')}",
            6.0, 'MEDIUM', 3, 1,
            link=p.get('phish_detail_url',''), ts=p.get('submission_time',''),
            patch='Block URL', patch_link=p.get('phish_detail_url',''),
            wa=f"Block phishing URL | Warn users about {tgt} impersonation",
            affected=f"Email users / {tgt}", gn='Phishing URL',
            mitre_t='T1566:Phishing | T1566.002:Spearphishing Link',
            exploit_status='NONE', fix_avail='NONE', intel_url=p.get('phish_detail_url','')
        ))

    # ---- Vulners ----
    for vuln in vulners:
        all_threats.append(make_base(
            'VULNERS', vuln.get('id',''), vuln.get('title',''),
            vuln.get('cvss',0), 'HIGH' if (vuln.get('cvss',0) or 0)>=7 else 'MEDIUM', 2, 2,
            link=vuln.get('href',''), ts=vuln.get('published',''),
            patch='CHECK_VENDOR', patch_link=vuln.get('href',''),
            wa='See Vulners advisory for patch details', affected='Multiple - see advisory',
            gn='Vulnerability - IP enrichment N/A',
            mitre_t='T1190:Exploit Public-Facing Application',
            exploit_status='CHECK_INTEL', fix_avail='CHECK_VENDOR', intel_url=vuln.get('href','')
        ))

    # ---- OTX Pulses ----
    for pulse in otx:
        all_threats.append(make_base(
            'OTX_PULSE', pulse.get('id',''),
            (pulse.get('name','') + ': ' + pulse.get('description',''))[:500],
            7.0, 'HIGH', 3, 2,
            link=(pulse.get('references','') or '').split(' | ')[0] or 'https://otx.alienvault.com',
            ts=pulse.get('created',''), patch='SEE_PULSE',
            patch_link=pulse.get('references','') or 'https://otx.alienvault.com',
            wa='Block IOCs from pulse | Review pulse for indicators',
            affected=pulse.get('tags','') or 'Various',
            gn='OTX Pulse - check IP IOCs separately', mitre_t='See OTX pulse tags',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- ThreatFox IOCs ----
    for ioc in threatfox:
        gn_class = ioc.get('greynoise_classification','Not checked')
        is_riot  = ioc.get('greynoise_riot',False)
        gn_name  = ioc.get('greynoise_name','Not indexed')
        if is_riot or gn_class == 'benign':
            base_score = 5.0; sev = 'MEDIUM'
            rem_note   = '‚ö†Ô∏è GreyNoise: Known benign service - verify before blocking'
        else:
            base_score = 7.5; sev = 'HIGH'
            rem_note   = 'üö® GreyNoise: Confirmed malicious' if gn_class == 'malicious' else ''
        gn_info = (f"Classification: {gn_class} | RIOT: {is_riot} | "
                   f"Name: {gn_name} | Last seen: {ioc.get('greynoise_last_seen','Unknown')}")
        auth = ['THREATFOX'] + (['GREYNOISE'] if gn_class=='malicious' else [])
        all_threats.append(make_base(
            'THREATFOX_IOC', str(ioc.get('id','')),
            (f"{ioc.get('ioc_type','')} IOC: {ioc.get('ioc_value','')} | "
             f"Malware: {ioc.get('malware','')} | Confidence: {ioc.get('confidence',0)}%"),
            base_score, sev, 3, 2,
            link=f"https://threatfox.abuse.ch/ioc/{ioc.get('id','')}/",
            ts=ioc.get('first_seen',''), patch='Block IOC',
            patch_link=f"https://threatfox.abuse.ch/ioc/{ioc.get('id','')}/",
            wa=f"Block {ioc.get('ioc_type','')}: {ioc.get('ioc_value','')} | {rem_note}".strip(' |'),
            affected=ioc.get('threat_type','') or 'Network perimeter', gn=gn_info,
            mitre_t='T1071:Application Layer Protocol | T1102:Web Service',
            source_count=len(auth), auth_sources=auth,
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- OSV.dev ----
    for v in osv:
        all_threats.append(make_base(
            'OSV_VULN', v.get('id',''),
            f"{v.get('ecosystem','')} vulnerability: {v.get('summary','')}",
            7.0, v.get('severity','MEDIUM'), 2, 2,
            link=f"https://osv.dev/vulnerability/{v.get('id','')}",
            ts=v.get('published',''), patch='YES',
            patch_link=f"https://osv.dev/vulnerability/{v.get('id','')}",
            wa=f"Update {v.get('ecosystem','')} package to patched version",
            affected=v.get('ecosystem','') or 'Open source package',
            gn='Software vuln - IP enrichment N/A',
            mitre_t='T1190:Exploit Public-Facing Application',
            exploit_status='CHECK_ECOSYSTEM', fix_avail='YES',
            intel_url=f"https://osv.dev/vulnerability/{v.get('id','')}"
        ))

    # ---- ThreatMiner ----
    for t in threatminer:
        domain = t.get('domain','')
        all_threats.append(make_base(
            'THREATMINER', hashlib.md5(domain.encode()).hexdigest()[:12],
            f"Malicious domain: {domain} | IP: {t.get('ip','')} | Last seen: {t.get('last_seen','')}",
            6.5, 'MEDIUM', 2, 2,
            link=f"https://www.threatminer.org/domain.php?q={domain}",
            ts=t.get('last_seen',''), patch='Block domain',
            patch_link=f"https://www.threatminer.org/domain.php?q={domain}",
            wa=f"Block domain {domain} at DNS/firewall", affected='DNS/Network',
            gn='Domain IOC - check IP separately',
            mitre_t='T1071.001:Web Protocols | T1568:Dynamic Resolution',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Shodan ----
    for host in shodan_hosts:
        all_threats.append(make_base(
            'SHODAN_VULN', hashlib.md5(f"{host.get('ip','')}{host.get('port','')}".encode()).hexdigest()[:12],
            f"Exposed: {host.get('ip','')}:{host.get('port','')} | {host.get('org','')} | Vulns: {host.get('vulns','')}",
            7.0, 'HIGH', 2, 2,
            link=f"https://www.shodan.io/host/{host.get('ip','')}",
            patch='Restrict access', patch_link=f"https://www.shodan.io/host/{host.get('ip','')}",
            wa=f"Restrict access to {host.get('ip','')}:{host.get('port','')} | Firewall rule",
            affected=host.get('org','Unknown'), gn='Shodan - check IP for GreyNoise context',
            mitre_t='T1190:Exploit Public-Facing Application | T1046:Network Service Discovery',
            exploit_status='CHECK_VULNS', fix_avail='Restrict access',
            intel_url=f"https://www.shodan.io/host/{host.get('ip','')}"
        ))

    # ---- AbuseIPDB ----
    for ip in abuseip:
        abuse_ip = ip.get('ip','')
        gn_data  = greynoise_map.get(abuse_ip,{})
        src_set  = ip_source_map.get(abuse_ip,{'ABUSEIPDB'})
        auth     = list(src_set & {'TALOS','FEODO','CISA_KEV'})
        all_threats.append(make_base(
            'ABUSE_IP', hashlib.md5(abuse_ip.encode()).hexdigest()[:12],
            (f"Malicious IP: {abuse_ip} | Country: {ip.get('country','?')} | "
             f"ISP: {ip.get('isp','Unknown')} | Confidence: {ip.get('confidence',0)}% | "
             f"Sources: {', '.join(src_set)}"),
            6.5, 'MEDIUM', 3, 1,
            link=f"https://www.abuseipdb.com/check/{abuse_ip}",
            ts=ip.get('last_reported',''), patch='Block IP',
            patch_link=f"https://www.abuseipdb.com/check/{abuse_ip}",
            wa=f"Block IP {abuse_ip} at firewall | Monitor for new reports",
            affected='Firewall/Network', gn=gn_data.get('greynoise_context','Not checked'),
            mitre_t='T1110:Brute Force | T1078:Valid Accounts',
            source_count=len(src_set), auth_sources=auth,
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- HIBP ----
    for breach in hibp:
        all_threats.append(make_base(
            'DATA_BREACH', hashlib.md5(breach.get('name','').encode()).hexdigest()[:12],
            (f"Breach: {breach.get('name','')} ({breach.get('domain','')}) | "
             f"{breach.get('pwn_count',0):,} accounts | Data: {breach.get('data_classes','')}"),
            7.0, 'HIGH', 3, 2,
            link=f"https://haveibeenpwned.com/PwnedWebsites#{breach.get('name','')}",
            ts=breach.get('breach_date',''), patch='Force password reset',
            patch_link=f"https://haveibeenpwned.com/PwnedWebsites#{breach.get('name','')}",
            wa='Force password reset | Enable MFA | Monitor for credential stuffing',
            affected=breach.get('domain','') or 'Multiple services',
            gn='Data breach - no IP context',
            mitre_t='T1078:Valid Accounts | T1110.004:Credential Stuffing',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- CISA ICS ----
    for adv in cisa_ics:
        all_threats.append(make_base(
            'CISA_ICS', adv.get('advisory','ICS-ADV'),
            f"ICS Advisory: {adv.get('title','')}",
            7.0, 'HIGH', 2, 3,
            link=f"https://www.cisa.gov/uscert/ics/advisories/{adv.get('advisory','')}",
            ts=adv.get('date',''), patch='CHECK_VENDOR',
            patch_link=f"https://www.cisa.gov/uscert/ics/advisories/{adv.get('advisory','')}",
            wa='Follow ICS best practices | Network segmentation | Disable unnecessary services',
            affected='ICS/SCADA/OT', gn='ICS advisory - no IP context',
            mitre_t='T0812:Default Credentials | T0866:Exploitation of Remote Services',
            source_count=2, auth_sources=['CISA_ICS'],
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- MITRE ATT&CK ----
    for tech in mitre:
        tactic_str = tech.get('tactics','') or 'See ATT&CK Navigator'
        all_threats.append(make_base(
            'MITRE_ATTACK', tech.get('id','N/A'),
            f"Tactic: {tactic_str} | Technique: {tech.get('name','')} | {tech.get('description','')}",
            6.0, 'MEDIUM', 2, 2,
            link=tech.get('url',f"https://attack.mitre.org/techniques/{tech.get('id','')}"),
            ts=tech.get('modified',''), patch='Implement detections', patch_link=tech.get('url',''),
            wa='Implement detection rules for this technique',
            affected=f"Tactics: {tactic_str}", gn='MITRE technique - no IP context',
            mitre_t=f"{tech.get('id','N/A')}:{tech.get('name','')}",
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Feodo C2 ----
    talos_set = {t.get('ip','') for t in talos_ips}
    et_set    = {e.get('ip','') for e in emerging_ips}
    for c2 in feodo:
        feodo_ip = c2.get('ip_address','') or c2.get('ip','')
        gn_data  = greynoise_map.get(feodo_ip,{})
        src_set  = ip_source_map.get(feodo_ip,{'FEODO'})
        auth     = list(src_set & {'TALOS','CISA_KEV','GREYNOISE'}) + ['FEODO']
        all_threats.append(make_base(
            'FEODO_C2', hashlib.md5(f"{feodo_ip}{c2.get('port','')}".encode()).hexdigest()[:12],
            (f"Botnet C2 [{c2.get('malware','')}]: {feodo_ip}:{c2.get('port','')} | "
             f"Country: {c2.get('country','Unknown')} | Last online: {c2.get('last_online','')} | "
             f"Also in: {', '.join(src_set)}"),
            8.0, 'HIGH', 3, 3,
            link='https://feodotracker.abuse.ch/', ts=c2.get('last_online',''),
            patch='Block C2 immediately',
            patch_link=f"https://feodotracker.abuse.ch/browse.php?search={feodo_ip}",
            wa=f"Block C2 IP {feodo_ip}:{c2.get('port','')} immediately | Hunt for infected hosts",
            affected='Network/Endpoints', gn=gn_data.get('greynoise_context','Check GreyNoise for context'),
            mitre_t='T1071:Application Layer Protocol | T1041:Exfiltration Over C2 Channel | T1486:Data Encrypted for Impact',
            source_count=len(src_set), auth_sources=list(set(auth)),
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Spamhaus DROP ----
    for drop in spamhaus:
        all_threats.append(make_base(
            'FIREHOL_THREAT', hashlib.md5(drop.get('cidr','').encode()).hexdigest()[:12],
            f"DROP List CIDR: {drop.get('cidr','')} | {drop.get('description','')} | ASN: {drop.get('org','')}",
            6.0, 'MEDIUM', 2, 2,
            link='https://www.spamhaus.org/drop/',
            patch='Block CIDR', patch_link='https://www.spamhaus.org/drop/',
            wa=f"Block CIDR {drop.get('cidr','')} at firewall", affected='Firewall/Email',
            gn='Spamhaus - CIDR range',
            mitre_t='T1566:Phishing | T1078:Valid Accounts',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Ubuntu Security ----
    for notice in ubuntu:
        all_threats.append(make_base(
            'UBUNTU_SEC', notice.get('id','N/A'),
            f"{notice.get('title','')} | {notice.get('summary','')}",
            6.5, 'MEDIUM', 2, 2,
            link=f"https://ubuntu.com/security/notices/{notice.get('id','')}",
            ts=notice.get('published',''), patch='YES', patch_link='apt-get update && apt-get upgrade',
            wa='Run: sudo apt-get update && sudo apt-get upgrade', affected='Ubuntu Linux',
            gn='Ubuntu advisory - no IP context',
            mitre_t='T1068:Exploitation for Privilege Escalation',
            exploit_status='CHECK_USN', fix_avail='YES',
            intel_url=f"https://ubuntu.com/security/notices/{notice.get('id','')}"
        ))

    # ---- Tor Exit Nodes ----
    for node in tor_nodes:
        node_ip = node.get('ip','')
        src_set = ip_source_map.get(node_ip,{'TOR'})
        all_threats.append(make_base(
            'TOR_EXIT', hashlib.md5(node_ip.encode()).hexdigest()[:12],
            f"Tor Exit Node: {node_ip} | Traffic from this IP may be anonymized/malicious",
            5.0, 'MEDIUM', 2, 1,
            link='https://check.torproject.org/', patch='Block or monitor',
            patch_link='https://check.torproject.org/torbulkexitlist',
            wa=f"Monitor traffic from Tor exit {node_ip} | Apply policy controls",
            affected='Network perimeter', gn='Tor exit node - known anonymization service',
            mitre_t='T1090.003:Multi-hop Proxy', source_count=len(src_set),
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Blocklist.de ----
    for blocked in blocklist:
        blk_ip  = blocked.get('ip','')
        src_set = ip_source_map.get(blk_ip,{'BLOCKLIST_DE'})
        auth    = list(src_set & {'TALOS','FEODO','CISA_KEV'})
        all_threats.append(make_base(
            'BLOCKLIST_DE', hashlib.md5(blk_ip.encode()).hexdigest()[:12],
            f"Blocklist.de: {blk_ip} | Attack activity reported | Sources: {', '.join(src_set)}",
            6.0, 'MEDIUM', 2, 2,
            link='https://www.blocklist.de/', patch='Block IP',
            patch_link='https://www.blocklist.de/',
            wa=f"Block IP {blk_ip} at firewall | Check SIEM for existing connections",
            affected='Firewall/Network', gn='Blocklist IP - check GreyNoise for context',
            mitre_t='T1110:Brute Force | T1190:Exploit Public-Facing Application',
            source_count=len(src_set), auth_sources=auth,
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- GreyNoise Mass Scan Threats ----
    for threat in greynoise_threats:
        all_threats.append(make_base(
            'GREYNOISE_THREAT', threat.get('ip',''),
            f"Active threat actor: {threat.get('actor','Unknown')} | Tags: {threat.get('tags','')} | Country: {threat.get('country','')}",
            7.5, 'HIGH', 3, 2,
            link=f"https://viz.greynoise.io/ip/{threat.get('ip','')}",
            ts=threat.get('last_seen',''), patch='Block IP',
            patch_link=f"https://viz.greynoise.io/ip/{threat.get('ip','')}",
            wa=f"Block IP {threat.get('ip','')} | GreyNoise confirmed malicious scanner",
            affected='Network perimeter',
            gn=f"Classification: {threat.get('classification','')} | First: {threat.get('first_seen','')} | Last: {threat.get('last_seen','')}",
            mitre_t='T1046:Network Service Discovery | T1595:Active Scanning',
            source_count=2, auth_sources=['GREYNOISE'],
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- GreyNoise RIOT (Benign) ----
    for benign in greynoise_benign:
        all_threats.append(make_base(
            'GREYNOISE_BENIGN', benign.get('ip',''),
            f"Benign service: {benign.get('name','')} | Category: {benign.get('category','')} | Whitelist candidate",
            0.0, 'LOW', 1, 1,
            link=f"https://viz.greynoise.io/ip/{benign.get('ip','')}",
            patch='Whitelist', patch_link=f"https://viz.greynoise.io/ip/{benign.get('ip','')}",
            wa='Whitelist - confirmed benign service',
            affected=benign.get('category','') or 'Trusted service',
            gn=f"RIOT: True | Category: {benign.get('category','')} | Trust: {benign.get('trust_level','')}",
            mitre_t='None - confirmed benign',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Censys Vulnerable Hosts ----
    for host in censys_vulns:
        all_threats.append(make_base(
            'CENSYS_VULN', host.get('ip',''),
            f"Vulnerable host: {host.get('ip','')} | {host.get('org','Unknown')} | CVEs: {host.get('cves','See Censys')}",
            7.0, 'HIGH', 2, 2,
            link=f"https://search.censys.io/hosts/{host.get('ip','')}",
            patch='CHECK_VENDOR', patch_link=f"https://search.censys.io/hosts/{host.get('ip','')}",
            wa=f"Patch vulnerable services on {host.get('ip','')} | Restrict access",
            affected=host.get('org','Unknown'), gn='Check GreyNoise for IP context',
            mitre_t='T1190:Exploit Public-Facing Application | T1046:Network Service Discovery',
            exploit_status='CHECK_CENSYS', fix_avail='CHECK_VENDOR',
            intel_url=f"https://search.censys.io/hosts/{host.get('ip','')}"
        ))

    # ---- Censys Exposed Services ----
    for svc in censys_exposed:
        all_threats.append(make_base(
            'CENSYS_EXPOSED', svc.get('ip',''),
            f"Exposed {svc.get('service','').upper()}: {svc.get('ip','')} | {svc.get('org','Unknown')} | Location: {svc.get('location','Unknown')}",
            6.5, 'MEDIUM', 2, 2,
            link=f"https://search.censys.io/hosts/{svc.get('ip','')}",
            patch='Restrict access', patch_link=f"https://search.censys.io/hosts/{svc.get('ip','')}",
            wa=f"Restrict {svc.get('service','').upper()} access | Firewall rule | VPN required",
            affected=svc.get('org','Unknown'), gn='Check GreyNoise for scanner activity on this IP',
            mitre_t='T1021:Remote Services | T1133:External Remote Services',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Red Hat CVEs ----
    sev_map = {'Critical':'CRITICAL','Important':'HIGH','Moderate':'MEDIUM','Low':'LOW'}
    for cve in redhat_cves:
        severity  = sev_map.get(cve.get('severity','Moderate'),'MEDIUM')
        cve_id_rh = cve.get('cve','')
        epss_data = epss_map.get(cve_id_rh,{'epss':0.0,'percentile':0.0})
        zdi_adv,atkb_s,news_str,auth_extra,src_bonus = _get_cve_enrichment(cve_id_rh)
        all_threats.append(make_base(
            'REDHAT_CVE', cve_id_rh,
            f"Red Hat Advisory: {cve.get('bugzilla','')}",
            7.0 if severity in ['HIGH','CRITICAL'] else 5.0, severity, 2, 2,
            link=f"https://access.redhat.com/security/cve/{cve_id_rh}",
            ts=cve.get('public_date',''), patch='YES',
            patch_link=f"https://access.redhat.com/security/cve/{cve_id_rh}",
            wa='Apply Red Hat patches via yum/dnf update',
            affected=cve.get('affected_release','See Red Hat advisory') or 'RHEL',
            gn='CVE advisory - no IP context',
            epss=epss_data.get('epss',0.0), epss_p=epss_data.get('percentile',0.0),
            mitre_t='T1068:Exploitation for Privilege Escalation',
            source_count=1+src_bonus, auth_sources=auth_extra,
            exploit_status='CHECK_REDHAT', fix_avail='YES',
            intel_url=f"https://access.redhat.com/security/cve/{cve_id_rh}",
            zdi_adv=zdi_adv, atkb_score=atkb_s, news=news_str
        ))

    print(f"‚úì Processed {len(all_threats)} threats (before MSRC/Windows/Patch Tuesday)")

    # ---- MSRC Updates ----
    regular_cve_ids = {v.get('cve',{}).get('id','') for v in cves}
    print(f"\nüîç DEBUG: Regular CVE IDs: {len(regular_cve_ids)} | MSRC to process: {len(msrc_updates)}")
    msrc_added = 0; msrc_skipped = 0
    for update in msrc_updates:
        if update.get('cve','') in regular_cve_ids:
            msrc_skipped += 1; continue
        msrc_added += 1
        sev  = update.get('severity','MEDIUM')
        cvss = update.get('cvss', 7.5 if sev=='HIGH' else 5.0)
        epss_d   = epss_map.get(update.get('cve',''),{'epss':0.0,'percentile':0.0})
        zdi_adv,atkb_s,news_str,auth_extra,src_bonus = _get_cve_enrichment(update.get('cve',''))
        all_threats.append(make_base(
            'MSRC_UPDATE', update.get('cve',''),
            f"Microsoft Update: {update.get('title','')[:400]}",
            cvss, sev, 2, 2,
            link=f"https://msrc.microsoft.com/update-guide/vulnerability/{update.get('cve','')}",
            ts=update.get('published',update.get('month','')), patch='YES',
            patch_link=f"https://msrc.microsoft.com/update-guide/vulnerability/{update.get('cve','')}",
            wa='Apply via Windows Update | WSUS | SCCM', affected='Microsoft Windows',
            gn='Microsoft CVE - no IP context',
            epss=epss_d.get('epss',0.0), epss_p=epss_d.get('percentile',0.0),
            mitre_t='T1203:Exploitation for Client Execution | T1068:Exploitation for Privilege Escalation',
            source_count=1+src_bonus, auth_sources=auth_extra,
            exploit_status='CHECK_MSRC', fix_avail='YES',
            intel_url=f"https://msrc.microsoft.com/update-guide/vulnerability/{update.get('cve','')}",
            zdi_adv=zdi_adv, atkb_score=atkb_s, news=news_str
        ))
    print(f"üîç DEBUG: MSRC added: {msrc_added}, skipped: {msrc_skipped}")

    # ---- Windows CVEs ----
    for wcve in windows_cves:
        cve_data = wcve.get('cve_data',{})
        score,sv = calculate_cvss_score(cve_data)
        pi       = extract_patch_info(cve_data)
        epss_d   = epss_map.get(wcve.get('cve_id',''),{'epss':0.0,'percentile':0.0})
        zdi_adv,atkb_s,news_str,auth_extra,src_bonus = _get_cve_enrichment(wcve.get('cve_id',''))
        kev_flag = 'YES' if wcve.get('cve_id','') in kev_set else 'NO'
        all_threats.append(make_base(
            'WINDOWS_CVE', wcve.get('cve_id',''), wcve.get('description',''), score, sv,
            calculate_likelihood('cve'), calculate_impact(score,'cve'),
            kev=kev_flag,
            link=f"https://nvd.nist.gov/vuln/detail/{wcve.get('cve_id','')}",
            ts=wcve.get('published',''),
            patch='YES' if pi['patch_links'] else 'Windows Update',
            patch_link=' | '.join(pi['patch_links']) if pi['patch_links'] else 'Windows Update',
            wa=' | '.join(pi['workarounds']) if pi['workarounds'] else 'Apply via Windows Update',
            affected='Microsoft Windows', gn='Windows CVE - no IP context',
            epss=epss_d.get('epss',0.0), epss_p=epss_d.get('percentile',0.0),
            mitre_t=map_cve_to_mitre(wcve.get('cve_id',''),wcve.get('description',''),[]),
            source_count=1+src_bonus, auth_sources=auth_extra,
            exploit_status='CHECK_MSRC', fix_avail='YES',
            intel_url=f"https://nvd.nist.gov/vuln/detail/{wcve.get('cve_id','')}",
            zdi_adv=zdi_adv, atkb_score=atkb_s, news=news_str
        ))

    # ---- Patch Tuesday ----
    for pt in patch_tuesday:
        all_threats.append(make_base(
            'PATCH_TUESDAY', f"PT-{pt.get('month','').replace(' ','-')}",
            f"Patch Tuesday {pt.get('month','')}: {pt.get('info','')} - Status: {pt.get('status','')}",
            0.0, 'LOW', 1, 1, link='https://msrc.microsoft.com/update-guide/',
            ts=pt.get('date',''), patch=pt.get('status',''),
            patch_link='https://msrc.microsoft.com/update-guide/',
            wa='Schedule patching cycle', affected='Microsoft Windows / Microsoft 365',
            gn='Informational - no IP context', mitre_t='Informational',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Talos IP Blacklist ----
    for tip in talos_ips:
        t_ip    = tip.get('ip','')
        gn_d    = greynoise_map.get(t_ip,{})
        src_set = ip_source_map.get(t_ip,{'TALOS'})
        also_et = '‚ö†Ô∏è ALSO in Emerging Threats' if t_ip in et_set else ''
        auth    = list(src_set & {'FEODO','CISA_KEV','GREYNOISE'}) + ['TALOS']
        all_threats.append(make_base(
            'TALOS_IP', hashlib.md5(t_ip.encode()).hexdigest()[:12],
            f"Cisco Talos Blacklisted IP: {t_ip} | Verified malicious | Sources: {', '.join(src_set)}" +
            (f" | {also_et}" if also_et else ''),
            7.0, 'HIGH', 3, 2,
            link=f"https://talosintelligence.com/reputation_center/lookup?search={t_ip}",
            patch='Block IP',
            patch_link=f"https://talosintelligence.com/reputation_center/lookup?search={t_ip}",
            wa=f"Block IP {t_ip} at firewall | Cisco Talos confirmed malicious",
            affected='Network perimeter / Email / Web', gn=gn_d.get('greynoise_context','Check GreyNoise'),
            mitre_t='T1110:Brute Force | T1190:Exploit Public-Facing Application | T1566:Phishing',
            source_count=len(src_set), auth_sources=list(set(auth)),
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Emerging Threats IPs ----
    for eip in emerging_ips:
        e_ip    = eip.get('ip','')
        gn_d    = greynoise_map.get(e_ip,{})
        src_set = ip_source_map.get(e_ip,{'EMERGING_THREATS'})
        also_t  = '‚ö†Ô∏è ALSO in Talos blacklist' if e_ip in talos_set else ''
        all_threats.append(make_base(
            'EMERGING_THREAT_IP', hashlib.md5(e_ip.encode()).hexdigest()[:12],
            f"Emerging Threats Compromised IP: {e_ip} | Sources: {', '.join(src_set)}" +
            (f" | {also_t}" if also_t else ''),
            6.5, 'HIGH', 3, 2,
            link="https://rules.emergingthreats.net/",
            patch='Block IP', patch_link="https://rules.emergingthreats.net/blockrules/compromised-ips.txt",
            wa=f"Block IP {e_ip} at firewall | Emerging Threats compromised host",
            affected='Network perimeter', gn=gn_d.get('greynoise_context','Check GreyNoise'),
            mitre_t='T1110:Brute Force | T1190:Exploit Public-Facing Application',
            source_count=len(src_set), exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- PacketStorm ----
    for item in packetstorm:
        all_threats.append(make_base(
            'PACKETSTORM', hashlib.md5(item.get('link','').encode()).hexdigest()[:12],
            f"PacketStorm: {item.get('title','')} | {item.get('summary','')[:200]}",
            7.5, 'HIGH', 3, 2,
            link=item.get('link',''), ts=item.get('published',''),
            patch='CHECK_VENDOR', patch_link=item.get('link',''),
            wa='See PacketStorm advisory for details', affected='See advisory',
            gn='Exploit advisory - no IP context',
            mitre_t='T1203:Exploitation for Client Execution | T1190:Exploit Public-Facing Application',
            exploit_status='YES', fix_avail='CHECK_VENDOR', intel_url=item.get('link','')
        ))

    # ---- VulnCheck KEV ----
    for vkev in vulncheck_kev:
        is_ransomware = vkev.get('ransomware',False)
        all_threats.append(make_base(
            'VULNCHECK_KEV', hashlib.md5(vkev.get('id','').encode()).hexdigest()[:12],
            (f"{'üîí RANSOMWARE: ' if is_ransomware else ''}VulnCheck KEV: {vkev.get('description','')[:400]} | CVEs: {vkev.get('cves','')}"),
            9.0 if is_ransomware else 7.0, 'CRITICAL' if is_ransomware else 'HIGH', 3,
            3 if is_ransomware else 2, kev='YES',
            link='https://vulncheck.com/blog/vuln-check-kev', ts=vkev.get('dateAdded',''),
            patch='URGENT - actively exploited', patch_link='https://vulncheck.com/blog/vuln-check-kev',
            wa='Patch immediately - known exploited' + (' | Ransomware active!' if is_ransomware else ''),
            affected=vkev.get('cves','') or 'See VulnCheck KEV',
            gn='KEV entry - check specific CVEs for IP context',
            mitre_t='T1486:Data Encrypted for Impact' if is_ransomware else 'T1190:Exploit Public-Facing Application',
            source_count=2, auth_sources=['VULNCHECK_KEV'],
            exploit_status='YES', fix_avail='URGENT', intel_url='https://vulncheck.com/blog/vuln-check-kev'
        ))

    # ---- CISA Ransomware ----
    for adv in cisa_ransomware:
        all_threats.append(make_base(
            'CISA_RANSOMWARE', hashlib.md5(adv.get('title','').encode()).hexdigest()[:12],
            f"üîí CISA Stop Ransomware: {adv.get('title','')} | Actors: {adv.get('actors','Unknown')}",
            9.0, 'CRITICAL', 3, 3, kev='YES',
            link='https://www.cisa.gov/stopransomware', ts=adv.get('date',''),
            patch='See advisory', patch_link='https://www.cisa.gov/stopransomware',
            wa='Follow CISA ransomware guidance | Backup critical data | Segment networks',
            affected='All sectors', gn='Ransomware advisory - check IOCs for IP context',
            mitre_t='T1486:Data Encrypted for Impact | T1490:Inhibit System Recovery | T1041:Exfiltration Over C2 Channel',
            source_count=2, auth_sources=['CISA_RANSOMWARE'],
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE'
        ))

    # ---- Firewall Vendor Advisories ----
    for fadv in firewall_advisories:
        vendor   = fadv.get('vendor','Firewall Vendor')
        sev      = fadv.get('Severity','HIGH').upper()
        sev      = sev if sev in ['CRITICAL','HIGH','MEDIUM','LOW'] else 'HIGH'
        cvss_map_v= {'CRITICAL':9.0,'HIGH':7.5,'MEDIUM':5.0,'LOW':3.0}
        cvss     = cvss_map_v.get(sev,7.5)
        l        = 3 if sev=='CRITICAL' else 2
        i        = 3 if sev=='CRITICAL' else 2
        adv_id   = fadv.get('ID',f"{vendor[:6]}-ADV")
        affected = fadv.get('Affected_Products',f"{vendor} products")
        fadv_cve = str(fadv.get('ID',''))
        fadv_zdi = zdi_cve_map.get(fadv_cve) if re.match(r'^CVE-',fadv_cve) else None
        all_threats.append(make_base(
            'FIREWALL_ADVISORY', adv_id, fadv.get('Description','')[:500],
            cvss, sev, l, i, link=fadv.get('Link',''),
            patch='YES - Apply vendor patch immediately', patch_link=fadv.get('Link',''),
            wa=f"Apply {vendor} security patches immediately | Review affected products | Check for workarounds",
            affected=affected, gn=f"Firewall Advisory - {vendor}",
            mitre_t='T1190:Exploit Public-Facing Application | T1133:External Remote Services',
            source_count=2 if sev in ['CRITICAL','HIGH'] else 1,
            auth_sources=[vendor.upper().replace(' ','_')] if sev=='CRITICAL' else [],
            exploit_status='CHECK_VENDOR', fix_avail='YES', intel_url=fadv.get('Link',''),
            zdi_adv=fadv_zdi['link'] if fadv_zdi else 'NONE'
        ))

    # ---- NEW v5.0: ZDI Published 0-Day Advisories ----
    print(f"\nüéØ Processing {len(zdi_vulns)} ZDI advisories...")
    for adv in zdi_vulns:
        primary_cve = adv['cves'][0] if adv.get('cves') else ''
        epss_data   = epss_map.get(primary_cve,{'epss':0.0,'percentile':0.0})
        atkb_info   = atkb_map.get(primary_cve,{})
        atkb_s      = atkb_info.get('atkb_score',0.0)
        news_str    = ' | '.join([f"[{n['source']}] {n['title'][:70]}" for n in news_cve_map.get(primary_cve,[])[:2]])
        auth        = ['ZDI']
        if primary_cve and primary_cve in kev_set: auth.append('CISA_KEV')
        if atkb_s >= 3: auth.append('ATTACKERKB')
        cves_str = ', '.join(adv.get('cves',[adv['id']]))
        all_threats.append(make_base(
            'ZDI_ADVISORY', adv['id'],
            f"ZDI Published 0-Day: {adv['title']} | CVEs: {cves_str} | Product: {adv.get('product','')}",
            adv.get('cvss',7.5), adv.get('severity','HIGH'), 3, 3,
            kev='YES' if (primary_cve and primary_cve in kev_set) else 'NO',
            link=adv.get('link',''), ts=adv.get('published',''),
            patch='CHECK_VENDOR - ZDI published, vendor patch may be pending',
            patch_link=adv.get('link',''),
            wa=f"ZDI-published 0-day: apply vendor patch IMMEDIATELY | CVEs: {cves_str}",
            affected=adv.get('product','See ZDI advisory'),
            gn='ZDI 0-day advisory - no IP context',
            epss=epss_data.get('epss',0.0), epss_p=epss_data.get('percentile',0.0),
            mitre_t=map_cve_to_mitre(primary_cve,adv.get('title',''),[]) if primary_cve else 'T1190:Exploit Public-Facing Application',
            source_count=len(auth)+1, auth_sources=auth,
            exploit_status='YES', fix_avail='CHECK_VENDOR',
            intel_url=f"https://security.snyk.io/vuln/{primary_cve}" if primary_cve else adv.get('link',''),
            zdi_adv=adv.get('link',''), atkb_score=atkb_s, news=news_str
        ))

    # ---- NEW v5.0: SANS ISC Diary ----
    print(f"\nüì° Processing {len(sans_isc)} SANS ISC diary entries...")
    for item in sans_isc:
        cves_str = ', '.join(item.get('cves',[]))
        all_threats.append(make_base(
            'SANS_ISC', hashlib.md5(item.get('link','').encode()).hexdigest()[:12],
            f"SANS ISC: {item.get('title','')} | {item.get('summary','')[:200]}",
            7.0, 'HIGH', 3, 2,
            link=item.get('link',''), ts=item.get('published',''),
            patch='CHECK_VENDOR', patch_link=item.get('link',''),
            wa='See SANS ISC diary for indicators and mitigations | Check IOCs',
            affected=cves_str or 'See SANS ISC diary',
            gn='SANS ISC analysis - no direct IP context',
            mitre_t='T1190:Exploit Public-Facing Application',
            exploit_status='YES' if item.get('cves') else 'CHECK_SANS',
            fix_avail='CHECK_VENDOR', intel_url=item.get('link',''),
            news=item.get('title','')
        ))

    # ---- NEW v5.0: Security News Alerts (CVE-less only) ----
    print(f"\nüì∞ Processing {len(news_kw_list)} keyword-only security news alerts...")
    for news_item in news_kw_list:
        kw_str = ', '.join(news_item.get('keywords',[]))
        all_threats.append(make_base(
            'NEWS_ALERT', hashlib.md5(news_item.get('link','').encode()).hexdigest()[:12],
            f"[{news_item.get('source','')}] {news_item.get('title','')} | Keywords: {kw_str} | {news_item.get('summary','')[:150]}",
            5.0, 'MEDIUM', 2, 1,
            link=news_item.get('link',''), ts=news_item.get('published',''),
            patch='Monitor', patch_link=news_item.get('link',''),
            wa='Monitor for developments | Review article for IOCs | Escalate if relevant to your infra',
            affected='Varies - see article', gn='News alert - no IP context',
            mitre_t='See article for technique context',
            exploit_status='NONE', fix_avail='NONE', intel_url='NONE', news=news_item.get('title','')
        ))

    # ---- NEW v5.0: Cross-source CVE deduplication ----
    print(f"\nüîó Cross-source CVE deduplication ({len(all_threats)} threats pre-dedup)...")
    CVE_TYPES = {'CVE','REDHAT_CVE','WINDOWS_CVE','MSRC_UPDATE','ZDI_ADVISORY'}
    cve_primary_idx = {}
    threats_deduped = []
    for threat in all_threats:
        tid   = str(threat.get('ID',''))
        ttype = threat.get('Type','')
        is_cve_row = re.match(r'^CVE-\d{4}-\d+$',tid) and ttype in CVE_TYPES
        if is_cve_row and tid in cve_primary_idx:
            idx      = cve_primary_idx[tid]
            existing = threats_deduped[idx]
            new_sc   = existing.get('Source_Count',1) + 1
            existing['Source_Count'] = new_sc
            existing['Final_Score']  = max(existing.get('Final_Score',0), threat.get('Final_Score',0))
            if threat.get('ZDI_Advisory','N/A') not in ['N/A','']:
                existing['ZDI_Advisory'] = threat['ZDI_Advisory']
            if float(threat.get('AttackerKB_Score',0) or 0) > float(existing.get('AttackerKB_Score',0) or 0):
                existing['AttackerKB_Score'] = threat['AttackerKB_Score']
            if threat.get('News_Coverage','') and not existing.get('News_Coverage',''):
                existing['News_Coverage'] = threat['News_Coverage']
            cl,cp = calculate_confidence(new_sc,[],existing.get('Type',''))
            existing['Confidence_Score']     = f"{cl} ({cp}%)"
            existing['Remediation_Priority'] = calculate_remediation_priority(existing)
        else:
            if is_cve_row:
                cve_primary_idx[tid] = len(threats_deduped)
            threats_deduped.append(threat)
    removed = len(all_threats) - len(threats_deduped)
    print(f"  ‚úì Deduplication complete: {len(threats_deduped)} unique threats ({removed} duplicates merged)")

    # ---- v5.7 NEW: Multi-source enrichment accuracy pass ----
    # CVEs confirmed across 3+ independent intel feeds get forced confidence upgrades.
    # CVEs seen in SANS ISC AND 2+ news articles get exploit_status escalated.
    print("\nüéØ v5.7 Multi-source accuracy validation pass...")
    news_cve_counts = {}
    for item in security_news:
        for cid in item.get("cves", []):
            news_cve_counts[cid] = news_cve_counts.get(cid, 0) + 1
    sans_isc_cves = set()
    for item in sans_isc:
        for cid in item.get("cves", []):
            sans_isc_cves.add(cid)
    upgraded = 0
    for threat in threats_deduped:
        tid   = str(threat.get("ID", ""))
        sc    = int(threat.get("Source_Count", 1) or 1)
        # Multi-source confidence boosting
        if re.match(r"^CVE-\d{4}-\d+$", tid):
            news_cnt = news_cve_counts.get(tid, 0)
            in_sans  = tid in sans_isc_cves
            # Force confidence based on corroborating sources
            if sc >= 5:
                threat["Confidence_Score"] = "CRITICAL (95%)"
                upgraded += 1
            elif sc >= 3:
                if "CRITICAL" not in threat.get("Confidence_Score",""):
                    threat["Confidence_Score"] = "HIGH (85%)"
                    upgraded += 1
            # SANS ISC + 2+ news mentions ‚Üí escalate exploit status
            if in_sans and news_cnt >= 2:
                if threat.get("Exploit_Status","") == "POSSIBLE":
                    threat["Exploit_Status"] = "HIGH"
                    upgraded += 1
            # 3+ news articles alone ‚Üí boost if still UNLIKELY
            if news_cnt >= 3 and threat.get("Exploit_Status","") == "UNLIKELY":
                threat["Exploit_Status"] = "POSSIBLE"
                upgraded += 1
    print(f"  ‚úì Accuracy pass: {upgraded} threats upgraded (confidence/exploit_status)")
    return threats_deduped

# ============= ALERT GENERATION =============
def create_threat_alert(threats):
    """
    v5.2: Alert now includes THREAT TYPE BREAKDOWN section showing counts
    of each threat type (column A categories) in the current batch.
    Makes it easy to see at a glance what the feed is pulling in.
    """
    now_str    = datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M')
    total      = len(threats)
    critical   = sum(1 for t in threats if t.get('Risk_Level','') == 'CRITICAL')
    high       = sum(1 for t in threats if t.get('Risk_Level','') == 'HIGH')
    p1_count   = sum(1 for t in threats if t.get('Remediation_Priority','') == 'P1')
    kev_count  = sum(1 for t in threats if t.get('CISA_KEV','') == 'YES')
    zdi_count  = sum(1 for t in threats if t.get('ZDI_Advisory','NONE') not in ['NONE','N/A',''])
    news_count = sum(1 for t in threats if t.get('News_Coverage',''))
    atkb_high  = sum(1 for t in threats if float(t.get('AttackerKB_Score',0) or 0) >= 3)

    # v5.2 NEW: type breakdown ‚Äî count per Type value (column A)
    type_counts = defaultdict(int)
    for t in threats:
        type_counts[t.get('Type','UNKNOWN')] += 1
    # Sort by count descending
    sorted_types = sorted(type_counts.items(), key=lambda x: -x[1])

    sorted_threats = sorted(threats, key=lambda x: (
        x.get('Remediation_Priority','P4'),
        -float(x.get('EPSS_Percentile',0) or 0),
        {'CRITICAL':4,'HIGH':3,'MEDIUM':2,'LOW':1}.get(x.get('Risk_Level','LOW'),1)
    ))[:10]

    emoji_map = {
        'CVE':              'üîç','EXPLOIT':         'üí•','MALWARE':         'ü¶†',
        'GH_ADVISORY':      'üêô','MAL_URL':         'üîó','PHISH':           'üé£',
        'THREATFOX_IOC':    'ü¶ä','OSV_VULN':        'üîì','FEODO_C2':        'ü§ñ',
        'ABUSE_IP':         'üö´','TALOS_IP':        'ü¶Ö','GREYNOISE_THREAT':'ü¶Ö',
        'CENSYS_VULN':      'üåê','WINDOWS_CVE':     'ü™ü','MSRC_UPDATE':     'ü™ü',
        'REDHAT_CVE':       'üé©','CISA_ICS':        'üè≠','CISA_RANSOMWARE': 'üîí',
        'VULNCHECK_KEV':    '‚úÖ','PACKETSTORM':     'üì¶','EMERGING_THREAT_IP':'üî•',
        'BLOCKLIST_DE':     'üîí','FIREHOL_THREAT':   'üõë','TOR_EXIT':        'üßÖ',
        'DATA_BREACH':      'üíî','OTX_PULSE':       'üëΩ','MITRE_ATTACK':    '‚öîÔ∏è',
        'UBUNTU_SEC':       'üêß','VULNERS':         'üîç','SHODAN_VULN':     'üì°',
        'FIREWALL_ADVISORY':'üõ°Ô∏è','ZDI_ADVISORY':    'üéØ','SANS_ISC':        'üì°',
        'NEWS_ALERT':       'üì∞','THREATMINER':     '‚õèÔ∏è','WINDOWS_CVE':     'ü™ü',
    }

    msg = ["‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
           "üê∫ ANUBIS THREATHUNTER v6.0",
           "üëë PharaonX RedTeam | Ramiz Alsafi",
           "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
           f"‚è∞ {now_str}",
           f"üìä NEW THREATS: {total}",
           f"üî¥ CRITICAL: {critical} | üü† HIGH: {high}",
           f"üö® P1 (Urgent): {p1_count}",
           f"‚ö†Ô∏è  CISA KEV: {kev_count} | üéØ ZDI 0-days: {zdi_count}",
           f"‚öîÔ∏è  AttackerKB High: {atkb_high} | üì∞ In News: {news_count}",
           "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
           "üìÇ THREAT TYPE BREAKDOWN:",
           "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]

    # Add each type with its emoji + count
    for ttype, count in sorted_types:
        type_emoji = emoji_map.get(ttype, '‚ö†Ô∏è')
        # Count P1 threats in this type
        p1_in_type = sum(1 for t in threats if t.get('Type') == ttype and t.get('Remediation_Priority') == 'P1')
        kev_in_type = sum(1 for t in threats if t.get('Type') == ttype and t.get('CISA_KEV') == 'YES')
        flags = []
        if p1_in_type: flags.append(f"üö®{p1_in_type}P1")
        if kev_in_type: flags.append(f"‚ö†Ô∏è{kev_in_type}KEV")
        flags_str = ' '.join(flags)
        msg.append(f"  {type_emoji} {ttype:<22} {count:>4}  {flags_str}".rstrip())

    msg += ["‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üèÜ TOP PRIORITY THREATS:",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]

    for i,t in enumerate(sorted_threats, 1):
        emoji    = emoji_map.get(t.get('Type',''),'‚ö†Ô∏è')
        tid      = str(t.get('ID',''))[:30]
        risk     = t.get('Risk_Level','?')
        prio     = t.get('Remediation_Priority','P4')
        sev_e    = get_severity_emoji(risk)
        kev_flag = 'üö®KEV' if t.get('CISA_KEV','') == 'YES' else ''
        zdi_flag = 'üéØZDI' if t.get('ZDI_Advisory','NONE') not in ['NONE','N/A',''] else ''
        epss_v   = float(t.get('EPSS_Percentile',0) or 0)
        epss_str = f"EPSS:{epss_v:.0%}" if epss_v > 0 else ''
        atkb_v   = float(t.get('AttackerKB_Score',0) or 0)
        atkb_str = f"ATKB:{atkb_v:.1f}" if atkb_v > 0 else ''
        flags    = ' '.join(filter(None,[kev_flag,zdi_flag,epss_str,atkb_str]))
        ttype_label = t.get('Type','')
        msg.append(f"{i}. {emoji} {ttype_label} [{prio}] {sev_e} {risk}")
        msg.append(f"   ID: {tid}")
        if flags: msg.append(f"   {flags}")
        desc = str(t.get('Description',''))[:100].replace('\n',' ')
        msg.append(f"   {desc}...")

    msg += ["‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üìé ATTACHMENTS:",
            f"  üìä threat_intelligence_log.xlsx ‚Äî Full database with Dashboard + PowerBI sheets",
            f"  üåê anubis_threat_dashboard.html ‚Äî Interactive browser dashboard",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üåê INTERACTIVE DASHBOARD:",
            "  Open the attached .html file in any browser for live charts:",
            "  ‚Ä¢ Risk Level distribution bar chart",
            "  ‚Ä¢ Top threat type doughnut chart",
            "  ‚Ä¢ EPSS score histogram",
            "  ‚Ä¢ P1/KEV/ZDI priority breakdown",
            "  ‚Ä¢ Searchable full threat table (first 200 rows)",
            "  Tip: Save the file locally and double-click to open",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üîÆ EPSS + AttackerKB CVE prioritization active",
            "üéØ ZDI 0-day advisory tracking active",
            "üì° SANS ISC + Security News correlation active",
            "üõ°Ô∏è 14 Firewall Vendors monitored",
            "üîó Cross-source deduplication + confidence scoring active",
            "üê∫ Guardian of the Digital Afterlife",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"]
    return "\n".join(msg)


# ============= EXCEL FORMATTING: AUTOFILTER + DASHBOARD =============
def _add_dashboard_charts(wb, dash, ws, data_row_start, n_types, total_row):
    """v5.6 OVERHAUL ‚Äî three polished charts + risk matrix formula table:
      1. Column Bar   ‚Äî Threats by Risk Level, colour-coded bars + axis labels
      2. Doughnut     ‚Äî Top 8 threat types with % labels (replaces plain pie)
      3. Risk Heatmap ‚Äî 3√ó3 Likelihood√óImpact grid, enlarged cells, COUNTIFS live
      4. Risk Matrix  ‚Äî Formula table: L√óI = Risk Score with zone labels
    Charts use hidden data tables in cols J-L for clean references.
    """
    from openpyxl.chart import BarChart, PieChart, DoughnutChart, Reference
    from openpyxl.chart.label import DataLabelList
    from openpyxl.chart.data_source import NumDataSource, NumRef
    from openpyxl.chart.series import SeriesLabel
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
    from openpyxl.utils import get_column_letter

    TI = "'Threat Intelligence'"   # sheet reference with single quotes for spaces

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # HIDDEN DATA TABLES  (cols J-L, tucked to right of type summary)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ‚îÄ‚îÄ Risk Level table: J2:K6 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    risk_labels  = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']
    risk_bar_hex = ['C0392B',   'E67E22', 'F1C40F', '27AE60']

    def _hdr(cell, txt, bg='E94560'):
        cell.value     = txt
        cell.font      = Font(bold=True, color='FFFFFF', size=9)
        cell.fill      = PatternFill('solid', fgColor=bg)
        cell.alignment = Alignment(horizontal='center', vertical='center')

    def _data(cell, val, fg='CCCCCC', bg='0F0F1A'):
        cell.value     = val
        cell.font      = Font(color=fg, size=9)
        cell.fill      = PatternFill('solid', fgColor=bg)
        cell.alignment = Alignment(horizontal='center', vertical='center')

    _hdr(dash['J2'], 'Risk Level')
    _hdr(dash['K2'], 'Count')
    for i, (lbl, hex_) in enumerate(zip(risk_labels, risk_bar_hex), start=3):
        dash[f'J{i}'].value     = lbl
        dash[f'J{i}'].font      = Font(bold=True, color='FFFFFF', size=9)
        dash[f'J{i}'].fill      = PatternFill('solid', fgColor=hex_)
        dash[f'J{i}'].alignment = Alignment(horizontal='center', vertical='center')
        dash[f'K{i}'].value     = f'=COUNTIF({TI}!$H:$H,"{lbl}")'
        dash[f'K{i}'].font      = Font(color='FFFFFF', size=9)
        dash[f'K{i}'].fill      = PatternFill('solid', fgColor='1A1A2E')
        dash[f'K{i}'].alignment = Alignment(horizontal='center')

    # Priority breakdown: J7:K11
    _hdr(dash['J7'], 'Priority')
    _hdr(dash['K7'], 'Count')
    prios = [('P1 URGENT','E94560'), ('P2 HIGH','E67E22'), ('P3 MED','3498DB'), ('P4 LOW','27AE60')]
    for i, (lbl, hex_) in enumerate(zip(['P1','P2','P3','P4'], ['E94560','E67E22','3498DB','27AE60']), start=8):
        dash[f'J{i}'].value     = lbl
        dash[f'J{i}'].font      = Font(bold=True, color='FFFFFF', size=9)
        dash[f'J{i}'].fill      = PatternFill('solid', fgColor=hex_)
        dash[f'J{i}'].alignment = Alignment(horizontal='center')
        dash[f'K{i}'].value     = f'=COUNTIF({TI}!$Q:$Q,"{lbl}")'
        dash[f'K{i}'].font      = Font(color='FFFFFF', size=9)
        dash[f'K{i}'].fill      = PatternFill('solid', fgColor='1A1A2E')
        dash[f'K{i}'].alignment = Alignment(horizontal='center')

    # Top-8 types for doughnut: J13:K21
    _hdr(dash['J12'], 'Threat Type')
    _hdr(dash['K12'], 'Count')
    pie_n = min(n_types, 8)
    for i in range(pie_n):
        r     = data_row_start + i
        pie_r = 13 + i
        dash[f'J{pie_r}'].value     = f'=A{r}'
        dash[f'J{pie_r}'].font      = Font(color='CCCCCC', size=9)
        dash[f'J{pie_r}'].fill      = PatternFill('solid', fgColor='111122')
        dash[f'J{pie_r}'].alignment = Alignment(horizontal='left')
        dash[f'K{pie_r}'].value     = f'=B{r}'
        dash[f'K{pie_r}'].font      = Font(color='CCCCCC', size=9)
        dash[f'K{pie_r}'].fill      = PatternFill('solid', fgColor='111122')
        dash[f'K{pie_r}'].alignment = Alignment(horizontal='center')

    # Column widths for data area
    for col, w in [('J', 22), ('K', 10), ('L', 10)]:
        dash.column_dimensions[col].width = w

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CHART 1 ‚Äî Vertical Bar: Risk Level Distribution  (anchor: M2)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    bar = BarChart()
    bar.type      = "col"
    bar.title     = "Threats by Risk Level"
    bar.style     = 2
    bar.width     = 14
    bar.height    = 9
    bar.grouping  = "clustered"
    bar.overlap   = 0

    bar_vals = Reference(dash, min_col=11, min_row=2, max_row=6)   # K2:K6 (header+4 rows)
    bar_cats = Reference(dash, min_col=10, min_row=3, max_row=6)   # J3:J6 (labels)
    bar.add_data(bar_vals, titles_from_data=True)
    bar.set_categories(bar_cats)

    # Per-series colour overrides
    series = bar.series[0]
    from openpyxl.chart.data_source import NumDataSource, NumRef
    from openpyxl.drawing.fill import PatternFillProperties
    # Colour each bar individually via dataPoints
    from openpyxl.chart.series import DataPoint
    bar_colors = ['C0392B', 'E67E22', 'F1C40F', '27AE60']
    for idx, color in enumerate(bar_colors):
        pt = DataPoint(idx=idx)
        pt.graphicalProperties.solidFill = color
        pt.graphicalProperties.line.solidFill = color
        bar.series[0].dPt.append(pt)

    # Axis labels
    bar.y_axis.title    = "Count"
    bar.x_axis.title    = "Risk Level"
    bar.y_axis.numFmt   = '0'
    bar.y_axis.majorGridlines = None
    bar.legend = None

    # Data labels on bars
    from openpyxl.chart.label import DataLabelList
    bar.series[0].dLbls = DataLabelList()
    bar.series[0].dLbls.showVal  = True
    bar.series[0].dLbls.showCatNm = False
    bar.series[0].dLbls.showSerNm = False
    bar.series[0].dLbls.position  = 'outEnd'

    dash.add_chart(bar, "M2")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CHART 1b ‚Äî Stacked Bar: Priority Breakdown  (anchor: M13)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    pbar = BarChart()
    pbar.type      = "col"
    pbar.title     = "Threats by Priority"
    pbar.style     = 2
    pbar.width     = 14
    pbar.height    = 8
    pbar.grouping  = "clustered"

    pbar_vals = Reference(dash, min_col=11, min_row=7, max_row=11)
    pbar_cats = Reference(dash, min_col=10, min_row=8, max_row=11)
    pbar.add_data(pbar_vals, titles_from_data=True)
    pbar.set_categories(pbar_cats)

    pbar_colors = ['E94560', 'E67E22', '3498DB', '27AE60']
    for idx, color in enumerate(pbar_colors):
        pt = DataPoint(idx=idx)
        pt.graphicalProperties.solidFill = color
        pt.graphicalProperties.line.solidFill = color
        pbar.series[0].dPt.append(pt)

    pbar.y_axis.title = "Count"
    pbar.y_axis.numFmt = '0'
    pbar.y_axis.majorGridlines = None
    pbar.legend = None
    pbar.series[0].dLbls = DataLabelList()
    pbar.series[0].dLbls.showVal = True
    pbar.series[0].dLbls.showSerNm = False
    pbar.series[0].dLbls.showCatNm = False
    # v5.10 FIX: 'outEnd' clips labels on short bars and overlaps on long ones.
    # 'ctr' (center) keeps labels inside the bar ‚Äî always readable, never clipped.
    pbar.series[0].dLbls.position = 'ctr'

    dash.add_chart(pbar, "M13")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # CHART 2 ‚Äî Doughnut: Threat Type Distribution  (anchor: V2)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    donut = DoughnutChart()
    donut.title   = "Threat Type Distribution (Top 8)"
    donut.style   = 10
    donut.width   = 16
    donut.height  = 18
    donut.holeSize = 40

    donut_vals = Reference(dash, min_col=11, min_row=12, max_row=12 + pie_n)
    donut_cats = Reference(dash, min_col=10, min_row=13, max_row=12 + pie_n)
    donut.add_data(donut_vals, titles_from_data=True)
    donut.set_categories(donut_cats)

    donut.series[0].dLbls = DataLabelList()
    donut.series[0].dLbls.showVal     = False   # v5.10 FIX: val + % + name = 3 labels per slice = overlap
    donut.series[0].dLbls.showPercent = True    # percentage only ‚Äî clean and readable
    donut.series[0].dLbls.showCatNm   = False   # use legend instead of inline labels
    donut.series[0].dLbls.showSerNm   = False

    donut_palette = ['E94560','3498DB','E67E22','9B59B6',
                     '1ABC9C','F39C12','2ECC71','E74C3C']
    for idx, color in enumerate(donut_palette[:pie_n]):
        pt = DataPoint(idx=idx)
        pt.graphicalProperties.solidFill = color
        pt.graphicalProperties.line.solidFill = '1A1A2E'
        donut.series[0].dPt.append(pt)

    dash.add_chart(donut, "V2")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # RISK HEATMAP TABLE  (below type summary, starting at total_row + 3)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    hm_row = total_row + 3
    hm_col = 1     # col A ‚Äî left side of dashboard, below summary

    # Section title ‚Äî v5.9 FIX: was end_column=hm_col+7 (cols 1-8),
    # which overlapped with risk matrix title merge starting at mx_col=hm_col+5=col6.
    # Merged slave cells are read-only ‚Üí AttributeError on second title write.
    # Fix: shrink to hm_col+3 (cols 1-4), exactly the heatmap data width. No overlap.
    dash.merge_cells(start_row=hm_row-1, start_column=hm_col,
                     end_row=hm_row-1,   end_column=hm_col+3)
    tc = dash.cell(row=hm_row-1, column=hm_col)
    tc.value     = "üî•  RISK HEATMAP  ‚îÄ  Likelihood √ó Impact"
    tc.font      = Font(bold=True, color='E94560', size=12)
    tc.fill      = PatternFill('solid', fgColor='1A1A2E')
    tc.alignment = Alignment(horizontal='center')
    dash.row_dimensions[hm_row-1].height = 22

    # Column headers: Impact Low / Med / High
    impact_lbls = ['Low Impact (1)', 'Med Impact (2)', 'High Impact (3)']
    corner = dash.cell(row=hm_row, column=hm_col)
    corner.value     = 'Likelihood / Impact'
    corner.font      = Font(bold=True, color='FFFFFF', size=9)
    corner.fill      = PatternFill('solid', fgColor='E94560')
    corner.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
    dash.column_dimensions[get_column_letter(hm_col)].width = 22
    dash.row_dimensions[hm_row].height = 30

    for ci, lbl in enumerate(impact_lbls, start=1):
        c = dash.cell(row=hm_row, column=hm_col+ci)
        c.value     = lbl
        c.font      = Font(bold=True, color='FFFFFF', size=10)
        c.fill      = PatternFill('solid', fgColor='2C3E50')
        c.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
        dash.column_dimensions[get_column_letter(hm_col+ci)].width = 20
        dash.row_dimensions[hm_row].height = 30

    hm_colors = {
        (1,1): ('1A5276','LOW',    'üü¢'),
        (1,2): ('1A5276','LOW',    'üü¢'),
        (1,3): ('7D6608','MEDIUM', 'üü°'),
        (2,1): ('1A5276','LOW',    'üü¢'),
        (2,2): ('7D6608','MEDIUM', 'üü°'),
        (2,3): ('784212','HIGH',   'üü†'),
        (3,1): ('7D6608','MEDIUM', 'üü°'),
        (3,2): ('784212','HIGH',   'üü†'),
        (3,3): ('7B241C','CRITICAL','üî¥'),
    }
    like_lbls = ['Low Likelihood (1)', 'Med Likelihood (2)', 'High Likelihood (3)']

    for ri, like_lbl in enumerate(like_lbls, start=1):
        row_label = dash.cell(row=hm_row+ri, column=hm_col)
        row_label.value     = like_lbl
        row_label.font      = Font(bold=True, color='FFFFFF', size=9)
        row_label.fill      = PatternFill('solid', fgColor='2C3E50')
        row_label.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
        dash.row_dimensions[hm_row+ri].height = 38

        for ci in range(1, 4):
            bg, zone, emoji = hm_colors[(ri, ci)]
            c = dash.cell(row=hm_row+ri, column=hm_col+ci)
            c.value = (
                f"=COUNTIFS({TI}!$F:$F,{ri},{TI}!$G:$G,{ci})"
            )
            c.number_format = '0'
            c.font      = Font(bold=True, color='FFFFFF', size=14)
            c.fill      = PatternFill('solid', fgColor=bg)
            c.alignment = Alignment(horizontal='center', vertical='center')
            c.border    = Border(
                top=Side(style='medium', color='0A0A14'),
                bottom=Side(style='medium', color='0A0A14'),
                left=Side(style='medium',  color='0A0A14'),
                right=Side(style='medium', color='0A0A14'),
            )

    # Zone legend row
    leg_row = hm_row + 5
    legend_items = [('üü¢ LOW','1A5276'), ('üü° MEDIUM','7D6608'),
                    ('üü† HIGH','784212'), ('üî¥ CRITICAL','7B241C')]
    for ci, (lbl, bg) in enumerate(legend_items):
        c = dash.cell(row=leg_row, column=hm_col+ci)
        c.value     = lbl
        c.font      = Font(bold=True, color='FFFFFF', size=9)
        c.fill      = PatternFill('solid', fgColor=bg)
        c.alignment = Alignment(horizontal='center')

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # RISK MATRIX FORMULA TABLE  (right of heatmap, same row band)
    # Cols E-H: shows Risk = Likelihood √ó Impact formula with zone colours
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    mx_col = hm_col + 5   # col F onwards

    # Title
    dash.merge_cells(start_row=hm_row-1, start_column=mx_col,
                     end_row=hm_row-1,   end_column=mx_col+4)
    mt = dash.cell(row=hm_row-1, column=mx_col)
    mt.value     = "üìê  RISK MATRIX  ‚îÄ  Score = Likelihood √ó Impact"
    mt.font      = Font(bold=True, color='E94560', size=12)
    mt.fill      = PatternFill('solid', fgColor='1A1A2E')
    mt.alignment = Alignment(horizontal='center')

    # Header row
    for ci, lbl in enumerate(['', 'Impact 1', 'Impact 2', 'Impact 3', 'Zone'], start=mx_col):
        c = dash.cell(row=hm_row, column=ci)
        c.value     = lbl
        c.font      = Font(bold=True, color='FFFFFF', size=9)
        c.fill      = PatternFill('solid', fgColor='2C3E50')
        c.alignment = Alignment(horizontal='center')

    risk_matrix = {
        (1,1):(1,'LOW'),    (1,2):(2,'LOW'),    (1,3):(3,'MEDIUM'),
        (2,1):(2,'LOW'),    (2,2):(4,'MEDIUM'),  (2,3):(6,'HIGH'),
        (3,1):(3,'MEDIUM'), (3,2):(6,'HIGH'),    (3,3):(9,'CRITICAL'),
    }
    mx_colors = {'LOW':'1A5276','MEDIUM':'7D6608','HIGH':'784212','CRITICAL':'7B241C'}
    mx_like_lbls = ['L=1 (Low)', 'L=2 (Med)', 'L=3 (High)']

    for ri, like_lbl in enumerate(mx_like_lbls, start=1):
        # Row label
        rl = dash.cell(row=hm_row+ri, column=mx_col)
        rl.value     = like_lbl
        rl.font      = Font(bold=True, color='FFFFFF', size=9)
        rl.fill      = PatternFill('solid', fgColor='2C3E50')
        rl.alignment = Alignment(horizontal='center')
        dash.column_dimensions[get_column_letter(mx_col)].width = 14

        for ci in range(1, 4):
            score, zone = risk_matrix[(ri, ci)]
            bg = mx_colors[zone]
            c  = dash.cell(row=hm_row+ri, column=mx_col+ci)
            c.value     = f"L{ri}√óI{ci}={score}  ({zone})"
            c.font      = Font(bold=True, color='FFFFFF', size=9)
            c.fill      = PatternFill('solid', fgColor=bg)
            c.alignment = Alignment(horizontal='center', vertical='center', wrap_text=True)
            c.border    = Border(
                top=Side(style='thin', color='0A0A14'),
                bottom=Side(style='thin', color='0A0A14'),
                left=Side(style='thin',  color='0A0A14'),
                right=Side(style='thin', color='0A0A14'),
            )
            dash.column_dimensions[get_column_letter(mx_col+ci)].width = 16

        # Zone label column
        zone_at_max = risk_matrix[(ri,3)][1]
        zc = dash.cell(row=hm_row+ri, column=mx_col+4)
        zc.value     = zone_at_max
        zc.font      = Font(bold=True, color='FFFFFF', size=9)
        zc.fill      = PatternFill('solid', fgColor=mx_colors[zone_at_max])
        zc.alignment = Alignment(horizontal='center')
        dash.column_dimensions[get_column_letter(mx_col+4)].width = 12

    # Formula legend below matrix
    fm_row = hm_row + 5
    dash.merge_cells(start_row=fm_row, start_column=mx_col,
                     end_row=fm_row,   end_column=mx_col+4)
    fl = dash.cell(row=fm_row, column=mx_col)
    fl.value     = "Risk Score = Likelihood (1-3) √ó Impact (1-3)  ‚Üí  Max 9 = CRITICAL"
    fl.font      = Font(italic=True, color='AAAAAA', size=8)
    fl.fill      = PatternFill('solid', fgColor='111122')
    fl.alignment = Alignment(horizontal='center')



def apply_excel_formatting(excel_path):
    """
    v5.2 NEW:
    1. Adds AutoFilter to the main data sheet header row (click dropdowns to filter
       by Type, Severity, Priority, KEV status ‚Äî any column)
    2. Creates a 'üìä Dashboard' sheet with a dynamic threat-type summary table
       showing Total / P1 / P2 / KEV counts per threat type, colour-coded by category
    3. Freezes header row so it stays visible while scrolling
    4. Sets column widths for readability
    """
    from openpyxl import load_workbook
    from openpyxl.styles import (Font, PatternFill, Alignment, Border, Side,
                                  GradientFill)
    from openpyxl.utils import get_column_letter
    from openpyxl.worksheet.filters import AutoFilter

    print("\nüìä Applying Excel formatting (AutoFilter + Dashboard)...")

    wb = load_workbook(excel_path)
    ws = wb.active
    ws.title = "Threat Intelligence"

    # ‚îÄ‚îÄ 1. AutoFilter on entire data range ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ws.auto_filter.ref = ws.dimensions
    print("  ‚úì AutoFilter applied to all columns")

    # ‚îÄ‚îÄ 2. Freeze header row ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    ws.freeze_panes = "A2"

    # ‚îÄ‚îÄ 3. Style header row ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    header_fill   = PatternFill("solid", fgColor="1A1A2E")   # dark navy
    header_font   = Font(bold=True, color="E94560", size=10)  # red text
    center_align  = Alignment(horizontal="center", vertical="center", wrap_text=False)
    thin_border   = Border(
        bottom=Side(style="thin", color="E94560"),
    )
    for cell in ws[1]:
        cell.fill      = header_fill
        cell.font      = header_font
        cell.alignment = center_align
        cell.border    = thin_border

    # ‚îÄ‚îÄ 4. Column widths ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    col_widths = {
        'A': 20,   # Type
        'B': 22,   # ID
        'C': 55,   # Description
        'D': 7,    # CVSS
        'E': 11,   # Severity
        'F': 11,   # Likelihood
        'G': 8,    # Impact
        'H': 12,   # Risk_Level
        'I': 12,   # Final_Score
        'J': 10,   # CISA_KEV
        'K': 35,   # Link
        'L': 18,   # Timestamp
        'M': 16,   # Patch_Available
        'N': 40,   # Patch_Links
        'O': 40,   # Workarounds
        'P': 35,   # Affected_Products
        'Q': 22,   # Remediation_Priority
        'R': 55,   # Remediation_Steps
        'S': 35,   # GreyNoise_Context
        'T': 22,   # Exploit_Status
        'U': 15,   # Fix_Available
        'V': 40,   # Intel_URL
        'W': 12,   # EPSS_Score
        'X': 16,   # EPSS_Percentile
        'Y': 55,   # MITRE_Techniques
        'Z': 13,   # Source_Count
        'AA': 20,  # Confidence_Score
        'AB': 40,  # ZDI_Advisory
        'AC': 17,  # AttackerKB_Score
        'AD': 60,  # News_Coverage
    }
    for col_letter, width in col_widths.items():
        ws.column_dimensions[col_letter].width = width

    # ‚îÄ‚îÄ 5. Alternate row shading on data rows ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    fill_dark  = PatternFill("solid", fgColor="0F0F1A")
    fill_light = PatternFill("solid", fgColor="1A1A2E")
    sev_colors = {
        'CRITICAL': "8B0000",
        'HIGH':     "8B4000",
        'MEDIUM':   "4A4000",
        'LOW':      "1A3A1A",
    }
    for row_idx, row in enumerate(ws.iter_rows(min_row=2, max_row=ws.max_row), start=2):
        severity = str(row[4].value or '').upper()   # col E = Severity
        bg_color = sev_colors.get(severity, "1A1A2E" if row_idx % 2 == 0 else "0F0F1A")
        row_fill = PatternFill("solid", fgColor=bg_color)
        for cell in row:
            cell.fill      = row_fill
            cell.font      = Font(color="D0D0D0", size=9)
            cell.alignment = Alignment(wrap_text=False, vertical="top")

    print(f"  ‚úì Styled {ws.max_row - 1} data rows with severity colour coding")

    # ‚îÄ‚îÄ 6. Build üìä Dashboard sheet ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # Remove old dashboard if present
    if "üìä Dashboard" in wb.sheetnames:
        del wb["üìä Dashboard"]

    dash = wb.create_sheet("üìä Dashboard", 0)   # insert at position 0 (first tab)
    dash.sheet_properties.tabColor = "E94560"    # red tab

    # --- Dashboard title ---
    dash.merge_cells("A1:G1")
    title_cell = dash["A1"]
    title_cell.value     = "üê∫ ANUBIS THREATHUNTER v6.0 ‚Äî THREAT INTELLIGENCE DASHBOARD"
    title_cell.font      = Font(bold=True, color="E94560", size=14)
    title_cell.fill      = PatternFill("solid", fgColor="1A1A2E")
    title_cell.alignment = Alignment(horizontal="center", vertical="center")
    dash.row_dimensions[1].height = 30

    dash.merge_cells("A2:G2")
    sub_cell = dash["A2"]
    sub_cell.value     = f"Generated: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M')}  |  üëë PharaonX RedTeam | Ramiz Alsafi"
    sub_cell.font      = Font(color="888888", size=10, italic=True)
    sub_cell.fill      = PatternFill("solid", fgColor="0F0F1A")
    sub_cell.alignment = Alignment(horizontal="center")

    # --- Table headers ---
    headers = ["Threat Type", "Total", "P1 (Urgent)", "P2 (High)", "KEV Active", "Critical", "High"]
    header_cols = "ABCDEFG"
    for col_letter, hdr in zip(header_cols, headers):
        cell = dash[f"{col_letter}3"]
        cell.value     = hdr
        cell.font      = Font(bold=True, color="FFFFFF", size=10)
        cell.fill      = PatternFill("solid", fgColor="E94560")
        cell.alignment = Alignment(horizontal="center")
        cell.border    = Border(
            bottom=Side(style="medium", color="FFFFFF"),
            right=Side(style="thin", color="333333"),
        )
    dash.row_dimensions[3].height = 22

    # --- Collect all unique type values from Threat Intelligence sheet ---
    # Read types from the actual sheet data (col A, skip header row 1)
    all_types_in_sheet = []
    seen_types = set()
    for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=1):
        val = str(row[0].value or '').strip()
        if val and val not in seen_types:
            seen_types.add(val)
            all_types_in_sheet.append(val)
    all_types_in_sheet.sort()

    # Color categories for threat types
    type_category_colors = {
        # CVE/Vulnerability types ‚Üí blue family
        'CVE':                ("0D3B6E", "FFFFFF"),
        'REDHAT_CVE':         ("1A4F8A", "FFFFFF"),
        'WINDOWS_CVE':        ("003366", "FFFFFF"),
        'MSRC_UPDATE':        ("0F4C81", "FFFFFF"),
        'GH_ADVISORY':        ("1B4F72", "FFFFFF"),
        'OSV_VULN':           ("1A5276", "FFFFFF"),
        'VULNCHECK_KEV':      ("154360", "FFFFFF"),
        'ZDI_ADVISORY':       ("0B3D91", "FFFFFF"),
        'UBUNTU_SEC':         ("1F618D", "FFFFFF"),
        'VULNERS':            ("1A6AA0", "FFFFFF"),
        # Active exploit/malware ‚Üí red family
        'EXPLOIT':            ("7B241C", "FFFFFF"),
        'MALWARE':            ("922B21", "FFFFFF"),
        'FEODO_C2':           ("641E16", "FFFFFF"),  # BUG FIX: duplicate key removed
        'CISA_RANSOMWARE':    ("8B0000", "FFFFFF"),
        'PACKETSTORM':        ("C0392B", "FFFFFF"),
        # IP threats ‚Üí orange family
        'TALOS_IP':           ("784212", "FFFFFF"),
        'EMERGING_THREAT_IP': ("935116", "FFFFFF"),
        'BLOCKLIST_DE':       ("6E2F1A", "FFFFFF"),
        'ABUSE_IP':           ("935116", "FFFFFF"),
        'GREYNOISE_THREAT':   ("7D6608", "FFFFFF"),
        'TOR_EXIT':           ("4A235A", "FFFFFF"),
        # Phishing/URL ‚Üí purple family
        'PHISH':              ("6C3483", "FFFFFF"),
        'MAL_URL':            ("7D3C98", "FFFFFF"),
        'THREATFOX_IOC':      ("5B2C6F", "FFFFFF"),
        # Firewall/vendor ‚Üí teal family
        'FIREWALL_ADVISORY':  ("0E6655", "FFFFFF"),
        'CISA_ICS':           ("117A65", "FFFFFF"),
        'SANS_ISC':           ("148F77", "FFFFFF"),
        # Intel feeds ‚Üí grey/green
        'OTX_PULSE':          ("1E8449", "FFFFFF"),
        'MITRE_ATTACK':       ("212F3D", "FFFFFF"),
        'FIREHOL_THREAT':      ("2C3E50", "FFFFFF"),
        'NEWS_ALERT':         ("2E4057", "FFFFFF"),
        'DATA_BREACH':        ("943126", "FFFFFF"),
        'SHODAN_VULN':        ("21618C", "FFFFFF"),
        'CENSYS_VULN':        ("1F618D", "FFFFFF"),
        'CENSYS_EXPOSED':     ("2471A3", "FFFFFF"),
        'THREATMINER':        ("283747", "FFFFFF"),
        'GREYNOISE_BENIGN':   ("1D6A39", "FFFFFF"),
        'PATCH_TUESDAY':      ("2C3E50", "FFFFFF"),
        'HIBP':               ("7B241C", "FFFFFF"),
    }
    default_color = ("2C3E50", "FFFFFF")

    # COUNTIFS formulas pointing at "Threat Intelligence" sheet col A-H
    data_sheet = "'Threat Intelligence'"
    type_col   = f"{data_sheet}!$A:$A"
    prio_col   = f"{data_sheet}!$Q:$Q"
    kev_col    = f"{data_sheet}!$J:$J"
    sev_col    = f"{data_sheet}!$E:$E"

    row_start = 4
    for i, ttype in enumerate(all_types_in_sheet):
        r = row_start + i
        bg, fg = type_category_colors.get(ttype, default_color)
        row_fill = PatternFill("solid", fgColor=bg)
        row_font = Font(color=fg, bold=False, size=10)
        bold_font = Font(color=fg, bold=True, size=10)
        center    = Alignment(horizontal="center", vertical="center")
        left      = Alignment(horizontal="left",   vertical="center")
        thin      = Border(
            bottom=Side(style="thin", color="1A1A2E"),
            right=Side(style="thin", color="1A1A2E"),
        )

        # Col A: Type name
        dash[f"A{r}"].value     = ttype
        dash[f"A{r}"].font      = bold_font
        dash[f"A{r}"].fill      = row_fill
        dash[f"A{r}"].alignment = left
        dash[f"A{r}"].border    = thin

        # Col B: Total count ‚Äî COUNTIF formula
        dash[f"B{r}"].value     = f'=COUNTIF({type_col},A{r})'
        dash[f"B{r}"].font      = bold_font
        dash[f"B{r}"].fill      = row_fill
        dash[f"B{r}"].alignment = center
        dash[f"B{r}"].border    = thin

        # Col C: P1 count ‚Äî COUNTIFS
        dash[f"C{r}"].value     = f'=COUNTIFS({type_col},A{r},{prio_col},"P1")'
        dash[f"C{r}"].fill      = row_fill
        dash[f"C{r}"].alignment = center
        dash[f"C{r}"].border    = thin
        # Red highlight if any P1
        dash[f"C{r}"].font      = Font(color="FF4444" if fg=="FFFFFF" else "FF0000", bold=True, size=10)

        # Col D: P2 count
        dash[f"D{r}"].value     = f'=COUNTIFS({type_col},A{r},{prio_col},"P2")'
        dash[f"D{r}"].font      = row_font
        dash[f"D{r}"].fill      = row_fill
        dash[f"D{r}"].alignment = center
        dash[f"D{r}"].border    = thin

        # Col E: KEV count
        dash[f"E{r}"].value     = f'=COUNTIFS({type_col},A{r},{kev_col},"YES")'
        dash[f"E{r}"].font      = Font(color="FFAA00", bold=True, size=10)
        dash[f"E{r}"].fill      = row_fill
        dash[f"E{r}"].alignment = center
        dash[f"E{r}"].border    = thin

        # Col F: Critical count
        dash[f"F{r}"].value     = f'=COUNTIFS({type_col},A{r},{sev_col},"CRITICAL")'
        dash[f"F{r}"].font      = Font(color="FF4444", bold=True, size=10)
        dash[f"F{r}"].fill      = row_fill
        dash[f"F{r}"].alignment = center
        dash[f"F{r}"].border    = thin

        # Col G: High count
        dash[f"G{r}"].value     = f'=COUNTIFS({type_col},A{r},{sev_col},"HIGH")'
        dash[f"G{r}"].font      = Font(color="FFAA44", bold=True, size=10)
        dash[f"G{r}"].fill      = row_fill
        dash[f"G{r}"].alignment = center
        dash[f"G{r}"].border    = thin

        dash.row_dimensions[r].height = 18

    # Totals row
    total_row = row_start + len(all_types_in_sheet)
    totals_fill = PatternFill("solid", fgColor="E94560")
    totals_font = Font(bold=True, color="FFFFFF", size=10)
    dash[f"A{total_row}"].value = "TOTAL"
    for col in "ABCDEFG":
        cell = dash[f"{col}{total_row}"]
        cell.fill   = totals_fill
        cell.font   = totals_font
        cell.border = Border(top=Side(style="medium", color="FFFFFF"))
        cell.alignment = Alignment(horizontal="center" if col != "A" else "left", vertical="center")
    dash[f"B{total_row}"].value = f"=SUM(B{row_start}:B{total_row-1})"
    dash[f"C{total_row}"].value = f"=SUM(C{row_start}:C{total_row-1})"
    dash[f"D{total_row}"].value = f"=SUM(D{row_start}:D{total_row-1})"
    dash[f"E{total_row}"].value = f"=SUM(E{row_start}:E{total_row-1})"
    dash[f"F{total_row}"].value = f"=SUM(F{row_start}:F{total_row-1})"
    dash[f"G{total_row}"].value = f"=SUM(G{row_start}:G{total_row-1})"
    dash[f"A{total_row}"].fill  = totals_fill
    dash[f"A{total_row}"].font  = totals_font
    dash.row_dimensions[total_row].height = 20

    # Column widths on Dashboard
    dash.column_dimensions["A"].width = 26
    for col in "BCDEFG":
        dash.column_dimensions[col].width = 14

    # Freeze header rows
    dash.freeze_panes = "A4"

    print(f"  ‚úì Dashboard created with {len(all_types_in_sheet)} threat type rows + COUNTIFS formulas")
    print(f"  ‚úì AutoFilter + freeze panes applied to main sheet")

    # ‚îÄ‚îÄ 7. Charts on Dashboard ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    _add_dashboard_charts(wb, dash, ws, row_start, len(all_types_in_sheet), total_row)
    print(f"  ‚úì Risk heatmap + bar + pie charts added to dashboard")

    wb.save(excel_path)
    print(f"  ‚úì Saved: {excel_path}")


def fetch_abuse_sslbl():
    """v5.6 NEW: Abuse.ch SSL Blacklist ‚Äî IPs hosting malicious SSL certificates.
    Free, no API key, updated every 5 minutes. Extremely high signal-to-noise.
    """
    print("\nüîê Fetching Abuse.ch SSL IP Blacklist...")
    ips = []
    try:
        r = requests.get(SSLBL_URL, timeout=15,
                         headers={'User-Agent': 'ANUBIS-ThreatHunter/5.6'})
        if r.status_code == 200:
            for line in r.text.splitlines():
                if line.startswith('#') or not line.strip():
                    continue
                parts = line.split(',')
                # v5.10 FIX: SSLBL CSV format is: date,ip,port,malware,reason
                # Old code read parts[0] as IP ‚Äî that's the date. IP is parts[1].
                if len(parts) >= 2:
                    ip     = parts[1].strip()
                    port   = parts[2].strip() if len(parts) > 2 else '443'
                    reason = parts[4].strip() if len(parts) > 4 else 'Malicious SSL cert'
                    if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$', ip):
                        ips.append({'ip': ip, 'port': port, 'reason': reason, 'source': 'SSLBL'})
            ips = ips[:30]
            print(f"‚úì Found {len(ips)} SSL blacklist IPs from Abuse.ch")
        else:
            print(f"‚úó SSLBL error: {r.status_code}")
    except Exception as e:
        print(f"‚úó SSLBL failed: {e}")
    return ips


def fetch_hybridanalysis():
    """
    Replaces MalShare (site down since early 2025).
    Hybrid Analysis public community feed ‚Äî no API key required.
    Returns recent malware submissions with threat scores, family tags, and hashes.
    Fallback: CAPE Sandbox public task list.

    Hybrid Analysis feed: https://www.hybrid-analysis.com/feed?json
    CAPE Sandbox API:     https://www.capesandbox.com/apiv2/tasks/list/
    """
    print("\nü¶† Fetching Hybrid Analysis public malware feed...")
    samples = []

    # ‚îÄ‚îÄ Primary: Hybrid Analysis public JSON feed ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    try:
        r = requests.get(
            HYBRIDANALYSIS_FEED,
            timeout=15,
            headers={
                'User-Agent':  'ANUBIS-ThreatHunter/6.2',
                'Accept':      'application/json',
            }
        )
        if r.status_code == 200:
            data = r.json() if isinstance(r.json(), list) else r.json().get('data', [])
            for item in data[:30]:
                sha256    = item.get('sha256', '')
                verdict   = item.get('verdict', item.get('threat_level', ''))
                family    = item.get('vx_family', item.get('threat_name', ''))
                file_type = item.get('type', item.get('file_type', ''))
                threat_score = int(item.get('threat_score', 0) or 0)
                if sha256:
                    samples.append({
                        'sha256':       sha256,
                        'type':         file_type or 'unknown',
                        'family':       family or 'unknown',
                        'verdict':      verdict,
                        'threat_score': threat_score,
                        'source':       'HybridAnalysis',
                    })
            print(f"  ‚úì Hybrid Analysis: {len(samples)} malware samples")
            return samples
        else:
            print(f"  ‚úó Hybrid Analysis feed: HTTP {r.status_code} ‚Äî trying CAPE fallback")
    except Exception as e:
        print(f"  ‚úó Hybrid Analysis failed: {str(e)[:80]} ‚Äî trying CAPE fallback")

    # ‚îÄ‚îÄ Fallback: CAPE Sandbox public task list ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    try:
        r = requests.get(
            CAPE_SANDBOX_API,
            params={'limit': 30, 'status': 'reported'},
            timeout=12,
            headers={'User-Agent': 'ANUBIS-ThreatHunter/6.2'}
        )
        if r.status_code == 200:
            tasks = r.json().get('data', [])
            for task in tasks:
                target   = task.get('target', {})
                sha256   = target.get('file', {}).get('sha256', '')
                family   = ', '.join(task.get('malfamily', []) or [])
                category = task.get('category', '')
                if sha256:
                    samples.append({
                        'sha256':       sha256,
                        'type':         category or 'unknown',
                        'family':       family or 'unknown',
                        'verdict':      'malicious',
                        'threat_score': 80,
                        'source':       'CAPE_Sandbox',
                    })
            print(f"  ‚úì CAPE Sandbox fallback: {len(samples)} malware samples")
        else:
            print(f"  ‚úó CAPE Sandbox: HTTP {r.status_code}")
    except Exception as e:
        print(f"  ‚úó CAPE Sandbox failed: {str(e)[:80]}")

    return samples


def fetch_certeu_reports():
    """v5.10 FIX: ENISA RSS URL returns 404. Now tries NCSC UK + CISA all-advisories
    + CERT Belgium in order. First feed that returns entries wins.
    """
    print("\nüá™üá∫ Fetching CERT/NCSC Threat Reports...")
    reports = []
    cutoff  = datetime.now() - timedelta(days=30)
    for url in CERT_EU_FALLBACKS:
        try:
            r = requests.get(url, timeout=12,
                             headers={'User-Agent': 'ANUBIS-ThreatHunter/5.10'})
            if r.status_code != 200:
                print(f"  ‚úó {url.split('/')[2]}: HTTP {r.status_code}")
                continue
            feed = feedparser.parse(r.text)
            if not feed.entries:
                continue
            for entry in feed.entries[:10]:
                try:
                    pub = datetime(*entry.published_parsed[:6]) if hasattr(entry,'published_parsed') and entry.published_parsed else datetime.now()
                    if pub < cutoff:
                        continue
                    cves = list(set(re.findall(r'CVE-\d{4}-\d+', entry.get('title','') + entry.get('summary',''))))
                    reports.append({
                        'id':        entry.get('id','')[-20:],
                        'title':     entry.get('title','')[:150],
                        'link':      entry.get('link',''),
                        'published': pub.strftime('%Y-%m-%d'),
                        'cves':      cves,
                        'source':    url.split('/')[2]
                    })
                except:
                    continue
            if reports:
                print(f"‚úì Found {len(reports)} CERT/NCSC reports (from {url.split('/')[2]})")
                return reports
        except Exception as e:
            print(f"  ‚úó {url.split('/')[2]} failed: {str(e)[:60]}")
    print("‚úó CERT/NCSC: all endpoints failed ‚Äî skipping")
    return reports

# ============= CONCURRENT FETCHER =============

# v5.8: Global flag for graceful Ctrl+C ‚Äî set by signal handler, checked by executor loop
_ANUBIS_SHUTDOWN = False

def _graceful_interrupt(sig, frame):
    global _ANUBIS_SHUTDOWN
    if not _ANUBIS_SHUTDOWN:
        _ANUBIS_SHUTDOWN = True
        print("\n\n‚ö†Ô∏è  Ctrl+C detected ‚Äî cancelling pending fetches, saving partial results...\n")

signal.signal(signal.SIGINT, _graceful_interrupt)

def fetch_all_concurrent():
    print("\nüöÄ CONCURRENT FETCH MODE - All sources in parallel...")
    tasks = {
        'cves':              fetch_cves,
        'kev':               get_cisa_kev_list,
        'github':            fetch_github_advisories,
        'urlhaus':           fetch_urlhaus,
        'phish':             fetch_phishtank,
        'exploits':          fetch_exploits,
        'malware':           fetch_malware,
        'msrc':              fetch_microsoft_security_updates,
        'windows_cves':      fetch_windows_cves_from_nvd,
        'patch_tuesday':     fetch_patch_tuesday_info,
        'vulners':           fetch_vulners_data,
        'otx':               fetch_alienvault_otx,
        'threatfox':         fetch_threatfox_iocs,
        'osv':               fetch_osv_dev,
        'threatminer':       fetch_threatminer,
        'cve_trends':        fetch_cve_trends,
        'shodan':            fetch_shodan,
        'abuseip':           fetch_abuseipdb,
        'hibp':              fetch_hibp,
        'cisa_ics':          fetch_cisa_ics_advisories,
        'mitre':             fetch_mitre_attack,
        'feodo':             fetch_feodo_tracker,
        'spamhaus':          fetch_spamhaus_drop,
        'ubuntu':            fetch_ubuntu_security,
        'tor':               fetch_tor_exit_nodes,
        'blocklist':         fetch_blocklist_de,
        'gn_threats':        fetch_greynoise_mass_scan,
        'gn_benign':         fetch_greynoise_riot,
        'censys_vuln':       fetch_censys_vulnerable_hosts,
        'censys_rdp':        lambda: fetch_censys_exposed_services("rdp"),
        'intel_feed':        fetch_snyk_vulnerabilities,
        'redhat':            fetch_redhat_cves,
        'talos':             fetch_talos_blacklist,
        'emerging':          fetch_emerging_threats_ips,
        'packetstorm':       fetch_packetstorm_rss,
        'vulncheck_kev':     fetch_vulncheck_kev,
        'cisa_ransomware':   fetch_cisa_ransomware,
        # ---- Firewall Vendor Advisories ----
        'fw_fortinet':       fetch_fortinet_advisories,
        'fw_paloalto':       fetch_palo_alto_advisories,
        'fw_cisco':          fetch_cisco_advisories,
        'fw_juniper':        fetch_juniper_advisories,
        'fw_f5':             fetch_f5_advisories,
        'fw_citrix':         fetch_citrix_advisories,
        'fw_sonicwall':      fetch_sonicwall_advisories,
        'fw_checkpoint':     fetch_checkpoint_advisories,
        'fw_watchguard':     fetch_watchguard_advisories,
        'fw_sophos':         fetch_sophos_advisories,
        'fw_aruba':          fetch_aruba_advisories,
        'fw_zyxel':          fetch_zyxel_advisories,
        'fw_barracuda':      fetch_barracuda_advisories,
        'fw_pfsense':        fetch_pfsense_advisories,
        # ---- NEW v5.0 Sources ----
        'zdi':               fetch_zdi_advisories,
        'attackerkb':        fetch_attackerkb,
        'sans_isc':          fetch_sans_isc,
        'security_news':     fetch_security_news,
        # ---- v5.6 Sources (were defined but never registered ‚Äî fixed in v5.8) ----
        'sslbl':             fetch_abuse_sslbl,
        'certeu':            fetch_certeu_reports,
        'hybridanalysis':    fetch_hybridanalysis,
    }

    # ‚îÄ‚îÄ v5.9: Live progress tracking ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # active_tasks: name ‚Üí start_time (float). Written by wrapper, deleted on finish.
    # Heartbeat thread reads it every HEARTBEAT_INTERVAL seconds and prints
    # "‚è≥ Still running: X (12s), Y (8s), ..." so you always know what's blocking.
    import threading
    HEARTBEAT_INTERVAL = 10   # seconds between heartbeat lines

    active_tasks  = {}        # {name: start_time}
    active_lock   = threading.Lock()
    heartbeat_stop = threading.Event()

    def _heartbeat():
        while not heartbeat_stop.wait(HEARTBEAT_INTERVAL):
            with active_lock:
                if not active_tasks:
                    continue
                now = time.time()
                parts = sorted(
                    [f"{n} ({int(now - t)}s)" for n, t in active_tasks.items()],
                    key=lambda s: -int(s.split('(')[1].rstrip('s)'))  # longest first
                )
                print(f"\n  ‚è≥ Still running [{len(parts)}]: {', '.join(parts)}\n", flush=True)

    def _wrap(name, fn):
        """Wraps a fetch function to record start/finish in active_tasks."""
        def _inner():
            with active_lock:
                active_tasks[name] = time.time()
            try:
                return fn()
            finally:
                with active_lock:
                    active_tasks.pop(name, None)
        return _inner

    # Launch heartbeat daemon
    hb = threading.Thread(target=_heartbeat, daemon=True)
    hb.start()

    results = {}
    executor = ThreadPoolExecutor(max_workers=20)
    # Wrap every task so we get live start/end tracking
    futures = {executor.submit(_wrap(name, fn)): name for name, fn in tasks.items()}
    done = 0; total = len(tasks)
    try:
        for future in as_completed(futures, timeout=300):
            if _ANUBIS_SHUTDOWN:
                break
            name = futures[future]
            try:
                results[name] = future.result(timeout=5)
                done += 1
                print(f"  ‚úì [{done}/{total}] {name}")
            except Exception as e:
                print(f"  ‚úó [{done+1}/{total}] {name} failed: {e}")
                results[name] = [] if name != 'kev' else set()
                done += 1
    except Exception:
        pass
    finally:
        heartbeat_stop.set()   # kill the heartbeat thread
        try:
            executor.shutdown(wait=False, cancel_futures=True)
        except TypeError:
            executor.shutdown(wait=False)

    # Fill missing keys with empty defaults so process_threats never KeyErrors
    for name in tasks:
        if name not in results:
            results[name] = [] if name != 'kev' else set()

    if _ANUBIS_SHUTDOWN:
        completed = sum(1 for v in results.values() if v)
        print(f"\n‚ö†Ô∏è  Interrupted after {done}/{total} sources ‚Äî {completed} returned data. Proceeding with partial results.\n")
    else:
        print(f"‚úÖ Fetched all {total} sources!\n")
    return results


def print_resource_report(results, tasks):
    """
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    üê∫ ANUBIS RESOURCE HEALTH REPORT ‚Äî comprehensive per-source diagnostics
    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    Prints a full breakdown of every fetch task: how many records came back,
    enrichment status, silent failures (returned [] with no error), and
    hard failures (exception caught). Also reports HTTP response anomalies
    where detectable from the data shape.
    """
    print("\n" + "‚ïê" * 70)
    print("üì° RESOURCE HEALTH REPORT")
    print("‚ïê" * 70)

    # Categorize results
    ok_sources      = []  # fetched > 0 records
    empty_silent    = []  # fetched 0 records, no explicit error (silent fail)
    failed_sources  = []  # exception was caught (result is default []/set())
    no_key_skipped  = []  # key-gated sources that we know need a key

    KEY_GATED = {
        'shodan':        'SHODAN_API_KEY',
        'abuseip':       'ABUSEIPDB_API_KEY',
        'gn_threats':    'GREYNOISE_API_KEY',
        'gn_benign':     'GREYNOISE_API_KEY',
        'censys_vuln':   'CENSYS_API_ID',
        'censys_rdp':    'CENSYS_API_ID',
        'otx':           'ALIENVAULT_API_KEY',
        'vulners':       'VULNERS_API_KEY',
        'attackerkb':    'ATTACKERKB_API_KEY',
        'vulncheck_kev': 'VULNCHECK_API_KEY',
        'intel_feed':    'SNYK_API_KEY (optional)',
    }

    api_keys_present = {
        'SHODAN_API_KEY':      bool(SHODAN_API_KEY),
        'ABUSEIPDB_API_KEY':   bool(ABUSEIPDB_API_KEY),
        'GREYNOISE_API_KEY':   bool(GREYNOISE_API_KEY),
        'CENSYS_API_ID':       bool(CENSYS_API_ID),
        'ALIENVAULT_API_KEY':  bool(ALIENVAULT_API_KEY),
        'VULNERS_API_KEY':     bool(VULNERS_API_KEY),
        'ATTACKERKB_API_KEY':  bool(ATTACKERKB_API_KEY),
        'VULNCHECK_API_KEY':   bool(VULNCHECK_API_KEY),
        'SNYK_API_KEY (optional)': False,
    }

    FRIENDLY = {
        'cves':'NVD CVE API','kev':'CISA KEV','github':'GitHub Advisories',
        'urlhaus':'URLhaus','phish':'OpenPhish','exploits':'Exploit-DB RSS',
        'malware':'Malware Bazaar','msrc':'Microsoft MSRC','windows_cves':'NVD Windows CVEs',
        'patch_tuesday':'Patch Tuesday','vulners':'Vulners API','otx':'AlienVault OTX',
        'threatfox':'ThreatFox IOCs','osv':'OSV.dev','threatminer':'ThreatMiner',
        'cve_trends':'CVE Trends','shodan':'Shodan','abuseip':'AbuseIPDB',
        'hibp':'HaveIBeenPwned','cisa_ics':'CISA ICS Advisories','mitre':'MITRE TAXII',
        'feodo':'Feodo Tracker','spamhaus':'Spamhaus DROP','ubuntu':'Ubuntu Security',
        'tor':'TOR Exit Nodes','blocklist':'Blocklist.de','gn_threats':'GreyNoise Threats',
        'gn_benign':'GreyNoise RIOT','censys_vuln':'Censys Vuln Hosts','censys_rdp':'Censys RDP Exposed',
        'intel_feed':'Snyk/Intel Feed','redhat':'RedHat CVE API','talos':'Talos IP Blacklist',
        'emerging':'Emerging Threats IPs','packetstorm':'PacketStorm RSS',
        'vulncheck_kev':'VulnCheck KEV','cisa_ransomware':'CISA Ransomware',
        'fw_fortinet':'Fortinet PSIRT','fw_paloalto':'Palo Alto Advisories',
        'fw_cisco':'Cisco PSIRT','fw_juniper':'Juniper Advisories',
        'fw_f5':'F5 Advisories','fw_citrix':'Citrix Advisories',
        'fw_sonicwall':'SonicWall PSIRT','fw_checkpoint':'CheckPoint Advisories',
        'fw_watchguard':'WatchGuard PSIRT','fw_sophos':'Sophos Advisories',
        'fw_aruba':'Aruba PSIRT','fw_zyxel':'Zyxel Advisories',
        'fw_barracuda':'Barracuda PSIRT','fw_pfsense':'pfSense Advisories',
        'zdi':'ZDI Advisories','attackerkb':'AttackerKB','sans_isc':'SANS ISC',
        'security_news':'Security News RSS','sslbl':'SSLBL Abuse.ch','certeu':'CERT/NCSC',
    }

    col_w = 30
    for name in sorted(tasks.keys()):
        val = results.get(name)
        friendly = FRIENDLY.get(name, name)
        count = len(val) if isinstance(val, (list, set)) else 0
        is_key_gated = name in KEY_GATED
        required_key = KEY_GATED.get(name, '')
        key_missing  = is_key_gated and not api_keys_present.get(required_key, True)

        if count > 0:
            ok_sources.append((name, friendly, count))
        elif key_missing:
            no_key_skipped.append((name, friendly, required_key))
        elif val is not None and count == 0:
            empty_silent.append((name, friendly))
        else:
            failed_sources.append((name, friendly))

    # ‚îÄ‚îÄ OK Sources ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if ok_sources:
        print(f"\n‚úÖ FETCHED & ENRICHED ({len(ok_sources)} sources):")
        print(f"  {'Source':<{col_w}} {'Friendly Name':<28} {'Records':>8}  {'MITRE Mapped'}")
        print(f"  {'‚îÄ'*col_w} {'‚îÄ'*28} {'‚îÄ'*8}  {'‚îÄ'*14}")
        for name, friendly, count in sorted(ok_sources, key=lambda x: -x[2]):
            # Rough MITRE mapping status: CVE-type sources get mapped
            mapped = "‚úì CWE+Keyword" if name in ('cves','windows_cves','redhat','msrc','github','osv','zdi') else \
                     "‚úì Keyword"     if name in ('malware','exploits','threatfox','security_news','packetstorm') else \
                     "~ IP/IOC only" if name in ('talos','emerging','tor','blocklist','feodo','spamhaus','abuseip','urlhaus','phish') else \
                     "~ Feed only"
            print(f"  {name:<{col_w}} {friendly:<28} {count:>8,}  {mapped}")

    # ‚îÄ‚îÄ Silent Failures ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if empty_silent:
        print(f"\n‚ö†Ô∏è  SILENT FAILURES ‚Äî returned 0 records, no exception ({len(empty_silent)} sources):")
        print("  These sources responded (no crash) but gave back nothing.")
        print("  Likely causes: rate limit, feed format change, 204/empty body.\n")
        for name, friendly in empty_silent:
            print(f"  ‚Ä¢ {name:<{col_w}} {friendly}")

    # ‚îÄ‚îÄ No API Key ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if no_key_skipped:
        print(f"\nüîë SKIPPED ‚Äî Missing API Key ({len(no_key_skipped)} sources):")
        for name, friendly, key in no_key_skipped:
            print(f"  ‚Ä¢ {name:<{col_w}} {friendly:<28} ‚Üí needs: {key}")
        print(f"\n  ‚Üí Set these as env vars: export SHODAN_API_KEY=... etc.")

    # ‚îÄ‚îÄ Hard Failures ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if failed_sources:
        print(f"\nüíÄ HARD FAILURES ‚Äî exception caught, returned empty ({len(failed_sources)} sources):")
        for name, friendly in failed_sources:
            print(f"  ‚Ä¢ {name:<{col_w}} {friendly}")

    # ‚îÄ‚îÄ Summary ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    total_rec = sum(c for _,_,c in ok_sources)
    print(f"\n{'‚ïê'*70}")
    print(f"üìä SUMMARY:")
    print(f"  ‚úÖ Active sources:        {len(ok_sources):>4}  ({total_rec:,} total records)")
    print(f"  ‚ö†Ô∏è  Silent failures:       {len(empty_silent):>4}  (responded but empty)")
    print(f"  üîë Missing API keys:      {len(no_key_skipped):>4}  (skipped, no crash)")
    print(f"  üíÄ Hard failures:         {len(failed_sources):>4}  (exception caught)")
    print(f"  üì° Total tasks attempted: {len(tasks):>4}")
    print(f"{'‚ïê'*70}\n")

# ============= MAIN =============
# ============= v6.0: HTML INTERACTIVE DASHBOARD GENERATOR =============
HTML_DASHBOARD_FILE = "anubis_threat_dashboard.html"

def generate_html_dashboard(df, output_path=HTML_DASHBOARD_FILE):
    """
    v6.0 FULL REWRITE ‚Äî AnubisX Maximum Force Edition.

    NEW v6.0 FEATURES:
      - ZERO external dependencies: pure Canvas JS charts (no Chart.js CDN)
      - API key security: keys never appear in HTML output
      - Severity EPSS/CVSS slider filter
      - MITRE technique filter (multi-select pills)
      - Vendor/product filter
      - Date range filter
      - Risk Heatmap: Type √ó Severity canvas grid
      - CVE Trending chart: threats over time (canvas)
      - MITRE ATT&CK matrix overlay (canvas, tactics √ó techniques)
      - Drill-Down Modal: click any row ‚Üí full details panel
          (exploit availability, EPSS score, ransomware usage, mitigations)
      - Purple Team Mode toggle:
          üî¥ Red Team: exploit chains, attack paths, kill chain mapping
          üîµ Blue Team: detection rules, D3FEND controls, hardening steps
      - All data self-contained (no backend, no server needed)
    """
    print(f"\nüåê Generating AnubisX v6.0 HTML dashboard ‚Üí {output_path}")

    import json as _json

    # ‚îÄ‚îÄ helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def _col(col, default=""):
        return df[col] if col in df.columns else pd.Series([default]*len(df))

    def _js_int(v):
        try: return int(v)
        except: return 0

    def _js_float(v):
        try: return round(float(v), 4)
        except: return 0.0

    def _safe_str(v, maxlen=300):
        if pd.isna(v): return ""
        s = str(v)
        return s[:maxlen] if len(s) > maxlen else s

    # ‚îÄ‚îÄ Summary counts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    total     = len(df)
    kev_cnt   = int((_col("CISA_KEV") == "YES").sum())
    p1_cnt    = int((_col("Remediation_Priority") == "P1").sum())
    zdi_col   = _col("ZDI_Advisory", "NONE")
    zdi_cnt   = int(zdi_col.apply(lambda x: str(x) not in ["NONE","N/A","","None"]).sum())
    crit_cnt  = int((_col("Risk_Level") == "CRITICAL").sum())
    high_cnt  = int((_col("Risk_Level") == "HIGH").sum())
    exploit_cnt = int((_col("Exploit_Status").apply(
        lambda x: str(x) not in ["NONE","N/A","","None","No known exploit"])).sum())

    # ‚îÄ‚îÄ Chart data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    risk_counts = _col("Risk_Level").value_counts().reindex(["CRITICAL","HIGH","MEDIUM","LOW"], fill_value=0)
    risk_labels = list(risk_counts.index)
    risk_values = [_js_int(x) for x in risk_counts.values]

    type_counts = _col("Type").value_counts().head(10)
    type_labels = list(type_counts.index)
    type_values = [_js_int(x) for x in type_counts.values]

    prio_counts = _col("Remediation_Priority").value_counts().reindex(["P1","P2","P3","P4"], fill_value=0)
    prio_values = [_js_int(x) for x in prio_counts.values]

    epss_col = pd.to_numeric(_col("EPSS_Score"), errors="coerce").fillna(0)
    epss_buckets = [0]*10
    for v in epss_col:
        epss_buckets[min(int(float(v) * 10), 9)] += 1

    exploit_counts = _col("Exploit_Status").value_counts().head(6)
    exploit_labels = list(exploit_counts.index)
    exploit_values = [_js_int(x) for x in exploit_counts.values]

    # ‚îÄ‚îÄ Risk Heatmap data: Type √ó Severity ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    heatmap_types = list(_col("Type").value_counts().head(8).index)
    heatmap_sevs  = ["CRITICAL", "HIGH", "MEDIUM", "LOW"]
    heatmap_grid  = []
    for t in heatmap_types:
        row = []
        for s in heatmap_sevs:
            cnt = int(((df.get("Type", pd.Series()) == t) & (_col("Severity") == s)).sum()) if "Type" in df.columns else 0
            row.append(cnt)
        heatmap_grid.append(row)

    # ‚îÄ‚îÄ Trending data: group by date ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    trend_labels, trend_values = [], []
    if "Timestamp" in df.columns:
        try:
            df2 = df.copy()
            df2["_date"] = pd.to_datetime(_col("Timestamp"), errors="coerce").dt.strftime("%m-%d")
            daily = df2["_date"].value_counts().sort_index()
            trend_labels = list(daily.index[-14:]) if len(daily) >= 2 else list(daily.index)
            trend_values = [_js_int(x) for x in daily.values[-14:]] if len(daily) >= 2 else [_js_int(x) for x in daily.values]
        except:
            pass

    # ‚îÄ‚îÄ MITRE techniques for filter ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    mitre_set = set()
    for v in _col("MITRE_Techniques"):
        s = str(v)
        for m in re.findall(r'T\d{4}(?:\.\d{3})?', s):
            mitre_set.add(m)
    mitre_list = sorted(mitre_set)

    # ‚îÄ‚îÄ Vendor/product list ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    vendor_set = set()
    for v in _col("Affected_Products"):
        s = str(v)
        for part in re.split(r'[,;|]', s):
            p = part.strip()
            if p and p not in ("", "N/A", "nan", "None"):
                vendor_set.add(p[:40])
    vendor_list = sorted(vendor_set)[:60]

    # ‚îÄ‚îÄ ATT&CK matrix data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    TACTICS = [
        ("Recon","TA0043"), ("Resource Dev","TA0042"), ("Initial Access","TA0001"),
        ("Execution","TA0002"), ("Persistence","TA0003"), ("Priv Esc","TA0004"),
        ("Defense Evasion","TA0005"), ("Cred Access","TA0006"),
        ("Discovery","TA0007"), ("Lateral Move","TA0008"),
        ("Collection","TA0009"), ("C2","TA0011"),
        ("Exfiltration","TA0010"), ("Impact","TA0040"),
    ]
    # v6.0 FIX: Real MITRE ATT&CK T-number ‚Üí tactic mapping (replaces wrong range heuristic)
    TECH_TO_TACTIC = {
        # Initial Access (TA0001)
        "T1189":"Initial Access","T1190":"Initial Access","T1195":"Initial Access",
        "T1199":"Initial Access","T1566":"Initial Access","T1133":"Initial Access",
        "T1200":"Initial Access","T1091":"Initial Access","T1192":"Initial Access",
        # Execution (TA0002)
        "T1059":"Execution","T1106":"Execution","T1053":"Execution","T1129":"Execution",
        "T1203":"Execution","T1204":"Execution","T1559":"Execution","T1569":"Execution",
        "T1072":"Execution",
        # Persistence (TA0003)
        "T1098":"Persistence","T1136":"Persistence","T1543":"Persistence","T1547":"Persistence",
        "T1574":"Persistence","T1505":"Persistence","T1037":"Persistence","T1078":"Persistence",
        "T1176":"Persistence","T1197":"Persistence","T1554":"Persistence",
        # Privilege Escalation (TA0004)
        "T1068":"Priv Esc","T1055":"Priv Esc","T1134":"Priv Esc","T1548":"Priv Esc",
        "T1484":"Priv Esc","T1611":"Priv Esc",
        # Defense Evasion (TA0005)
        "T1027":"Defense Evasion","T1036":"Defense Evasion","T1070":"Defense Evasion",
        "T1112":"Defense Evasion","T1014":"Defense Evasion","T1222":"Defense Evasion",
        "T1562":"Defense Evasion","T1600":"Defense Evasion","T1218":"Defense Evasion",
        "T1553":"Defense Evasion","T1207":"Defense Evasion","T1564":"Defense Evasion",
        "T1620":"Defense Evasion",
        # Credential Access (TA0006)
        "T1003":"Cred Access","T1040":"Cred Access","T1056":"Cred Access","T1110":"Cred Access",
        "T1111":"Cred Access","T1187":"Cred Access","T1212":"Cred Access","T1552":"Cred Access",
        "T1528":"Cred Access","T1539":"Cred Access","T1557":"Cred Access","T1558":"Cred Access",
        "T1606":"Cred Access",
        # Discovery (TA0007)
        "T1007":"Discovery","T1010":"Discovery","T1012":"Discovery","T1016":"Discovery",
        "T1018":"Discovery","T1033":"Discovery","T1046":"Discovery","T1049":"Discovery",
        "T1057":"Discovery","T1069":"Discovery","T1082":"Discovery","T1083":"Discovery",
        "T1087":"Discovery","T1518":"Discovery","T1613":"Discovery",
        # Lateral Movement (TA0008)
        "T1021":"Lateral Move","T1080":"Lateral Move","T1534":"Lateral Move",
        "T1563":"Lateral Move","T1570":"Lateral Move","T1210":"Lateral Move",
        # Collection (TA0009)
        "T1005":"Collection","T1025":"Collection","T1039":"Collection","T1074":"Collection",
        "T1113":"Collection","T1114":"Collection","T1115":"Collection","T1119":"Collection",
        "T1123":"Collection","T1125":"Collection","T1185":"Collection","T1213":"Collection",
        # C2 (TA0011)
        "T1071":"C2","T1090":"C2","T1092":"C2","T1095":"C2","T1102":"C2","T1104":"C2",
        "T1105":"C2","T1132":"C2","T1568":"C2","T1571":"C2","T1572":"C2","T1573":"C2",
        # Exfiltration (TA0010)
        "T1011":"Exfiltration","T1020":"Exfiltration","T1022":"Exfiltration",
        "T1029":"Exfiltration","T1030":"Exfiltration","T1041":"Exfiltration",
        "T1048":"Exfiltration","T1052":"Exfiltration",
        # Impact (TA0040)
        "T1485":"Impact","T1486":"Impact","T1487":"Impact","T1489":"Impact","T1490":"Impact",
        "T1491":"Impact","T1494":"Impact","T1495":"Impact","T1496":"Impact","T1498":"Impact",
        "T1499":"Impact","T1529":"Impact","T1531":"Impact","T1561":"Impact","T1565":"Impact",
        # Recon (TA0043)
        "T1595":"Recon","T1592":"Recon","T1589":"Recon","T1591":"Recon","T1598":"Recon",
        "T1596":"Recon","T1593":"Recon","T1597":"Recon",
        # Resource Development (TA0042)
        "T1583":"Resource Dev","T1584":"Resource Dev","T1585":"Resource Dev",
        "T1586":"Resource Dev","T1587":"Resource Dev","T1588":"Resource Dev","T1608":"Resource Dev",
    }
    tactic_hits = {t[0]: 0 for t in TACTICS}
    technique_detail = {}  # technique_id ‚Üí list of CVE/threat IDs
    for _, row in df.iterrows():
        techniques = str(row.get("MITRE_Techniques", "") or "")
        tid = str(row.get("ID", ""))
        # Format is "T1190:Name | T1059:Name" ‚Äî extract technique IDs
        for m in re.findall(r'(T\d{4}(?:\.\d{3})?)', techniques):
            base = m.split(".")[0]  # strip subtechnique for lookup
            tactic = TECH_TO_TACTIC.get(base)
            if tactic:
                tactic_hits[tactic] = tactic_hits.get(tactic, 0) + 1
            technique_detail.setdefault(m, []).append(tid)

    # ‚îÄ‚îÄ Top-10 priority threats table ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    prio_map_order = {"P1":0,"P2":1,"P3":2,"P4":3}
    top10_df = df.copy()
    top10_df["_pn"] = _col("Remediation_Priority").map(prio_map_order).fillna(4)
    top10_df["_en"] = pd.to_numeric(_col("EPSS_Percentile"), errors="coerce").fillna(0)
    top10_df = top10_df.sort_values(["_pn","_en"], ascending=[True,False]).head(10)

    sev_colors = {"CRITICAL":"#c0392b","HIGH":"#e67e22","MEDIUM":"#f39c12","LOW":"#27ae60"}
    top10_rows = ""
    for _, r in top10_df.iterrows():
        sev   = str(r.get("Severity","?"))
        sc    = sev_colors.get(sev,"#7f8c8d")
        epss  = _js_float(r.get("EPSS_Percentile",0))
        kev_b = '<span class="badge kev">KEV</span>' if str(r.get("CISA_KEV",""))=="YES" else ""
        zdi_b = '<span class="badge zdi">ZDI</span>' if str(r.get("ZDI_Advisory","NONE")) not in ["NONE","N/A","","None"] else ""
        exp_b = '<span class="badge exp">EXPLOIT</span>' if str(r.get("Exploit_Status","NONE")) not in ["NONE","N/A","","None","No known exploit"] else ""
        desc  = str(r.get("Description",""))[:140].replace("<","&lt;").replace(">","&gt;")
        tid   = str(r.get("ID",""))
        link  = str(r.get("Link",""))
        idc   = f'<a href="{link}" target="_blank">{tid}</a>' if link and link not in ["nan","None",""] else tid
        top10_rows += f"""<tr>
          <td>{idc}</td>
          <td><span class="sev-badge" style="background:{sc}">{sev}</span></td>
          <td><span class="prio-badge prio-{str(r.get("Remediation_Priority","P4"))}">{str(r.get("Remediation_Priority","?"))}</span></td>
          <td>{str(r.get("Type",""))}</td>
          <td>{"%.0f%%" % (epss*100) if epss>0 else "‚Äì"}</td>
          <td>{kev_b}{zdi_b}{exp_b}</td>
          <td class="desc-cell">{desc}{"‚Ä¶" if len(str(r.get("Description","")))>140 else ""}</td>
        </tr>\n"""

    # ‚îÄ‚îÄ Source breakdown bars ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    src_bar_colors = ["#e94560","#e67e22","#3498db","#9b59b6","#27ae60",
                      "#1abc9c","#f39c12","#e74c3c","#2ecc71","#8e44ad"]
    src_rows = ""
    top_types = _col("Type").value_counts().head(10)
    max_v = int(top_types.iloc[0]) if len(top_types) else 1
    for i, (ttype, cnt) in enumerate(top_types.items()):
        pct = int(cnt) / max_v * 100
        col = src_bar_colors[i % len(src_bar_colors)]
        src_rows += f"""<div class="src-row">
          <span class="src-label">{ttype}</span>
          <div class="src-bar-wrap"><div class="src-bar" style="width:{pct:.1f}%;background:{col}"></div></div>
          <span class="src-count">{int(cnt):,}</span>
        </div>\n"""

    # ‚îÄ‚îÄ Embed ALL rows as JSON ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    show_cols = ["Type","ID","Severity","Risk_Level","Remediation_Priority",
                 "CISA_KEV","EPSS_Score","EPSS_Percentile","Exploit_Status",
                 "Confidence_Score","Description","Affected_Products",
                 "MITRE_Techniques","ZDI_Advisory","AttackerKB_Score",
                 "Source_Count","Link","Timestamp","Vendor",
                 "Fix_Available","Intel_URL","News_Coverage",
                 "GreyNoise_Context","CVSS"]
    avail = [c for c in show_cols if c in df.columns]

    rows_json = []
    for _, r in df.iterrows():
        obj = {}
        for c in avail:
            v = r[c]
            if pd.isna(v):   obj[c] = ""
            elif isinstance(v, float): obj[c] = round(v, 4)
            elif hasattr(v, 'item'):   obj[c] = v.item()
            else:                       obj[c] = str(v)[:300]
        rows_json.append(obj)

    all_data_json   = _json.dumps(rows_json, ensure_ascii=False)
    j_risk_labels   = _json.dumps(risk_labels)
    j_risk_values   = _json.dumps(risk_values)
    j_type_labels   = _json.dumps(type_labels)
    j_type_values   = _json.dumps(type_values)
    j_prio_values   = _json.dumps(prio_values)
    j_epss          = _json.dumps(epss_buckets)
    j_exploit_labels= _json.dumps(exploit_labels)
    j_exploit_values= _json.dumps(exploit_values)
    j_trend_labels  = _json.dumps(trend_labels)
    j_trend_values  = _json.dumps(trend_values)
    j_heatmap_types = _json.dumps(heatmap_types)
    j_heatmap_sevs  = _json.dumps(heatmap_sevs)
    j_heatmap_grid  = _json.dumps(heatmap_grid)
    j_tactic_names  = _json.dumps([t[0] for t in TACTICS])
    j_tactic_hits   = _json.dumps([tactic_hits.get(t[0], 0) for t in TACTICS])
    j_mitre_list    = _json.dumps(mitre_list[:80])
    j_vendor_list   = _json.dumps(vendor_list)

    # TTP simulation counts (for live data-driven descriptions in template)
    j_tactic_initial_access = tactic_hits.get("Initial Access", 0)
    j_tactic_cred_access    = tactic_hits.get("Cred Access", 0)
    j_tactic_execution      = tactic_hits.get("Execution", 0)
    j_tactic_c2             = tactic_hits.get("C2", 0)
    j_tactic_impact         = tactic_hits.get("Impact", 0)

    col_display = {
        "Type":"Type","ID":"ID","Severity":"Severity","Risk_Level":"Risk",
        "Remediation_Priority":"Priority","CISA_KEV":"KEV","EPSS_Score":"EPSS",
        "EPSS_Percentile":"EPSS%ile","Exploit_Status":"Exploit",
        "Confidence_Score":"Confidence","Description":"Description",
        "Affected_Products":"Affected","MITRE_Techniques":"MITRE",
        "ZDI_Advisory":"ZDI","AttackerKB_Score":"AttackerKB",
        "Source_Count":"Sources","Link":"Link","Timestamp":"Date",
        "Fix_Available":"Fix","CVSS":"CVSS"
    }
    th_cells = "".join(
        f'<th onclick="sortBy(\'{c}\')" data-col="{c}">{col_display.get(c,c)} <span class="sort-arrow"></span></th>'
        for c in avail
    )

    gen_time = datetime.now(CAIRO_TZ).strftime("%Y-%m-%d %H:%M")

    html = f"""<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>üê∫ ANUBIS ThreatHunter v6.0 ‚Äî AnubisX</title>
<style>
*{{box-sizing:border-box;margin:0;padding:0}}
:root{{
  --bg:#0a0a16;--bg2:#0e0e22;--bg3:#12122a;--bg4:#1a1a35;
  --border:#1f1f40;--accent:#e94560;--accent2:#9b59b6;
  --text:#d0d0e0;--muted:#777;--green:#27ae60;--orange:#e67e22;
  --red:#c0392b;--blue:#3498db;
}}
body{{font-family:'Segoe UI',system-ui,sans-serif;background:var(--bg);color:var(--text);font-size:13px;line-height:1.5}}
::-webkit-scrollbar{{width:6px;height:6px}}
::-webkit-scrollbar-track{{background:var(--bg2)}}
::-webkit-scrollbar-thumb{{background:var(--accent);border-radius:3px}}

/* HEADER */
header{{background:linear-gradient(135deg,#0f0f23,#1a1a3e 50%,#0f0f23);
       padding:18px 28px;border-bottom:2px solid var(--accent);
       display:flex;align-items:center;gap:16px;flex-wrap:wrap}}
.logo{{font-size:2.4rem}}
.header-text h1{{color:var(--accent);font-size:1.5rem;letter-spacing:1px;font-weight:800}}
.header-text p{{color:var(--muted);font-size:0.78rem;margin-top:2px}}
.header-meta{{margin-left:auto;text-align:right;color:#555;font-size:0.75rem;line-height:1.8}}
.header-meta strong{{color:var(--accent);font-size:1.05rem}}

/* PURPLE TEAM TOGGLE */
.team-toggle{{
  display:flex;align-items:center;gap:10px;
  padding:8px 16px;background:var(--bg3);border-radius:10px;
  border:1px solid var(--border);margin-left:20px}}
.team-btn{{
  padding:6px 18px;border-radius:7px;border:1px solid var(--border);
  background:var(--bg4);color:var(--muted);cursor:pointer;font-size:12px;
  font-weight:700;transition:all .2s;letter-spacing:.5px}}
.team-btn.red.active{{background:#7b0a0a;color:#ff6b6b;border-color:#e74c3c}}
.team-btn.blue.active{{background:#0a2a4a;color:#5dade2;border-color:#2980b9}}
.team-label{{color:var(--muted);font-size:11px;text-transform:uppercase;letter-spacing:.5px}}

/* TEAM MODE OVERLAY */
.team-panel{{
  margin:0 28px 16px;padding:14px 18px;border-radius:10px;
  border:1px solid var(--border);background:var(--bg3);
  display:none;
}}
.team-panel.red-panel{{border-color:#e74c3c}}
.team-panel.blue-panel{{border-color:#2980b9}}
.team-panel h3{{font-size:.85rem;font-weight:700;margin-bottom:10px;text-transform:uppercase;letter-spacing:.6px}}
.team-panel.red-panel h3{{color:#e74c3c}}
.team-panel.blue-panel h3{{color:#5dade2}}
.team-grid{{display:grid;grid-template-columns:repeat(auto-fit,minmax(280px,1fr));gap:12px}}
.team-card{{background:var(--bg4);border-radius:8px;padding:12px 14px;border:1px solid var(--border)}}
.team-card h4{{font-size:.78rem;font-weight:700;margin-bottom:6px;color:var(--text)}}
.team-card ul{{padding-left:14px;color:var(--muted);font-size:.75rem;line-height:1.7}}
.team-card li{{margin-bottom:2px}}
.team-card .tag{{
  display:inline-block;padding:1px 6px;border-radius:3px;
  font-size:.65rem;font-weight:800;margin:1px;
}}
.tag-red{{background:#7b0a0a;color:#ff8080}}
.tag-blue{{background:#0a2a4a;color:#5dade2}}
.tag-orange{{background:#7d3c00;color:#f0a500}}

/* CARDS */
.cards{{display:flex;flex-wrap:wrap;gap:12px;padding:18px 28px}}
.card{{background:var(--bg3);border:1px solid var(--border);border-radius:12px;
      padding:16px 20px;min-width:120px;flex:1;cursor:pointer;
      transition:transform .15s,border-color .15s;position:relative;overflow:hidden}}
.card::before{{content:"";position:absolute;inset:0;
  background:linear-gradient(135deg,transparent 60%,rgba(233,69,96,.06));pointer-events:none}}
.card:hover{{transform:translateY(-2px);border-color:var(--accent)}}
.card h3{{font-size:2rem;font-weight:800;line-height:1}}
.card p{{color:var(--muted);font-size:.7rem;margin-top:5px;text-transform:uppercase;letter-spacing:.8px}}
.card.crit h3{{color:var(--red)}} .card.p1 h3{{color:var(--orange)}}
.card.kev h3{{color:var(--red)}} .card.zdi h3{{color:var(--accent2)}}
.card.high h3{{color:var(--orange)}} .card.exploit h3{{color:var(--red)}}
.card.total h3{{color:var(--blue)}}
.card-icon{{position:absolute;top:10px;right:12px;font-size:1.4rem;opacity:.2}}

/* CHARTS GRID */
.charts{{display:grid;grid-template-columns:repeat(auto-fit,minmax(300px,1fr));gap:16px;padding:0 28px 16px}}
.chart-box{{background:var(--bg3);border:1px solid var(--border);border-radius:12px;padding:16px;transition:border-color .2s}}
.chart-box:hover{{border-color:#2c2c5a}}
.chart-box h2{{color:var(--accent);font-size:.82rem;margin-bottom:12px;border-bottom:1px solid var(--border);
              padding-bottom:7px;font-weight:700;text-transform:uppercase;letter-spacing:.6px}}
.chart-box.wide{{grid-column:span 2}}
.charts-two{{grid-template-columns:1fr 1fr!important}}
canvas{{display:block;width:100%!important}}

/* TTP SIMULATION */
.ttp-sim{{background:var(--bg3);border:1px solid var(--border);border-radius:12px;
          padding:16px 20px;margin:0 28px 16px;}}
.ttp-sim h2{{color:var(--accent);font-size:.82rem;margin-bottom:12px;border-bottom:1px solid var(--border);
             padding-bottom:7px;font-weight:700;text-transform:uppercase;letter-spacing:.6px}}
.ttp-chain{{display:flex;flex-wrap:wrap;gap:0;align-items:stretch;margin-bottom:14px}}
.ttp-step{{flex:1;min-width:120px;background:var(--bg4);border:1px solid var(--border);
            padding:10px 12px;position:relative;cursor:pointer;transition:border-color .15s}}
.ttp-step:hover{{border-color:var(--accent)}}
.ttp-step.active{{border-color:var(--accent);background:#1a0a16}}
.ttp-step .ttp-tactic{{font-size:.62rem;color:var(--muted);text-transform:uppercase;letter-spacing:.5px;margin-bottom:3px}}
.ttp-step .ttp-tech{{font-size:.7rem;font-weight:700;color:var(--text)}}
.ttp-step .ttp-tid{{font-size:.62rem;color:var(--accent);font-family:monospace;margin-top:2px}}
.ttp-step .ttp-heat{{height:3px;border-radius:2px;margin-top:6px;background:linear-gradient(90deg,#27ae60,#e67e22,#c0392b)}}
.ttp-detail{{background:var(--bg4);border:1px solid var(--border);border-radius:8px;padding:14px 16px;
             margin-top:8px;display:none}}
.ttp-detail.open{{display:grid;grid-template-columns:repeat(auto-fit,minmax(240px,1fr));gap:12px}}
.ttp-detail-card{{background:var(--bg3);border-radius:6px;padding:10px 12px;border:1px solid var(--border)}}
.ttp-detail-card h5{{font-size:.72rem;font-weight:700;color:var(--accent);margin-bottom:6px;text-transform:uppercase}}
.ttp-detail-card p{{font-size:.72rem;color:#bbb;line-height:1.6}}
.ttp-detail-card .code{{font-family:monospace;font-size:.68rem;color:#a0c4ff;background:#0a0a20;
                         padding:4px 8px;border-radius:4px;margin-top:6px;display:block;
                         white-space:pre-wrap;border:1px solid #1f1f50}}
.ttp-cvelist{{display:flex;flex-wrap:wrap;gap:4px;margin-top:6px}}
.ttp-cvetag{{background:#1a0a20;border:1px solid var(--accent);color:var(--accent);
             border-radius:3px;padding:1px 6px;font-size:.62rem;font-family:monospace;cursor:pointer}}
.ttp-cvetag:hover{{background:#2a0a30}}

/* HEATMAP LEGEND */
.hm-legend{{display:flex;align-items:center;gap:6px;margin-top:8px;justify-content:flex-end}}
.hm-gradient{{width:80px;height:10px;border-radius:3px;
  background:linear-gradient(90deg,#121234,#7b0a1a,#c0392b,#ff6b35)}}
.hm-legend span{{font-size:.65rem;color:var(--muted)}}

/* FILTER BAR */
.filter-bar{{display:flex;flex-wrap:wrap;align-items:center;gap:8px;
            padding:12px 28px;background:var(--bg2);border-top:1px solid var(--border);
            border-bottom:1px solid var(--border);margin-bottom:14px;
            position:sticky;top:0;z-index:100}}
.filter-bar input,.filter-bar select{{
  background:var(--bg3);border:1px solid #2c2c50;color:var(--text);
  padding:5px 10px;border-radius:6px;font-size:12px;outline:none;transition:border-color .2s}}
.filter-bar input{{width:220px}}
.filter-bar input:focus,.filter-bar select:focus{{border-color:var(--accent)}}
.filter-bar label{{color:#555;font-size:10px;text-transform:uppercase;letter-spacing:.5px}}
.filter-bar .range-wrap{{display:flex;align-items:center;gap:6px}}
.filter-bar input[type=range]{{width:90px;accent-color:var(--accent);height:16px;padding:0}}
.filter-bar .range-val{{color:var(--accent);font-size:11px;font-weight:700;min-width:28px}}
.btn{{background:var(--accent);color:#fff;border:none;padding:5px 12px;border-radius:6px;
      cursor:pointer;font-size:12px;font-weight:600;transition:opacity .2s}}
.btn:hover{{opacity:.85}}
.btn.secondary{{background:var(--bg4);border:1px solid var(--border);color:var(--text)}}
.active-filters{{display:flex;flex-wrap:wrap;gap:5px;padding:0 28px 10px}}
.pill{{background:var(--bg4);border:1px solid var(--accent);color:var(--accent);
      border-radius:20px;padding:2px 8px;font-size:10px;display:flex;align-items:center;gap:4px}}
.pill button{{background:none;border:none;color:var(--accent);cursor:pointer;padding:0;font-size:12px;line-height:1}}

/* MITRE FILTER PANEL */
.mitre-panel{{padding:0 28px 12px;display:none}}
.mitre-panel.open{{display:block}}
.mitre-panel-inner{{background:var(--bg3);border:1px solid var(--border);border-radius:10px;padding:12px 14px}}
.mitre-panel-inner h4{{color:var(--accent);font-size:.78rem;font-weight:700;margin-bottom:8px;text-transform:uppercase}}
.mitre-tags{{display:flex;flex-wrap:wrap;gap:5px}}
.mitre-tag{{
  padding:2px 8px;background:var(--bg4);border:1px solid var(--border);
  border-radius:4px;font-size:.68rem;cursor:pointer;color:var(--muted);
  transition:all .15s;font-weight:600}}
.mitre-tag.selected{{background:#1a0a2e;border-color:var(--accent2);color:#c39bd3}}

/* SECTION */
.section{{padding:0 28px 24px}}
.section h2{{color:var(--accent);font-size:.95rem;margin-bottom:12px;
            border-bottom:1px solid var(--border);padding-bottom:7px;
            font-weight:700;text-transform:uppercase;letter-spacing:.6px}}
.src-row{{display:flex;align-items:center;gap:10px;margin-bottom:6px}}
.src-label{{width:190px;font-size:.75rem;color:#aaa;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}}
.src-bar-wrap{{flex:1;background:#1a1a30;border-radius:3px;height:12px;overflow:hidden}}
.src-bar{{height:100%;border-radius:3px;transition:width .3s}}
.src-count{{width:55px;text-align:right;font-size:.75rem;color:var(--muted);font-weight:600}}

/* TABLE */
.table-wrap{{overflow-x:auto;border-radius:10px;border:1px solid var(--border)}}
table{{width:100%;border-collapse:collapse;background:var(--bg2)}}
thead{{position:sticky;top:0;z-index:10}}
th{{background:#1a0a12;color:var(--accent);padding:8px 10px;text-align:left;
    font-size:.73rem;white-space:nowrap;cursor:pointer;user-select:none;
    border-bottom:2px solid var(--accent);transition:background .15s}}
th:hover{{background:#2a0a18}}
th .sort-arrow{{color:#555;font-size:.6rem;margin-left:2px}}
th.sort-asc .sort-arrow::after{{content:"‚ñ≤";color:var(--accent)}}
th.sort-desc .sort-arrow::after{{content:"‚ñº";color:var(--accent)}}
td{{padding:6px 10px;border-bottom:1px solid #131328;vertical-align:top;font-size:11px}}
tr:hover td{{background:#14142a;cursor:pointer}}
tr.kev-row td:first-child{{border-left:3px solid var(--red)}}
.sev-badge{{display:inline-block;padding:1px 6px;border-radius:4px;color:#fff;font-size:.68rem;font-weight:700}}
.prio-badge{{display:inline-block;padding:1px 6px;border-radius:4px;color:#fff;font-size:.68rem;font-weight:700}}
.prio-P1{{background:#7b0a0a}} .prio-P2{{background:#7d3c00}}
.prio-P3{{background:#6b5b00}} .prio-P4{{background:#0f3d0f}}
.badge{{display:inline-block;padding:1px 5px;border-radius:3px;font-size:.62rem;font-weight:800;margin:1px}}
.badge.kev{{background:var(--red);color:#fff}}
.badge.zdi{{background:#6c3483;color:#fff}}
.badge.exp{{background:#873600;color:#fff}}
.desc-cell{{max-width:260px;color:#999;font-size:.72rem;line-height:1.4}}
a{{color:var(--accent);text-decoration:none}}
a:hover{{text-decoration:underline}}

/* PAGINATION */
.pagination{{display:flex;align-items:center;gap:6px;padding:12px 28px;justify-content:center}}
.page-btn{{background:var(--bg3);border:1px solid #2c2c50;color:#aaa;padding:4px 10px;
          border-radius:5px;cursor:pointer;font-size:11px;transition:all .15s}}
.page-btn:hover,.page-btn.active{{background:var(--accent);border-color:var(--accent);color:#fff}}
.table-stats{{display:flex;align-items:center;justify-content:space-between;
             padding:8px 28px;color:var(--muted);font-size:11px}}
.table-stats strong{{color:#aaa}}

/* DRILL-DOWN MODAL */
.modal-overlay{{
  position:fixed;inset:0;background:rgba(0,0,0,.85);z-index:1000;
  display:none;align-items:center;justify-content:center;padding:20px;
}}
.modal-overlay.open{{display:flex}}
.modal{{
  background:var(--bg3);border:1px solid var(--border);border-radius:14px;
  width:100%;max-width:800px;max-height:90vh;overflow-y:auto;
  box-shadow:0 24px 80px rgba(0,0,0,.6);
}}
.modal-header{{
  display:flex;align-items:center;justify-content:space-between;
  padding:16px 20px;border-bottom:1px solid var(--border);
  position:sticky;top:0;background:var(--bg3);z-index:2;
}}
.modal-header h2{{color:var(--accent);font-size:1rem;font-weight:800}}
.modal-close{{background:none;border:none;color:var(--muted);cursor:pointer;font-size:1.4rem;line-height:1}}
.modal-close:hover{{color:#fff}}
.modal-body{{padding:18px 20px}}
.modal-grid{{display:grid;grid-template-columns:1fr 1fr;gap:14px;margin-bottom:16px}}
.modal-section{{background:var(--bg4);border-radius:8px;padding:12px 14px;border:1px solid var(--border)}}
.modal-section.full{{grid-column:span 2}}
.modal-section h4{{font-size:.75rem;font-weight:700;text-transform:uppercase;
                  letter-spacing:.5px;margin-bottom:8px;color:var(--muted)}}
.modal-section .val{{font-size:.88rem;color:var(--text);font-weight:500;line-height:1.5}}
.modal-section .val a{{color:var(--blue)}}
.epss-bar{{height:8px;background:#1a1a30;border-radius:4px;margin-top:6px;overflow:hidden}}
.epss-fill{{height:100%;border-radius:4px;background:linear-gradient(90deg,var(--green),var(--orange),var(--red))}}
.kill-chain{{display:flex;flex-wrap:wrap;gap:6px;margin-top:6px}}
.kc-step{{
  padding:4px 10px;background:var(--bg3);border-radius:20px;
  font-size:.7rem;font-weight:700;border:1px solid var(--border);color:var(--muted);
}}
.kc-step.active{{background:#1a0a12;border-color:var(--red);color:var(--red)}}
.detection-rule{{
  background:#0a0a20;border:1px solid #1f1f50;border-radius:6px;
  padding:8px 12px;font-family:monospace;font-size:.72rem;color:#a0c4ff;
  margin-top:6px;white-space:pre-wrap;line-height:1.5;
}}
.hardening-list{{list-style:none;padding:0;margin-top:6px}}
.hardening-list li{{
  padding:4px 0;font-size:.75rem;color:var(--muted);
  border-bottom:1px solid var(--border);display:flex;gap:8px;align-items:flex-start}}
.hardening-list li::before{{content:"üõ°";font-size:.8rem;flex-shrink:0;margin-top:2px}}
.defend-tag{{
  display:inline-block;padding:2px 7px;border-radius:3px;font-size:.65rem;
  font-weight:700;margin:2px;background:#0a2a4a;color:#5dade2;border:1px solid #1a4060;
}}
.ransomware-badge{{
  display:inline-block;padding:3px 10px;border-radius:5px;font-size:.75rem;
  font-weight:700;margin-right:6px;
}}
.ransomware-badge.yes{{background:#7b0a0a;color:#ff6b6b;border:1px solid #e74c3c}}
.ransomware-badge.no{{background:#0f3d0f;color:#82e0aa;border:1px solid #27ae60}}
.modal-tabs{{display:flex;gap:6px;margin-bottom:14px}}
.modal-tab{{
  padding:6px 14px;border-radius:6px;border:1px solid var(--border);
  background:var(--bg4);color:var(--muted);cursor:pointer;font-size:.75rem;font-weight:600;
  transition:all .15s;
}}
.modal-tab.active.red{{background:#7b0a0a;color:#ff8080;border-color:#e74c3c}}
.modal-tab.active.blue{{background:#0a2a4a;color:#5dade2;border-color:#2980b9}}
.modal-tab.active.info{{background:#1a2a3e;color:#aaa;border-color:#3a4a5e}}
.modal-pane{{display:none}}
.modal-pane.active{{display:block}}

/* FOOTER */
.footer{{text-align:center;padding:16px;color:#444;font-size:.68rem;
        border-top:1px solid #1a1a30;margin-top:8px}}
</style>
</head>
<body>

<!-- ‚ïê‚ïê HEADER ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<header>
  <div class="logo">üê∫</div>
  <div class="header-text">
    <h1>ANUBIS ThreatHunter v6.0 ‚Äî AnubisX</h1>
    <p>‚öñÔ∏è Judge Every Threat, Protect Every Soul &nbsp;¬∑&nbsp; üéØ PharaonX RedTeam</p>
  </div>
  <div class="team-toggle">
    <span class="team-label">Team View:</span>
    <button class="team-btn red" id="redBtn" onclick="setTeam('red')">üî¥ Red Team</button>
    <button class="team-btn blue" id="blueBtn" onclick="setTeam('blue')">üîµ Blue Team</button>
    <button class="team-btn" id="neutralBtn" style="font-size:11px" onclick="setTeam('none')">‚úï</button>
  </div>
  <div class="header-meta">
    <div>üëë Ramiz Alsafi &nbsp;¬∑&nbsp; Generated: <strong>{gen_time}</strong></div>
    <div>Database: <strong>{total:,}</strong> threats</div>
  </div>
</header>

<!-- ‚ïê‚ïê PURPLE TEAM PANELS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="team-panel red-panel" id="redPanel">
  <h3>üî¥ Red Team Intelligence ‚Äî Attack Perspective</h3>
  <div class="team-grid">
    <div class="team-card">
      <h4>üí• High-Value Exploit Chains</h4>
      <ul>
        <li>Filter P1 + EXPLOIT badge ‚Üí prioritize initial access vectors</li>
        <li>Cross-reference KEV list with EPSS &gt;70% for active weaponization</li>
        <li>ZDI advisories indicate unpublished or limited-patch PoC availability</li>
        <li>Chain: Initial Access ‚Üí Execution ‚Üí Persistence ‚Üí Priv Esc ‚Üí Impact</li>
      </ul>
    </div>
    <div class="team-card">
      <h4>üó∫Ô∏è Kill Chain Mapping</h4>
      <ul>
        <li><span class="tag tag-red">TA0001</span> Initial Access ‚Äî phishing, supply chain, public-facing apps</li>
        <li><span class="tag tag-red">TA0002</span> Execution ‚Äî scripting, scheduled tasks, exploitation</li>
        <li><span class="tag tag-red">TA0005</span> Defense Evasion ‚Äî LOLBAS, obfuscation, rootkits</li>
        <li><span class="tag tag-red">TA0040</span> Impact ‚Äî ransomware, data destruction, exfil</li>
      </ul>
    </div>
    <div class="team-card">
      <h4>üéØ Priority Attack Paths</h4>
      <ul>
        <li>CRITICAL + KEV = immediate weaponization risk ‚Üí exploit within 24h</li>
        <li>AttackerKB score &gt;3 = community-validated exploitability</li>
        <li>Shodan-visible services + CVE overlap = exposed attack surface</li>
        <li>Ransomware-known CVEs ‚Üí double-extortion probability elevated</li>
      </ul>
    </div>
    <div class="team-card">
      <h4>‚ö° Quick Wins (Offensive)</h4>
      <ul>
        <li>Search MITRE panel for T1190 (public-facing exploit)</li>
        <li>Filter Exploit_Status = "PoC Available" or "Exploited in Wild"</li>
        <li>EPSS &gt;80% CVEs in CISA KEV = proven breach vector</li>
        <li>Cross-ref vendor filter with your target perimeter</li>
      </ul>
    </div>
  </div>
</div>

<div class="team-panel blue-panel" id="bluePanel">
  <h3>üîµ Blue Team Intelligence ‚Äî Defense Perspective</h3>
  <div class="team-grid">
    <div class="team-card">
      <h4>üõ°Ô∏è Detection Engineering</h4>
      <ul>
        <li>Map MITRE techniques to Sigma/YARA/Snort rules</li>
        <li>KEV entries ‚Üí trigger immediate vulnerability scanning</li>
        <li>Monitor AttackerKB score spikes for emerging PoC activity</li>
        <li>Set SIEM alerts on affected product names from drill-down</li>
      </ul>
    </div>
    <div class="team-card">
      <h4>üîí D3FEND Controls</h4>
      <ul>
        <li><span class="defend-tag">D3-NI</span> Network Isolation ‚Äî segment affected systems</li>
        <li><span class="defend-tag">D3-PSA</span> Process Spawn Analysis ‚Äî detect malicious execution</li>
        <li><span class="defend-tag">D3-PLF</span> Platform Monitoring ‚Äî OS-level telemetry</li>
        <li><span class="defend-tag">D3-UBA</span> User Behavior Analytics ‚Äî detect lateral movement</li>
        <li><span class="defend-tag">D3-PA</span> Patch &amp; Vulnerability Management ‚Äî apply fix_available</li>
      </ul>
    </div>
    <div class="team-card">
      <h4>üîß Hardening Checklist</h4>
      <ul>
        <li>P1 CVEs ‚Üí emergency patching within 24h, isolate if unpatched</li>
        <li>Disable unused services matching affected products</li>
        <li>Enable MFA on all admin interfaces exposed per Shodan data</li>
        <li>Update WAF/IDS signatures for current KEV exploit patterns</li>
        <li>Rotate credentials for affected vendor accounts immediately</li>
      </ul>
    </div>
    <div class="team-card">
      <h4>üìä Metrics to Track</h4>
      <ul>
        <li>Mean Time to Patch (MTTP) for P1 &lt; 24h, P2 &lt; 72h</li>
        <li>% of KEV CVEs patched in your environment</li>
        <li>EPSS score vs actual exploitation correlation</li>
        <li>Threat intel coverage: sources with 0 results = potential gaps</li>
      </ul>
    </div>
  </div>
</div>

<!-- ‚ïê‚ïê SUMMARY CARDS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="cards">
  <div class="card crit" onclick="applyQuickFilter('Risk_Level','CRITICAL')">
    <div class="card-icon">üî¥</div><h3>{crit_cnt}</h3><p>Critical</p>
  </div>
  <div class="card high" onclick="applyQuickFilter('Risk_Level','HIGH')">
    <div class="card-icon">üü†</div><h3>{high_cnt}</h3><p>High</p>
  </div>
  <div class="card p1" onclick="applyQuickFilter('Remediation_Priority','P1')">
    <div class="card-icon">üö®</div><h3>{p1_cnt}</h3><p>P1 Urgent</p>
  </div>
  <div class="card kev" onclick="applyQuickFilter('CISA_KEV','YES')">
    <div class="card-icon">‚ö†Ô∏è</div><h3>{kev_cnt}</h3><p>CISA KEV</p>
  </div>
  <div class="card zdi">
    <div class="card-icon">üéØ</div><h3>{zdi_cnt}</h3><p>ZDI Advisories</p>
  </div>
  <div class="card exploit" onclick="applyQuickFilter('Exploit','any')">
    <div class="card-icon">üí•</div><h3>{exploit_cnt}</h3><p>With Exploit</p>
  </div>
  <div class="card total">
    <div class="card-icon">üìä</div><h3>{total:,}</h3><p>Total Threats</p>
  </div>
</div>

<!-- ‚ïê‚ïê CHARTS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="charts">
  <div class="chart-box" id="riskBox">
    <h2>üìä Risk Level Distribution</h2>
    <canvas id="riskChart" height="220"></canvas>
  </div>
  <div class="chart-box" id="typeBox">
    <h2>üç© Top Threat Types</h2>
    <canvas id="typeChart" height="220"></canvas>
  </div>
  <div class="chart-box" id="prioBox">
    <h2>üö® Remediation Priority</h2>
    <canvas id="prioChart" height="220"></canvas>
  </div>
  <div class="chart-box">
    <h2>üîÆ EPSS Score Distribution <span id="epssNote" style="font-size:.65rem;color:#888;font-weight:400"></span></h2>
    <canvas id="epssChart" height="220"></canvas>
  </div>
  <div class="chart-box">
    <h2>üìà Threats by Date (Last 14 Days)</h2>
    <canvas id="trendChart" height="220"></canvas>
  </div>
  <div class="chart-box">
    <h2>‚ö° Exploit Status Breakdown</h2>
    <canvas id="exploitChart" height="220"></canvas>
  </div>
</div>

<!-- ‚ïê‚ïê THREAT PULSE SUMMARY ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="charts" style="margin-top:4px">
  <div class="chart-box" style="grid-column:span 2">
    <h2>‚ö° Exploit Intelligence Pulse</h2>
    <div id="exploitPulse" style="display:flex;gap:16px;flex-wrap:wrap;align-items:center;padding:8px 0"></div>
  </div>
  <div class="chart-box" style="grid-column:span 2">
    <h2>üè∑Ô∏è Top Affected Vendors</h2>
    <div id="vendorCloud" style="display:flex;gap:8px;flex-wrap:wrap;padding:8px 0;align-items:center;min-height:60px"></div>
  </div>
</div>

<!-- ‚ïê‚ïê HEATMAP + ATT&CK ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="charts charts-two" style="margin-top:4px">
  <div class="chart-box">
    <h2>üå°Ô∏è Risk Heatmap ‚Äî Type √ó Severity</h2>
    <canvas id="heatmapChart" height="380"></canvas>
    <div class="hm-legend">
      <span>Low</span><div class="hm-gradient"></div><span>Critical</span>
    </div>
  </div>
  <div class="chart-box">
    <h2>‚öîÔ∏è MITRE ATT&CK Tactic Coverage</h2>
    <canvas id="attackChart" height="380"></canvas>
  </div>
</div>

<!-- ‚ïê‚ïê TTP SIMULATION ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="ttp-sim">
  <h2>üéÆ Live TTP Simulation ‚Äî Click a Phase to Expand</h2>
  <div class="ttp-chain" id="ttpChain"></div>
  <div class="ttp-detail" id="ttpDetail"></div>
</div>

<!-- ‚ïê‚ïê SOURCE BREAKDOWN ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="section">
  <h2>üì° Source Volume Breakdown</h2>
  {src_rows}
</div>

<!-- ‚ïê‚ïê TOP-10 ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="section">
  <h2>üèÜ Top 10 Priority Threats</h2>
  <div class="table-wrap">
  <table id="top10Table">
    <thead><tr>
      <th>ID</th><th>Severity</th><th>Priority</th><th>Type</th>
      <th>EPSS%ile</th><th>Flags</th><th>Description</th>
    </tr></thead>
    <tbody id="top10Body">{top10_rows}</tbody>
  </table>
  </div>
</div>

<!-- ‚ïê‚ïê FILTER BAR ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="filter-bar" id="filterBar">
  <label>üîç</label>
  <input type="text" id="searchBox" placeholder="Search all fields‚Ä¶" oninput="applyFilters()">
  <label>Type:</label>
  <select id="typeFilter" onchange="applyFilters()"><option value="">All</option></select>
  <label>Severity:</label>
  <select id="sevFilter" onchange="applyFilters()">
    <option value="">All</option>
    <option>CRITICAL</option><option>HIGH</option><option>MEDIUM</option><option>LOW</option>
  </select>
  <label>Priority:</label>
  <select id="prioFilter" onchange="applyFilters()">
    <option value="">All</option>
    <option>P1</option><option>P2</option><option>P3</option><option>P4</option>
  </select>
  <label>KEV:</label>
  <select id="kevFilter" onchange="applyFilters()">
    <option value="">All</option><option>YES</option><option>NO</option>
  </select>
  <label>Vendor:</label>
  <select id="vendorFilter" onchange="applyFilters()"><option value="">All</option></select>
  <label>EPSS‚â•:</label>
  <div class="range-wrap">
    <input type="range" id="epssSlider" min="0" max="100" value="0" step="5" oninput="updateEpssLabel();applyFilters()">
    <span class="range-val" id="epssVal">0%</span>
  </div>
  <button class="btn secondary" onclick="toggleMitrePanel()">üß© MITRE</button>
  <button class="btn secondary" onclick="resetFilters()">‚úï Clear</button>
  <button class="btn" onclick="exportCSV()">‚¨á CSV</button>
</div>

<div class="mitre-panel" id="mitrePanel">
  <div class="mitre-panel-inner">
    <h4>üß© MITRE ATT&CK Technique Filter ‚Äî click to toggle (OR logic)</h4>
    <div class="mitre-tags" id="mitreTags"></div>
  </div>
</div>

<div class="active-filters" id="activePills"></div>

<div class="table-stats">
  <span>Showing <strong id="showingCount">0</strong> of <strong id="totalCount">{total:,}</strong></span>
  <span id="pageInfo"></span>
</div>

<div class="section" style="padding-top:0">
  <h2>üìã Full Threat Database ‚Äî click any row for details</h2>
  <div class="table-wrap">
  <table id="fullTable">
    <thead><tr id="fullTableHead">{th_cells}</tr></thead>
    <tbody id="fullTableBody"></tbody>
  </table>
  </div>
</div>
<div class="pagination" id="pagination"></div>

<!-- ‚ïê‚ïê DRILL-DOWN MODAL ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="modal-overlay" id="modalOverlay" onclick="closeModal(event)">
  <div class="modal" id="modal">
    <div class="modal-header">
      <h2 id="modalTitle">Threat Details</h2>
      <button class="modal-close" onclick="closeModalDirect()">‚úï</button>
    </div>
    <div class="modal-body">
      <div class="modal-tabs">
        <button class="modal-tab active info" id="tab-info" onclick="switchTab('info')">‚ÑπÔ∏è Details</button>
        <button class="modal-tab red" id="tab-red" onclick="switchTab('red')">üî¥ Red Team</button>
        <button class="modal-tab blue" id="tab-blue" onclick="switchTab('blue')">üîµ Blue Team</button>
      </div>
      <div class="modal-pane active" id="pane-info">
        <div class="modal-grid" id="modalInfoGrid"></div>
      </div>
      <div class="modal-pane" id="pane-red">
        <div class="modal-grid" id="modalRedGrid"></div>
      </div>
      <div class="modal-pane" id="pane-blue">
        <div class="modal-grid" id="modalBlueGrid"></div>
      </div>
    </div>
  </div>
</div>

<!-- ‚ïê‚ïê SOURCES MODAL BUTTON ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div style="text-align:center;padding:10px 28px 20px">
  <button class="btn" style="padding:10px 28px;font-size:13px;letter-spacing:.5px"
    onclick="document.getElementById('sourcesOverlay').classList.add('open')">
    üì° View All Intelligence Sources (57+)
  </button>
</div>

<!-- ‚ïê‚ïê SOURCES MODAL ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="modal-overlay" id="sourcesOverlay" onclick="if(event.target===this)this.classList.remove('open')">
  <div class="modal" style="max-width:960px">
    <div class="modal-header">
      <h2>üì° ANUBIS Intelligence Sources ‚Äî All 57 Active Feeds</h2>
      <button class="modal-close" onclick="document.getElementById('sourcesOverlay').classList.remove('open')">‚úï</button>
    </div>
    <div class="modal-body" style="padding:16px 20px">

      <div style="display:grid;grid-template-columns:repeat(auto-fit,minmax(420px,1fr));gap:16px">

        <!-- CVE & Vulnerability Feeds -->
        <div class="modal-section">
          <h4 style="color:#e94560">üî¥ CVE & Vulnerability Intelligence</h4>
          <table style="width:100%;border-collapse:collapse;font-size:.75rem">
            <tr style="color:#555;text-transform:uppercase;font-size:.65rem">
              <th style="padding:4px 6px;text-align:left">Source</th>
              <th style="padding:4px 6px;text-align:left">Type</th>
              
            </tr>
            <tr class="src-tr"><td>NVD (NIST)</td><td>CVE Feed</td></tr>
            <tr class="src-tr"><td>CISA KEV</td><td>Exploited CVEs</td></tr>
            <tr class="src-tr"><td>VulnCheck KEV</td><td>Enhanced KEV</td></tr>
            <tr class="src-tr"><td>CIRCL CVE API</td><td>CVE Details</td></tr>
            <tr class="src-tr"><td>Red Hat Security</td><td>RHSA Advisories</td></tr>
            <tr class="src-tr"><td>GitHub Advisory DB</td><td>OSS Vulns</td></tr>
            <tr class="src-tr"><td>OSV.dev</td><td>Multi-ecosystem</td></tr>
            <tr class="src-tr"><td>Vulners API</td><td>CVE Aggregator</td></tr>
            <tr class="src-tr"><td>ZDI (Zero Day Initiative)</td><td>0-day Research</td></tr>
            <tr class="src-tr"><td>AttackerKB</td><td>Exploit Research</td></tr>
            <tr class="src-tr"><td>EPSS (FIRST.org)</td><td>Exploit Probability</td></tr>
            <tr class="src-tr"><td>Exploit-DB</td><td>PoC Exploits</td></tr>
            <tr class="src-tr"><td>PacketStorm</td><td>Security Research</td></tr>
          </table>
        </div>

        <!-- Firewall & Network Vendors -->
        <div class="modal-section">
          <h4 style="color:#e67e22">üõ°Ô∏è Firewall & Network Vendor PSIRTs</h4>
          <table style="width:100%;border-collapse:collapse;font-size:.75rem">
            <tr style="color:#555;text-transform:uppercase;font-size:.65rem">
              <th style="padding:4px 6px;text-align:left">Vendor</th>
              <th style="padding:4px 6px;text-align:left">Advisory Feed</th>
              
            </tr>
            <tr class="src-tr"><td>Fortinet PSIRT</td><td>FortiGuard RSS</td></tr>
            <tr class="src-tr"><td>Palo Alto Networks</td><td>Security Advisories API</td></tr>
            <tr class="src-tr"><td>Cisco PSIRT</td><td>Security Advisories RSS</td></tr>
            <tr class="src-tr"><td>Juniper Networks</td><td>PSIRT RSS</td></tr>
            <tr class="src-tr"><td>F5 / BIG-IP</td><td>Security RSS</td></tr>
            <tr class="src-tr"><td>Citrix / NetScaler</td><td>Security Bulletins</td></tr>
            <tr class="src-tr"><td>SonicWall PSIRT</td><td>Security Advisories</td></tr>
            <tr class="src-tr"><td>Check Point</td><td>Security Bulletins</td></tr>
            <tr class="src-tr"><td>WatchGuard</td><td>Security RSS</td></tr>
            <tr class="src-tr"><td>Sophos</td><td>Security RSS</td></tr>
            <tr class="src-tr"><td>Aruba / HPE</td><td>Security RSS</td></tr>
            <tr class="src-tr"><td>Zyxel</td><td>Security Advisories</td></tr>
            <tr class="src-tr"><td>Barracuda</td><td>Security RSS</td></tr>
            <tr class="src-tr"><td>pfSense / Netgate</td><td>Security RSS</td></tr>
            <tr class="src-tr"><td>Microsoft MSRC</td><td>Security Updates API</td></tr>
          </table>
        </div>

        <!-- Threat Intelligence Platforms -->
        <div class="modal-section">
          <h4 style="color:#9b59b6">üëæ Threat Intelligence Platforms</h4>
          <table style="width:100%;border-collapse:collapse;font-size:.75rem">
            <tr style="color:#555;text-transform:uppercase;font-size:.65rem">
              <th style="padding:4px 6px;text-align:left">Source</th>
              <th style="padding:4px 6px;text-align:left">Data Type</th>
              
            </tr>
            <tr class="src-tr"><td>AlienVault OTX</td><td>Threat Pulses</td></tr>
            <tr class="src-tr"><td>ThreatFox (Abuse.ch)</td><td>IOC Feed</td></tr>
            <tr class="src-tr"><td>MalwareBazaar</td><td>Malware Samples</td></tr>
            <tr class="src-tr"><td>URLHaus (Abuse.ch)</td><td>Malicious URLs</td></tr>
            <tr class="src-tr"><td>Abuse.ch SSL Blacklist</td><td>Malicious SSL IPs</td></tr>
            <tr class="src-tr"><td>IPsum Threat Intel</td><td>Threat IP List</td></tr>
            <tr class="src-tr"><td>Feodo Tracker</td><td>Botnet C2 IPs</td></tr>
            <tr class="src-tr"><td>OpenPhish</td><td>Phishing URLs</td></tr>
            <tr class="src-tr"><td>SANS ISC</td><td>Threat Diary</td></tr>
          </table>
        </div>

        <!-- IP Reputation & Scanning -->
        <div class="modal-section">
          <h4 style="color:#27ae60">üåê IP Reputation & Attack Surface</h4>
          <table style="width:100%;border-collapse:collapse;font-size:.75rem">
            <tr style="color:#555;text-transform:uppercase;font-size:.65rem">
              <th style="padding:4px 6px;text-align:left">Source</th>
              <th style="padding:4px 6px;text-align:left">Data Type</th>
              
            </tr>
            <tr class="src-tr"><td>Shodan</td><td>Internet-exposed hosts</td></tr>
            <tr class="src-tr"><td>Censys</td><td>Vulnerable hosts / RDP</td></tr>
            <tr class="src-tr"><td>GreyNoise</td><td>Mass scanner intel</td></tr>
            <tr class="src-tr"><td>AbuseIPDB</td><td>Malicious IP reports</td></tr>
            <tr class="src-tr"><td>Blocklist.de</td><td>Reported attack IPs</td></tr>
            <tr class="src-tr"><td>Emerging Threats</td><td>Compromised IPs</td></tr>
            <tr class="src-tr"><td>Talos (CINSscore)</td><td>IP Reputation</td></tr>
            <tr class="src-tr"><td>FireHOL L1+L2</td><td>IP Blocklists</td></tr>
            <tr class="src-tr"><td>Tor Exit Nodes</td><td>Anonymization IPs</td></tr>
            <tr class="src-tr"><td>Have I Been Pwned</td><td>Breach Database</td></tr>
          </table>
        </div>

        <!-- News & Advisory Feeds -->
        <div class="modal-section">
          <h4 style="color:#3498db">üì∞ Security News & Advisory Feeds</h4>
          <table style="width:100%;border-collapse:collapse;font-size:.75rem">
            <tr style="color:#555;text-transform:uppercase;font-size:.65rem">
              <th style="padding:4px 6px;text-align:left">Source</th>
              <th style="padding:4px 6px;text-align:left">Type</th>
              
            </tr>
            <tr class="src-tr"><td>SecurityWeek</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>BleepingComputer</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>DarkReading</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>The Hacker News</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>KrebsOnSecurity</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>SecurityAffairs</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>SC Magazine</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>Wired Security</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>HackRead</td><td>News RSS</td></tr>
            <tr class="src-tr"><td>InfoSecurity Magazine</td><td>News RSS</td></tr>
          </table>
        </div>

        <!-- CISA & Government -->
        <div class="modal-section">
          <h4 style="color:#e74c3c">üèõÔ∏è Government & CERT Sources</h4>
          <table style="width:100%;border-collapse:collapse;font-size:.75rem">
            <tr style="color:#555;text-transform:uppercase;font-size:.65rem">
              <th style="padding:4px 6px;text-align:left">Source</th>
              <th style="padding:4px 6px;text-align:left">Coverage</th>
              
            </tr>
            <tr class="src-tr"><td>CISA KEV</td><td>Exploited vulns</td></tr>
            <tr class="src-tr"><td>CISA ICS Advisories</td><td>OT/ICS systems</td></tr>
            <tr class="src-tr"><td>CISA Ransomware Advisories</td><td>Ransomware TTPs</td></tr>
            <tr class="src-tr"><td>NCSC UK / CISA Advisories</td><td>Gov alerts</td></tr>
            <tr class="src-tr"><td>Ubuntu Security Notices</td><td>Linux advisories</td></tr>
            <tr class="src-tr"><td>Patch Tuesday Data</td><td>Microsoft cadence</td></tr>
            <tr class="src-tr"><td>MITRE ATT&amp;CK</td><td>TTP mapping</td></tr>
          </table>
        </div>

      </div>

      <div style="margin-top:16px;padding:12px 14px;background:var(--bg4);border-radius:8px;border:1px solid var(--border)">
        <div style="font-size:.75rem;color:#777;line-height:1.8">
          <strong style="color:#aaa">Total:</strong> 57 concurrent sources ¬∑ Up to 1,734+ threats per run ¬∑ 168h lookback window
          <br>
          <strong style="color:#aaa">Enrichment:</strong> EPSS scores ¬∑ AttackerKB community scores ¬∑ GreyNoise IP context ¬∑ ZDI cross-correlation ¬∑ MITRE ATT&amp;CK mapping
        </div>
      </div>

    </div>
  </div>
</div>

<style>
.src-tr td {{ padding:4px 6px; border-bottom:1px solid #131328; color:#bbb; }}
.src-tr:last-child td {{ border-bottom:none }}
.src-tr:hover td {{ background:#14142a; color:#fff; }}
</style>

<!-- ‚ïê‚ïê FOOTER ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê -->
<div class="footer">
  üê∫ ANUBIS ThreatHunter v6.0 ‚Äî AnubisX &nbsp;¬∑&nbsp; PharaonX RedTeam &nbsp;¬∑&nbsp; üëë Ramiz Alsafi<br>
  Self-contained ¬∑ No backend ¬∑ No external libraries
</div>

<script>
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// DATA ‚Äî all rows embedded, no API keys, no external libs
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
const ALL_DATA   = {all_data_json};
const COLS       = {_json.dumps(avail)};
const PAGE_SIZE  = 50;

const SEV_COLORS = {{CRITICAL:"#c0392b",HIGH:"#e67e22",MEDIUM:"#f39c12",LOW:"#27ae60"}};
const PRIO_COLORS = {{P1:"#7b0a0a",P2:"#7d3c00",P3:"#6b5b00",P4:"#0f3d0f"}};
const PAL = ["#e94560","#e67e22","#27ae60","#3498db","#9b59b6","#1abc9c","#f39c12","#e74c3c","#2ecc71","#8e44ad"];

let filteredData   = [...ALL_DATA];
let currentPage    = 1;
let sortCol        = null;
let sortAsc        = true;
let selectedMitre  = new Set();
let currentTeam    = "none";
let activeRow      = null;

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// PURE CANVAS CHART ENGINE
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function dpr() {{ return window.devicePixelRatio || 1; }}

function setupCanvas(id, h) {{
  const el = document.getElementById(id);
  if (!el) return null;
  const parent = el.parentElement;
  const w = parent.clientWidth - 32;
  el.style.width  = w + "px";
  el.style.height = h + "px";
  el.width  = w * dpr();
  el.height = h * dpr();
  const ctx = el.getContext("2d");
  ctx.scale(dpr(), dpr());
  return {{ctx, w, h}};
}}

// ‚îÄ‚îÄ Bar Chart ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function drawBarChart(id, labels, values, colors, h, onClick) {{
  const c = setupCanvas(id, h||200); if (!c) return;
  const {{ctx,w}} = c; const height = h||200;
  const pad={{l:40,r:14,t:14,b:50}};
  const cw = w - pad.l - pad.r, ch = height - pad.t - pad.b;
  const max = Math.max(...values, 1);
  const bw = Math.min(60, (cw / labels.length) * 0.6);
  const gap = (cw - bw * labels.length) / (labels.length + 1);

  ctx.clearRect(0, 0, w, height);
  // Grid lines
  for (let i=0; i<=4; i++) {{
    const y = pad.t + ch - (ch * i / 4);
    ctx.strokeStyle = "#1a1a30"; ctx.lineWidth = 1;
    ctx.beginPath(); ctx.moveTo(pad.l, y); ctx.lineTo(pad.l + cw, y); ctx.stroke();
    ctx.fillStyle = "#666"; ctx.font = "10px sans-serif"; ctx.textAlign = "right";
    ctx.fillText(Math.round(max * i / 4).toLocaleString(), pad.l - 4, y + 3);
  }}

  labels.forEach((lbl, i) => {{
    const x = pad.l + gap + i * (bw + gap);
    const bh = (values[i] / max) * ch;
    const y  = pad.t + ch - bh;
    const col = Array.isArray(colors) ? colors[i % colors.length] : colors;
    // Gradient
    const grad = ctx.createLinearGradient(x, y, x, pad.t + ch);
    grad.addColorStop(0, col + "ee"); grad.addColorStop(1, col + "55");
    ctx.fillStyle = grad;
    // Rounded bar
    const r = 4;
    ctx.beginPath();
    ctx.moveTo(x + r, y); ctx.lineTo(x + bw - r, y);
    ctx.quadraticCurveTo(x + bw, y, x + bw, y + r);
    ctx.lineTo(x + bw, pad.t + ch); ctx.lineTo(x, pad.t + ch);
    ctx.lineTo(x, y + r); ctx.quadraticCurveTo(x, y, x + r, y); ctx.fill();
    // Label
    ctx.fillStyle = "#888"; ctx.font = "10px sans-serif"; ctx.textAlign = "center";
    const short = lbl.length > 10 ? lbl.slice(0,9)+"‚Ä¶" : lbl;
    ctx.fillText(short, x + bw/2, pad.t + ch + 14);
    // Value on top
    if (values[i] > 0) {{
      ctx.fillStyle = "#aaa"; ctx.font = "bold 10px sans-serif";
      ctx.fillText(values[i].toLocaleString(), x + bw/2, y - 4);
    }}
  }});

  // Click handler
  if (onClick) {{
    const el = document.getElementById(id);
    el.onclick = function(ev) {{
      const rect = el.getBoundingClientRect();
      const mx   = (ev.clientX - rect.left) / dpr();
      labels.forEach((lbl, i) => {{
        const x = pad.l + gap + i * (bw + gap);
        if (mx >= x && mx <= x + bw) onClick(lbl, i);
      }});
    }};
  }}
}}

// ‚îÄ‚îÄ Donut Chart ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function drawDonutChart(id, labels, values, colors, h, onClick) {{
  const c = setupCanvas(id, h||200); if (!c) return;
  const {{ctx,w}} = c; const height = h||200;
  const cx = w * 0.38, cy = height / 2;
  const r  = Math.min(cx, cy) - 14;
  const ri = r * 0.55;
  const total = values.reduce((a,b) => a+b, 0) || 1;

  ctx.clearRect(0, 0, w, height);
  let angle = -Math.PI/2;
  values.forEach((v, i) => {{
    const slice = (v / total) * Math.PI * 2;
    const col   = colors[i % colors.length];
    ctx.beginPath();
    ctx.moveTo(cx, cy);
    ctx.arc(cx, cy, r, angle, angle + slice);
    ctx.closePath();
    ctx.fillStyle = col + "cc";
    ctx.fill();
    ctx.strokeStyle = "#0a0a16"; ctx.lineWidth = 2;
    ctx.stroke();
    angle += slice;
  }});
  // Hole
  ctx.beginPath(); ctx.arc(cx, cy, ri, 0, Math.PI*2);
  ctx.fillStyle = "#0e0e22"; ctx.fill();
  // Center text
  ctx.fillStyle = "#e94560"; ctx.font = "bold 14px sans-serif"; ctx.textAlign = "center";
  ctx.fillText(total.toLocaleString(), cx, cy + 4);
  ctx.fillStyle = "#555"; ctx.font = "9px sans-serif";
  ctx.fillText("total", cx, cy + 16);
  // Legend
  const lx = w * 0.72, ly0 = 16;
  labels.forEach((lbl, i) => {{
    const ly = ly0 + i * 18;
    if (ly + 12 > height) return;
    ctx.fillStyle = colors[i % colors.length];
    ctx.fillRect(lx, ly, 10, 10);
    ctx.fillStyle = "#999"; ctx.font = "10px sans-serif"; ctx.textAlign = "left";
    const short = lbl.length > 14 ? lbl.slice(0,13)+"‚Ä¶" : lbl;
    ctx.fillText(short + " (" + values[i] + ")", lx + 14, ly + 9);
  }});

  if (onClick) {{
    const el = document.getElementById(id);
    el.onclick = function(ev) {{
      const rect = el.getBoundingClientRect();
      const mx = ev.clientX - rect.left - cx;
      const my = ev.clientY - rect.top - cy;
      const dist = Math.sqrt(mx*mx + my*my);
      if (dist < ri || dist > r) return;
      let a = Math.atan2(my, mx) - (-Math.PI/2);
      if (a < 0) a += Math.PI*2;
      let cumAngle = 0;
      for (let i=0; i<values.length; i++) {{
        cumAngle += (values[i]/total)*Math.PI*2;
        if (a <= cumAngle) {{ onClick(labels[i], i); break; }}
      }}
    }};
  }}
}}

// ‚îÄ‚îÄ Line Chart ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function drawLineChart(id, labels, values, color, h) {{
  const c = setupCanvas(id, h||150); if (!c) return;
  const {{ctx,w}} = c; const height = h||150;
  const pad={{l:40,r:14,t:14,b:36}};
  const cw = w - pad.l - pad.r, ch = height - pad.t - pad.b;
  const max = Math.max(...values, 1);
  const n = labels.length; if (n < 2) return;
  const step = cw / (n - 1);

  ctx.clearRect(0, 0, w, height);
  // Grid
  for (let i=0; i<=4; i++) {{
    const y = pad.t + ch * (1 - i/4);
    ctx.strokeStyle="#1a1a30"; ctx.lineWidth=1;
    ctx.beginPath(); ctx.moveTo(pad.l, y); ctx.lineTo(pad.l+cw, y); ctx.stroke();
    ctx.fillStyle="#555"; ctx.font="9px sans-serif"; ctx.textAlign="right";
    ctx.fillText(Math.round(max*i/4), pad.l-4, y+3);
  }}
  // Fill gradient
  const area = ctx.createLinearGradient(0, pad.t, 0, pad.t+ch);
  area.addColorStop(0, (color||"#e94560") + "44");
  area.addColorStop(1, (color||"#e94560") + "00");
  ctx.beginPath();
  ctx.moveTo(pad.l, pad.t+ch);
  values.forEach((v, i) => {{
    const x = pad.l + i*step, y = pad.t + ch - (v/max)*ch;
    if (i===0) ctx.lineTo(x, y); else ctx.lineTo(x, y);
  }});
  ctx.lineTo(pad.l + (n-1)*step, pad.t+ch); ctx.closePath();
  ctx.fillStyle = area; ctx.fill();
  // Line
  ctx.beginPath(); ctx.strokeStyle = color||"#e94560"; ctx.lineWidth=2;
  values.forEach((v, i) => {{
    const x = pad.l + i*step, y = pad.t + ch - (v/max)*ch;
    i===0 ? ctx.moveTo(x,y) : ctx.lineTo(x,y);
  }});
  ctx.stroke();
  // Dots + labels
  values.forEach((v, i) => {{
    const x = pad.l + i*step, y = pad.t + ch - (v/max)*ch;
    ctx.beginPath(); ctx.arc(x, y, 3, 0, Math.PI*2);
    ctx.fillStyle = color||"#e94560"; ctx.fill();
    if (i % Math.max(1, Math.floor(n/10)) === 0) {{
      ctx.fillStyle="#666"; ctx.font="9px sans-serif"; ctx.textAlign="center";
      ctx.fillText(labels[i], x, pad.t+ch+14);
    }}
  }});
}}

// ‚îÄ‚îÄ Heatmap ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function drawHeatmap(id, rowLabels, colLabels, grid, h) {{
  const c = setupCanvas(id, h||260); if (!c) return;
  const {{ctx,w}} = c; const height = h||260;
  const padL = 135, padT = 36, padR = 16, padB = 20;
  const cw = w - padL - padR, ch = height - padT - padB;
  const cols = colLabels.length, rows = rowLabels.length;
  const bw = cw / cols, bh = ch / rows;
  const max = Math.max(...grid.flat(), 1);
  ctx.clearRect(0, 0, w, height);
  const sevColors = ["#e74c3c","#e67e22","#f39c12","#27ae60"];
  colLabels.forEach((lbl, ci) => {{
    const x = padL + ci*bw + bw/2;
    ctx.fillStyle = sevColors[ci]+"33";
    ctx.fillRect(padL+ci*bw+1, padT-26, bw-2, 22);
    ctx.fillStyle = sevColors[ci]; ctx.font="bold 10px sans-serif"; ctx.textAlign="center";
    ctx.fillText(lbl, x, padT-10);
  }});
  grid.forEach((row, ri) => {{
    ctx.fillStyle="#bbb"; ctx.font="10px sans-serif"; ctx.textAlign="right";
    const short=rowLabels[ri].length>20?rowLabels[ri].slice(0,19)+"‚Ä¶":rowLabels[ri];
    ctx.fillText(short,padL-8,padT+ri*bh+bh/2+4);
    ctx.strokeStyle="#1a1a35"; ctx.lineWidth=1;
    ctx.beginPath(); ctx.moveTo(padL,padT+ri*bh); ctx.lineTo(padL+cw,padT+ri*bh); ctx.stroke();
    row.forEach((v,ci) => {{
      const intensity=v/max;
      let r,g,b;
      if (intensity<0.001) {{r=18;g=18;b=52;}}
      else if (intensity<0.3) {{const t=intensity/0.3;r=Math.round(18+105*t);g=Math.round(18*(1-t));b=Math.round(52*(1-t)+10*t);}}
      else if (intensity<0.7) {{const t=(intensity-0.3)/0.4;r=Math.round(123+80*t);g=Math.round(10+20*t);b=10;}}
      else {{const t=(intensity-0.7)/0.3;r=Math.round(203+30*t);g=Math.round(30+50*t);b=Math.round(10+30*t);}}
      ctx.fillStyle=`rgb(${{r}},${{g}},${{b}})`;
      ctx.fillRect(padL+ci*bw+1,padT+ri*bh+1,bw-2,bh-2);
      if (v>0) {{
        ctx.fillStyle=intensity>0.4?"#fff":"#ccc";
        ctx.font="9px sans-serif"; ctx.textAlign="center";
        ctx.fillText(v.toLocaleString(),padL+ci*bw+bw/2,padT+ri*bh+bh/2+4);
      }}
    }});
  }});
  colLabels.forEach((_,ci) => {{
    ctx.strokeStyle="#1a1a35"; ctx.lineWidth=1;
    ctx.beginPath(); ctx.moveTo(padL+ci*bw,padT); ctx.lineTo(padL+ci*bw,padT+ch); ctx.stroke();
  }});
  ctx.beginPath(); ctx.moveTo(padL+cw,padT); ctx.lineTo(padL+cw,padT+ch); ctx.stroke();
}}

// ‚îÄ‚îÄ Horizontal Bar (Exploit Status) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function drawHorizBarChart(id, labels, values, colors, h) {{
  const c = setupCanvas(id, h||220); if (!c) return;
  const {{ctx,w}} = c; const height=h||220;
  const padL=120,padR=70,padT=14,padB=14;
  const cw=w-padL-padR, ch=height-padT-padB;
  const max=Math.max(...values,1);
  const bh=Math.floor((ch/labels.length)*0.62);
  const gap=(ch-bh*labels.length)/(labels.length+1);
  const total=values.reduce((a,b)=>a+b,0)||1;
  ctx.clearRect(0,0,w,height);
  labels.forEach((lbl,i) => {{
    const y=padT+gap+i*(bh+gap);
    const bwi=(values[i]/max)*cw;
    const col=colors[i%colors.length];
    const pct=((values[i]/total)*100).toFixed(1);
    ctx.fillStyle="#13132a"; ctx.fillRect(padL,y,cw,bh);
    if (bwi>1) {{
      const grad=ctx.createLinearGradient(padL,0,padL+bwi,0);
      grad.addColorStop(0,col+"ff"); grad.addColorStop(1,col+"77");
      ctx.fillStyle=grad;
      const r4=Math.min(4,bh/2);
      ctx.beginPath();
      ctx.moveTo(padL,y+r4); ctx.arcTo(padL,y,padL+r4,y,r4);
      ctx.lineTo(padL+bwi-r4,y); ctx.arcTo(padL+bwi,y,padL+bwi,y+r4,r4);
      ctx.lineTo(padL+bwi,y+bh-r4); ctx.arcTo(padL+bwi,y+bh,padL+bwi-r4,y+bh,r4);
      ctx.lineTo(padL+r4,y+bh); ctx.arcTo(padL,y+bh,padL,y+bh-r4,r4);
      ctx.closePath(); ctx.fill();
    }}
    ctx.fillStyle="#bbb"; ctx.font="bold 10px sans-serif"; ctx.textAlign="right";
    ctx.fillText(lbl,padL-6,y+bh/2+4);
    ctx.fillStyle="#aaa"; ctx.font="10px sans-serif"; ctx.textAlign="left";
    ctx.fillText(`${{values[i].toLocaleString()}} (${{pct}}%)`,padL+bwi+6,y+bh/2+4);
  }});
  ctx.strokeStyle="#2c2c4a"; ctx.lineWidth=1;
  ctx.beginPath(); ctx.moveTo(padL,padT); ctx.lineTo(padL,padT+ch); ctx.stroke();
}}

// ‚îÄ‚îÄ ATT&CK Horizontal Bar (v6.2 ‚Äî log scale, improved coverage) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function drawAttackChart(id, tactics, hits, h) {{
  const height = h || 380;
  const c = setupCanvas(id, height); if (!c) return;
  const {{ctx, w}} = c;
  const padL = 130, padR = 72, padT = 28, padB = 14;
  const cw = w - padL - padR, ch = height - padT - padB;
  const total = hits.reduce((a, b) => a + b, 0) || 1;
  // Log scale: log1p so zero entries still render a tiny bar
  const logHits = hits.map(v => Math.log1p(v));
  const maxLog  = Math.max(...logHits, 1);
  const bh  = Math.max(16, Math.floor((ch / tactics.length) * 0.72));
  const gap = Math.max(3, (ch - bh * tactics.length) / (tactics.length + 1));

  ctx.clearRect(0, 0, w, height);

  // Header label
  ctx.fillStyle = "#888"; ctx.font = "9px sans-serif"; ctx.textAlign = "left";
  ctx.fillText("‚Üê log scale", padL + 4, padT - 8);
  ctx.fillStyle = "#555"; ctx.textAlign = "right";
  ctx.fillText("threats", padL - 6, padT - 8);

  tactics.forEach((t, i) => {{
    const y = padT + gap + i * (bh + gap);
    // Alternating row bg
    if (i % 2 === 0) {{
      ctx.fillStyle = "rgba(255,255,255,0.018)";
      ctx.fillRect(0, y - gap / 2, w, bh + gap);
    }}
    // Track bar (background)
    ctx.fillStyle = "#0d0d24";
    ctx.fillRect(padL, y, cw, bh);

    const logVal = logHits[i];
    const bwi = (logVal / maxLog) * cw;
    const heat = hits[i] / total;   // fraction of total for colour
    // Colour: blue(0) ‚Üí orange(mid) ‚Üí red(high)
    const cr = Math.min(255, Math.round(52 + 203 * heat));
    const cg = Math.round(Math.max(0, 152 - 120 * heat));
    const cb = Math.max(10, Math.round(219 - 190 * heat));
    const col = `rgb(${{cr}},${{cg}},${{cb}})`;

    if (bwi > 1) {{
      const grad = ctx.createLinearGradient(padL, 0, padL + bwi, 0);
      grad.addColorStop(0, col + "ff");
      grad.addColorStop(1, col + "77");
      ctx.fillStyle = grad;
      const r4 = Math.min(4, bh / 2);
      ctx.beginPath();
      ctx.moveTo(padL, y + r4); ctx.arcTo(padL, y, padL + r4, y, r4);
      ctx.lineTo(padL + bwi - r4, y); ctx.arcTo(padL + bwi, y, padL + bwi, y + r4, r4);
      ctx.lineTo(padL + bwi, y + bh - r4); ctx.arcTo(padL + bwi, y + bh, padL + bwi - r4, y + bh, r4);
      ctx.lineTo(padL + r4, y + bh); ctx.arcTo(padL, y + bh, padL, y + bh - r4, r4);
      ctx.closePath(); ctx.fill();
    }}

    // Tactic label (right-aligned to axis)
    ctx.fillStyle = hits[i] > 0 ? "#c8c8e0" : "#555";
    ctx.font = hits[i] > 0 ? "bold 10px sans-serif" : "10px sans-serif";
    ctx.textAlign = "right";
    ctx.fillText(t, padL - 8, y + bh / 2 + 4);

    // Count label (right of bar, or inside if large)
    if (hits[i] === 0) {{
      ctx.fillStyle = "#3a3a5a"; ctx.font = "9px sans-serif"; ctx.textAlign = "left";
      ctx.fillText("0", padL + 5, y + bh / 2 + 4);
    }} else {{
      const pct = ((hits[i] / total) * 100).toFixed(1);
      const label = `${{hits[i].toLocaleString()}} (${{pct}}%)`;
      ctx.fillStyle = "#e0e0f4"; ctx.font = "bold 9px sans-serif"; ctx.textAlign = "left";
      ctx.fillText(label, padL + bwi + 6, y + bh / 2 + 4);
    }}
  }});

  // Axis line
  ctx.strokeStyle = "#3a3a6a"; ctx.lineWidth = 1;
  ctx.beginPath(); ctx.moveTo(padL, padT - 4); ctx.lineTo(padL, padT + ch + 4); ctx.stroke();
}}

// ‚îÄ‚îÄ Init Charts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
const riskColors  = ["#c0392b","#e67e22","#f39c12","#27ae60"];
const prioColors  = ["#7b0a0a","#7d3c00","#6b5b00","#0f3d0f"];

function drawAllCharts() {{
  drawBarChart("riskChart",  {j_risk_labels},  {j_risk_values},  riskColors, 220,
    lbl => applyQuickFilter("Risk_Level", lbl));
  drawDonutChart("typeChart", {j_type_labels}, {j_type_values}, PAL, 220,
    lbl => applyQuickFilter("Type", lbl));
  drawBarChart("prioChart", ["P1","P2","P3","P4"], {j_prio_values}, prioColors, 220,
    (lbl,i) => applyQuickFilter("Remediation_Priority", ["P1","P2","P3","P4"][i]));
  const epssVals = {j_epss};
  const epssLabels = ["0‚Äì10%","10‚Äì20%","20‚Äì30%","30‚Äì40%","40‚Äì50%","50‚Äì60%","60‚Äì70%","70‚Äì80%","80‚Äì90%","90‚Äì100%"];
  drawBarChart("epssChart", epssLabels, epssVals, "#3498db", 220, null, true);
  if (epssVals[0]>0 && epssVals.slice(1).every(v=>v===0)) {{
    // EPSS data not available this run ‚Äî show clean placeholder
    const epssEl = document.getElementById("epssChart");
    const ctx2 = epssEl.getContext("2d");
    const dpr2 = window.devicePixelRatio || 1;
    const cw2 = epssEl.width / dpr2, ch2 = epssEl.height / dpr2;
    ctx2.clearRect(0, 0, cw2, ch2);
    ctx2.fillStyle = "#0d0d1f";
    ctx2.fillRect(0, 0, cw2, ch2);
    ctx2.strokeStyle = "#2c2c4a"; ctx2.lineWidth = 1;
    ctx2.strokeRect(1, 1, cw2 - 2, ch2 - 2);
    ctx2.font = "bold 12px sans-serif"; ctx2.textAlign = "center";
    ctx2.fillStyle = "#555";
    ctx2.fillText("EPSS data unavailable", cw2 / 2, ch2 / 2 - 8);
    ctx2.font = "9px sans-serif"; ctx2.fillStyle = "#3a3a5a";
    ctx2.fillText("Scores will populate on next enriched run", cw2 / 2, ch2 / 2 + 12);
  }}
  if ({j_trend_labels}.length >= 2) {{
    drawLineChart("trendChart", {j_trend_labels}, {j_trend_values}, "#e94560", 220);
  }} else {{
    drawBarChart("trendChart", {j_type_labels}.slice(0,7), {j_type_values}.slice(0,7), "#e94560", 220);
    document.querySelector("#trendChart").parentElement.querySelector("h2").textContent = "üìä Top Threat Types";
  }}
  drawHorizBarChart("exploitChart", {j_exploit_labels}, {j_exploit_values},
    ["#c0392b","#666666","#27ae60","#3498db","#9b59b6","#1abc9c"], 220);
  drawHeatmap("heatmapChart", {j_heatmap_types}, {j_heatmap_sevs}, {j_heatmap_grid}, 380);
  drawAttackChart("attackChart", {j_tactic_names}, {j_tactic_hits}, 380);
  buildTTPSimulation();
  buildExploitPulse();
  buildVendorCloud();
}}

window.addEventListener("resize", drawAllCharts);

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// EXPLOIT PULSE + VENDOR CLOUD
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function buildExploitPulse() {{
  const pulseEl = document.getElementById("exploitPulse");
  if (!pulseEl) return;
  const total = ALL_DATA.length;
  const kev   = ALL_DATA.filter(r => r.CISA_KEV === "YES").length;
  const exploited = ALL_DATA.filter(r => (r.Exploit_Status||"").toUpperCase() === "YES").length;
  const high  = ALL_DATA.filter(r => (r.Exploit_Status||"").toUpperCase() === "HIGH").length;
  const p1    = ALL_DATA.filter(r => r.Remediation_Priority === "P1").length;
  const p2    = ALL_DATA.filter(r => r.Remediation_Priority === "P2").length;

  const stats = [
    {{ label: "Total Threats",    val: total.toLocaleString(),     color: "#3498db" }},
    {{ label: "CISA KEV",         val: kev.toLocaleString(),       color: "#e94560" }},
    {{ label: "Confirmed Exploit", val: exploited.toLocaleString(), color: "#e74c3c" }},
    {{ label: "High Exploit Risk", val: high.toLocaleString(),     color: "#e67e22" }},
    {{ label: "P1 Critical",      val: p1.toLocaleString(),        color: "#c0392b" }},
    {{ label: "P2 High Priority", val: p2.toLocaleString(),        color: "#7d5c00" }},
  ];
  pulseEl.innerHTML = stats.map(s =>
    `<div style="background:#0d0d1f;border:1px solid #1f1f50;border-radius:8px;padding:12px 20px;text-align:center;min-width:110px">
      <div style="font-size:1.4rem;font-weight:700;color:${s.color}">${s.val}</div>
      <div style="font-size:.68rem;color:#888;margin-top:4px">${s.label}</div>
    </div>`
  ).join("");
}}

function buildVendorCloud() {{
  const vendorEl = document.getElementById("vendorCloud");
  if (!vendorEl) return;
  const vendorMap = {{}};
  const vendorField = ALL_DATA[0] && ALL_DATA[0].Vendor ? "Vendor" :
                      ALL_DATA[0] && ALL_DATA[0].Source ? "Source" : null;
  if (!vendorField) {{ vendorEl.innerHTML = "<span style='color:#444;font-size:.75rem'>No vendor data</span>"; return; }}
  ALL_DATA.forEach(r => {{
    const v = r[vendorField];
    if (v && v !== "nan" && v !== "None" && v !== "") {{
      vendorMap[v] = (vendorMap[v] || 0) + 1;
    }}
  }});
  const sorted = Object.entries(vendorMap).sort((a,b)=>b[1]-a[1]).slice(0,25);
  const maxCount = sorted[0]?.[1] || 1;
  const colors = ["#e94560","#e67e22","#f39c12","#27ae60","#3498db","#9b59b6","#1abc9c","#e74c3c","#2ecc71","#8e44ad"];
  vendorEl.innerHTML = sorted.map(([vendor, count], i) => {{
    const size = 0.65 + (count / maxCount) * 0.55;
    const col = colors[i % colors.length];
    return `<span onclick="applyQuickFilter('Source', '${vendor}')" title="${vendor}: ${count} threats" style="font-size:${size.toFixed(2)}rem;color:${col};cursor:pointer;background:#0d0d1f;border:1px solid #1f1f50;padding:3px 10px;border-radius:20px;transition:background .15s" onmouseover="this.style.background='#14142a'" onmouseout="this.style.background='#0d0d1f'">${vendor} <span style='color:#555;font-size:.65rem'>${count}</span></span>`;
  }}).join("");
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// FILTER DROPDOWNS ‚Äî populate
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function populateSelect(id, values) {{
  const sel = document.getElementById(id);
  values.forEach(v => {{
    const o = document.createElement("option");
    o.value = v; o.textContent = v; sel.appendChild(o);
  }});
}}
populateSelect("typeFilter",   [...new Set(ALL_DATA.map(r=>r.Type||"").filter(Boolean))].sort());
populateSelect("vendorFilter", {j_vendor_list});

// MITRE tags
const mitreList = {j_mitre_list};
const mitreCont = document.getElementById("mitreTags");
mitreList.forEach(m => {{
  const t = document.createElement("span");
  t.className = "mitre-tag"; t.textContent = m;
  t.onclick = () => {{
    if (selectedMitre.has(m)) {{ selectedMitre.delete(m); t.classList.remove("selected"); }}
    else {{ selectedMitre.add(m); t.classList.add("selected"); }}
    applyFilters();
  }};
  mitreCont.appendChild(t);
}});

function toggleMitrePanel() {{
  const p = document.getElementById("mitrePanel");
  p.classList.toggle("open");
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// FILTER LOGIC
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function updateEpssLabel() {{
  const v = document.getElementById("epssSlider").value;
  document.getElementById("epssVal").textContent = v + "%";
}}

function applyFilters() {{
  const q      = document.getElementById("searchBox").value.toLowerCase().trim();
  const type   = document.getElementById("typeFilter").value;
  const sev    = document.getElementById("sevFilter").value;
  const prio   = document.getElementById("prioFilter").value;
  const kev    = document.getElementById("kevFilter").value;
  const vendor = document.getElementById("vendorFilter").value;
  const epssMin = parseInt(document.getElementById("epssSlider").value) / 100;

  filteredData = ALL_DATA.filter(r => {{
    if (type   && (r.Type||"") !== type) return false;
    if (sev    && (r.Severity||"") !== sev) return false;
    if (prio   && (r.Remediation_Priority||"") !== prio) return false;
    if (kev    && (r.CISA_KEV||"") !== kev) return false;
    if (vendor && !(r.Affected_Products||"").includes(vendor)) return false;
    if (epssMin > 0) {{
      const e = parseFloat(r.EPSS_Percentile||r.EPSS_Score||0);
      if (e < epssMin) return false;
    }}
    if (selectedMitre.size > 0) {{
      const m = r.MITRE_Techniques||"";
      const hit = [...selectedMitre].some(t => m.includes(t));
      if (!hit) return false;
    }}
    if (q) return COLS.some(c => String(r[c]||"").toLowerCase().includes(q));
    return true;
  }});

  if (sortCol) doSort(sortCol, false);
  currentPage = 1;
  renderTable(); renderPagination(); renderPills();
  document.getElementById("showingCount").textContent = filteredData.length.toLocaleString();
}}

function resetFilters() {{
  document.getElementById("searchBox").value = "";
  ["typeFilter","sevFilter","prioFilter","kevFilter","vendorFilter"].forEach(id => {{
    document.getElementById(id).value = "";
  }});
  document.getElementById("epssSlider").value = 0;
  document.getElementById("epssVal").textContent = "0%";
  selectedMitre.clear();
  document.querySelectorAll(".mitre-tag.selected").forEach(t => t.classList.remove("selected"));
  applyFilters();
}}

function applyQuickFilter(col, val) {{
  if (col === "Risk_Level") document.getElementById("sevFilter").value = val;
  else if (col === "Remediation_Priority") document.getElementById("prioFilter").value = val;
  else if (col === "CISA_KEV") document.getElementById("kevFilter").value = val;
  else if (col === "Type") document.getElementById("typeFilter").value = val;
  else if (col === "Exploit") {{
    const sel = document.getElementById("sevFilter");
    if (sel.options.length > 1) sel.value = sel.options[1].value;
  }}
  applyFilters();
  document.getElementById("filterBar").scrollIntoView({{behavior:"smooth",block:"start"}});
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// SORT
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function sortBy(col) {{
  if (sortCol === col) sortAsc = !sortAsc;
  else {{ sortCol = col; sortAsc = true; }}
  doSort(col, true); renderTable(); renderPagination();
  document.querySelectorAll("#fullTableHead th").forEach(th => {{
    th.classList.remove("sort-asc","sort-desc");
    if (th.dataset.col === col) th.classList.add(sortAsc?"sort-asc":"sort-desc");
  }});
}}

function doSort(col) {{
  filteredData.sort((a,b) => {{
    let av=a[col]||"", bv=b[col]||"";
    if (["EPSS_Score","EPSS_Percentile","CVSS","AttackerKB_Score","Source_Count"].includes(col)) {{
      av=parseFloat(av)||0; bv=parseFloat(bv)||0;
    }} else if (col==="Remediation_Priority") {{
      const m={{P1:1,P2:2,P3:3,P4:4}}; av=m[av]||9; bv=m[bv]||9;
    }} else if (["Severity","Risk_Level"].includes(col)) {{
      const m={{CRITICAL:1,HIGH:2,MEDIUM:3,LOW:4}}; av=m[av]||9; bv=m[bv]||9;
    }} else {{ av=String(av).toLowerCase(); bv=String(bv).toLowerCase(); }}
    return sortAsc?(av<bv?-1:av>bv?1:0):(av>bv?-1:av<bv?1:0);
  }});
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// TABLE RENDERER
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
const NON_VALS = new Set(["NONE","N/A","","None","nan","No known exploit"]);

function renderTable() {{
  const tbody = document.getElementById("fullTableBody");
  const start = (currentPage-1)*PAGE_SIZE;
  const page  = filteredData.slice(start, start+PAGE_SIZE);

  tbody.innerHTML = page.map((r, idx) => {{
    const isKev = (r.CISA_KEV||"") === "YES";
    const globalIdx = start + idx;
    const cells = COLS.map(c => {{
      let v = r[c]||""; v = String(v).replace(/</g,"&lt;").replace(/>/g,"&gt;");
      if (c==="Severity") {{
        const sc=SEV_COLORS[v]||"#555";
        return `<td><span class="sev-badge" style="background:${{sc}}">${{v||"?"}}</span></td>`;
      }}
      if (c==="Remediation_Priority") return `<td><span class="prio-badge prio-${{v||"P4"}}">${{v||"?"}}</span></td>`;
      if (c==="CISA_KEV") return `<td>${{v==="YES"?'<span class="badge kev">KEV</span>':v}}</td>`;
      if (c==="ZDI_Advisory" && !NON_VALS.has(v)) return `<td><span class="badge zdi">ZDI</span></td>`;
      if (c==="Exploit_Status" && !NON_VALS.has(v)) return `<td><span class="badge exp">${{v.slice(0,18)}}</span></td>`;
      if (c==="Link" && v && v!=="nan") return `<td><a href="${{v}}" target="_blank" onclick="event.stopPropagation()">${{r.ID||"link"}}</a></td>`;
      if (c==="Description") return `<td class="desc-cell" title="${{v}}">${{v.slice(0,110)}}${{v.length>110?"‚Ä¶":""}}</td>`;
      if (c==="EPSS_Score"||c==="EPSS_Percentile") {{
        const num=parseFloat(v)||0;
        return `<td>${{num>0?(num*100).toFixed(1)+"%":"‚Äì"}}</td>`;
      }}
      return `<td>${{v.slice(0,70)}}</td>`;
    }}).join("");
    return `<tr class="${{isKev?"kev-row":""}}" onclick="openModal(ALL_DATA[${{filteredData.indexOf ? filteredData.indexOf(r) : globalIdx}}])">${{cells}}</tr>`;
  }}).join("");
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// PAGINATION
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function renderPagination() {{
  const ttl   = filteredData.length;
  const pages = Math.ceil(ttl/PAGE_SIZE);
  const el    = document.getElementById("pagination");
  const info  = document.getElementById("pageInfo");
  info.textContent = `Page ${{currentPage}} / ${{pages}} (${{ttl.toLocaleString()}} rows)`;

  let h = `<button class="page-btn" onclick="goPage(1)">¬´</button>`;
  h += `<button class="page-btn" onclick="goPage(${{currentPage-1}})">‚Äπ</button>`;
  for (let p=Math.max(1,currentPage-3); p<=Math.min(pages,currentPage+3); p++) {{
    h += `<button class="page-btn ${{p===currentPage?"active":""}}" onclick="goPage(${{p}})">${{p}}</button>`;
  }}
  h += `<button class="page-btn" onclick="goPage(${{currentPage+1}})">‚Ä∫</button>`;
  h += `<button class="page-btn" onclick="goPage(${{pages}})">¬ª</button>`;
  el.innerHTML = h;
}}

function goPage(p) {{
  const pages = Math.ceil(filteredData.length/PAGE_SIZE);
  currentPage = Math.max(1, Math.min(p, pages));
  renderTable(); renderPagination();
  document.getElementById("fullTable").scrollIntoView({{behavior:"smooth",block:"start"}});
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// ACTIVE PILLS
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function renderPills() {{
  const filters = [
    ["typeFilter","Type"],["sevFilter","Severity"],["prioFilter","Priority"],
    ["kevFilter","KEV"],["vendorFilter","Vendor"]
  ];
  const q = document.getElementById("searchBox").value.trim();
  const epss = parseInt(document.getElementById("epssSlider").value);
  let html = "";
  if (q) html += `<span class="pill">üîç "${{q}}" <button onclick="document.getElementById('searchBox').value='';applyFilters()">√ó</button></span>`;
  filters.forEach(([id,lbl]) => {{
    const v = document.getElementById(id).value;
    if (v) html += `<span class="pill">${{lbl}}: ${{v}} <button onclick="document.getElementById('${{id}}').value='';applyFilters()">√ó</button></span>`;
  }});
  if (epss > 0) html += `<span class="pill">EPSS‚â•${{epss}}% <button onclick="document.getElementById('epssSlider').value=0;updateEpssLabel();applyFilters()">√ó</button></span>`;
  selectedMitre.forEach(m => {{
    html += `<span class="pill">MITRE: ${{m}} <button onclick="selectedMitre.delete('${{m}}');document.querySelectorAll('.mitre-tag').forEach(t=>{{if(t.textContent==='${{m}}')t.classList.remove('selected')}});applyFilters()">√ó</button></span>`;
  }});
  document.getElementById("activePills").innerHTML = html;
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// CSV EXPORT
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function exportCSV() {{
  const header = COLS.join(",");
  const rows = filteredData.map(r => COLS.map(c => {{
    const v = String(r[c]||"").replace(/"/g,'""');
    return v.includes(",") || v.includes('"') || v.includes("\\n") ? `"${{v}}"` : v;
  }}).join(",")).join("\\n");
  const blob = new Blob([header+"\\n"+rows], {{type:"text/csv"}});
  const a = document.createElement("a");
  a.href = URL.createObjectURL(blob); a.download = "anubis_export.csv"; a.click();
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// PURPLE TEAM TOGGLE
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
function setTeam(mode) {{
  currentTeam = mode;
  document.getElementById("redPanel").style.display  = mode==="red"  ? "block" : "none";
  document.getElementById("bluePanel").style.display = mode==="blue" ? "block" : "none";
  document.getElementById("redBtn").classList.toggle("active", mode==="red");
  document.getElementById("blueBtn").classList.toggle("active", mode==="blue");
  document.getElementById("neutralBtn").style.opacity = mode==="none" ? "0.4" : "1";
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// DRILL-DOWN MODAL
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
const KILL_CHAIN = ["Recon","Weaponize","Delivery","Exploit","Install","C2","Act on Obj"];
const KC_MAP = {{
  "Initial Access":   ["Delivery","Exploit"],
  "Execution":        ["Exploit","Install"],
  "Persistence":      ["Install"],
  "Priv Esc":         ["Install"],
  "Defense Evasion":  ["Exploit","Install","C2"],
  "Credential Access":["Install","C2"],
  "Discovery":        ["C2"],
  "Lateral Movement": ["C2","Act on Obj"],
  "Collection":       ["Act on Obj"],
  "Exfiltration":     ["Act on Obj"],
  "Impact":           ["Act on Obj"],
  "C2":               ["C2"],
}};

function inferKillChainSteps(r) {{
  const active = new Set();
  const mitre  = r.MITRE_Techniques||"";
  const exp    = r.Exploit_Status||"";
  const type   = r.Type||"";
  if (r.CISA_KEV==="YES" || !["NONE","N/A","","None","No known exploit"].includes(exp)) {{
    active.add("Exploit"); active.add("Delivery");
  }}
  if (type.toLowerCase().includes("malware") || type.toLowerCase().includes("trojan")) {{
    active.add("Install"); active.add("C2");
  }}
  if (type.toLowerCase().includes("ransomware") || type.toLowerCase().includes("impact")) {{
    active.add("Act on Obj");
  }}
  if (mitre.includes("T1566") || mitre.includes("T1190")) active.add("Delivery");
  if (mitre.includes("T1059") || mitre.includes("T1203")) active.add("Exploit");
  if (mitre.includes("T1547") || mitre.includes("T1053")) active.add("Install");
  if (mitre.includes("T1071") || mitre.includes("T1095")) active.add("C2");
  if (active.size > 0) active.add("Recon"); // If any step is active, recon precedes
  return active;
}}

function genDetectionRule(r) {{
  const id   = r.ID||"CVE-UNKNOWN";
  const prods= r.Affected_Products||"Unknown Product";
  const mitre= r.MITRE_Techniques||"N/A";
  return `# Sigma Rule ‚Äî ${{id}}
title: Detect exploitation attempt for ${{id}}
status: experimental
description: >
  Detects exploitation of ${{id}} affecting ${{prods.slice(0,60)}}
  MITRE: ${{mitre.slice(0,60)}}
logsource:
  category: process_creation
  product: windows
detection:
  selection:
    CommandLine|contains:
      - "${{id}}"
      - "exploit"
  condition: selection
falsepositives: [Security scanning tools]
level: high`;
}}

function genHardeningSteps(r) {{
  const steps = [];
  const sev   = r.Severity||"";
  const prod  = r.Affected_Products||"";
  const fix   = r.Fix_Available||r.Patch_Available||"";
  if (["CRITICAL","HIGH"].includes(sev)) steps.push("Apply vendor patch immediately ‚Äî P1 SLA: 24 hours");
  if (fix && !["NONE","N/A","","None"].includes(fix)) steps.push(`Apply fix: ${{fix.slice(0,80)}}`);
  steps.push("Isolate affected systems if patch unavailable");
  steps.push(`Scan environment for ${{prod.slice(0,40)||"affected software"}} installations`);
  steps.push("Enable enhanced logging on affected services (EventID 4688, 4625, 4776)");
  steps.push("Update EDR/AV signatures to detect associated malware families");
  steps.push("Review access controls ‚Äî principle of least privilege on affected resources");
  steps.push("Verify backup integrity for business-critical data on affected systems");
  return steps;
}}

function genDefendControls(r) {{
  const mitre = r.MITRE_Techniques||"";
  const tags = ["D3-PA (Patch & Vuln Mgmt)"];
  if (mitre.includes("T1190") || mitre.includes("T1566")) tags.push("D3-RUEX (Executable Allowlisting)");
  if (mitre.includes("T1059")) tags.push("D3-SCA (Script Content Analysis)");
  if (mitre.includes("T1547")) tags.push("D3-BA (Boot Record Analysis)");
  if (mitre.includes("T1071") || mitre.includes("T1095")) tags.push("D3-NI (Network Isolation)");
  if (mitre.includes("T1003") || mitre.includes("T1110")) tags.push("D3-CSA (Credential Stuffing Analysis)");
  tags.push("D3-NTA (Network Traffic Analysis)");
  tags.push("D3-UBA (User Behavior Analytics)");
  return tags;
}}

function isRansomwareLinked(r) {{
  const desc = (r.Description||"").toLowerCase();
  const type = (r.Type||"").toLowerCase();
  const news = (r.News_Coverage||"").toLowerCase();
  const keywords = ["ransomware","lockbit","conti","blackcat","revil","ryuk","clop","maze","darkside"];
  return keywords.some(k => desc.includes(k) || type.includes(k) || news.includes(k));
}}

function openModal(r) {{
  if (!r) return;
  activeRow = r;
  const ovl   = document.getElementById("modalOverlay");
  const title = document.getElementById("modalTitle");
  title.textContent = (r.ID||"Unknown") + " ‚Äî " + (r.Type||"Threat");

  const sev    = r.Severity||"?";
  const sevCol = SEV_COLORS[sev]||"#777";
  const epss   = parseFloat(r.EPSS_Percentile||r.EPSS_Score||0);
  const epssW  = Math.min(100, Math.round(epss * 100));
  const kc     = inferKillChainSteps(r);
  const kcHtml = KILL_CHAIN.map(s =>
    `<span class="kc-step ${{kc.has(s)?"active":""}}">${{s}}</span>`).join("");
  const ransomware = isRansomwareLinked(r);
  const mitres = (r.MITRE_Techniques||"").split(/[,;| ]+/).filter(m => /T[0-9]{{4}}/.test(m));

  // ‚îÄ‚îÄ INFO PANE ‚îÄ‚îÄ
  document.getElementById("modalInfoGrid").innerHTML = `
    <div class="modal-section">
      <h4>Threat ID / Type</h4>
      <div class="val">
        <strong style="color:var(--accent);font-size:1rem">${{r.ID||"N/A"}}</strong><br>
        ${{r.Type||"Unknown"}} &nbsp; <span class="sev-badge" style="background:${{sevCol}}">${{sev}}</span>
        &nbsp; <span class="prio-badge prio-${{r.Remediation_Priority||"P4"}}">${{r.Remediation_Priority||"?"}}</span>
      </div>
    </div>
    <div class="modal-section">
      <h4>EPSS Score</h4>
      <div class="val">
        <strong style="color:${{epss>0.7?"#e74c3c":epss>0.4?"#e67e22":"#27ae60"}};font-size:1.1rem">
          ${{epss>0?(epss*100).toFixed(1)+"%":"N/A"}}
        </strong>
        ${{epss>0?`<br><small style="color:#666">Percentile: top ${{(100-epss*100).toFixed(0)}}%</small>`:""}}</div>
      <div class="epss-bar"><div class="epss-fill" style="width:${{epssW}}%"></div></div>
    </div>
    <div class="modal-section">
      <h4>CISA KEV / Exploit Status</h4>
      <div class="val">
        ${{r.CISA_KEV==="YES"?'<span class="badge kev">‚úì CISA KEV ‚Äî Actively Exploited</span>':"Not in KEV"}}
        <br>${{r.Exploit_Status||"No known exploit"}}
      </div>
    </div>
    <div class="modal-section">
      <h4>Ransomware Association</h4>
      <div class="val">
        <span class="ransomware-badge ${{ransomware?"yes":"no"}}">${{ransomware?"‚ö†Ô∏è LINKED":"‚úÖ No Known Link"}}</span>
        ${{ransomware?"<br><small style='color:#ff8080'>Mentioned in ransomware-related threat feeds or news</small>":""}}
      </div>
    </div>
    <div class="modal-section full">
      <h4>Description</h4>
      <div class="val" style="color:#bbb;line-height:1.6">${{(r.Description||"N/A").replace(/</g,"&lt;").replace(/>/g,"&gt;")}}</div>
    </div>
    <div class="modal-section full">
      <h4>Affected Products / Vendors</h4>
      <div class="val">${{(r.Affected_Products||"N/A").replace(/</g,"&lt;")}}</div>
    </div>
    <div class="modal-section">
      <h4>MITRE ATT&CK Techniques</h4>
      <div class="val">
        ${{mitres.length ? mitres.map(t => `<span class="defend-tag">${{t}}</span>`).join(" ") : "N/A"}}
      </div>
    </div>
    <div class="modal-section">
      <h4>Confidence / Sources</h4>
      <div class="val">${{r.Confidence_Score||"N/A"}} &nbsp;&nbsp; Sources: <strong>${{r.Source_Count||1}}</strong></div>
    </div>
    ${{r.Link&&r.Link!=="nan"?`<div class="modal-section full"><h4>Reference Link</h4><div class="val"><a href="${{r.Link}}" target="_blank">${{r.Link}}</a></div></div>`:""}}
  `;

  // ‚îÄ‚îÄ RED TEAM PANE ‚îÄ‚îÄ
  const hardenSteps = genHardeningSteps(r);
  document.getElementById("modalRedGrid").innerHTML = `
    <div class="modal-section full">
      <h4>üó∫Ô∏è Kill Chain Mapping</h4>
      <div class="kill-chain">${{kcHtml}}</div>
    </div>
    <div class="modal-section full">
      <h4>üí• Exploit Context</h4>
      <div class="val">
        <strong>Status:</strong> ${{r.Exploit_Status||"No known exploit"}}<br>
        <strong>AttackerKB Score:</strong> ${{r.AttackerKB_Score||"0"}} / 10<br>
        <strong>ZDI Advisory:</strong> ${{r.ZDI_Advisory||"NONE"}}<br>
        <strong>CVSS:</strong> ${{r.CVSS||"N/A"}}<br>
        <strong>KEV (active in wild):</strong> ${{r.CISA_KEV==="YES"?"‚úì YES ‚Äî actively exploited":"No"}}
      </div>
    </div>
    <div class="modal-section full">
      <h4>‚ö° Attack Path Summary</h4>
      <div class="val" style="color:#bbb">
        ${{r.CISA_KEV==="YES" ? "‚ö†Ô∏è <strong>WEAPONIZED</strong> ‚Äî This CVE is in CISA KEV: confirmed exploitation in the wild.<br>" : ""}}
        ${{parseFloat(r.EPSS_Percentile||0) > 0.7 ? "üìà <strong>HIGH EPSS</strong> ‚Äî Top 30% likelihood of exploitation in next 30 days.<br>" : ""}}
        ${{r.AttackerKB_Score > 3 ? "üî¨ <strong>COMMUNITY VALIDATED</strong> ‚Äî AttackerKB score indicates active research/PoC discussion.<br>" : ""}}
        ${{ransomware ? "üí∞ <strong>RANSOMWARE LINKED</strong> ‚Äî Associated with ransomware threat actors. Double-extortion risk.<br>" : ""}}
        Affected: ${{(r.Affected_Products||"Unknown").slice(0,100)}}
      </div>
    </div>
  `;

  // ‚îÄ‚îÄ BLUE TEAM PANE ‚îÄ‚îÄ
  const defendTags = genDefendControls(r);
  document.getElementById("modalBlueGrid").innerHTML = `
    <div class="modal-section full">
      <h4>üìã Detection Rule (Sigma)</h4>
      <div class="detection-rule">${{genDetectionRule(r).replace(/</g,"&lt;").replace(/>/g,"&gt;")}}</div>
    </div>
    <div class="modal-section">
      <h4>üõ°Ô∏è D3FEND Controls</h4>
      <div class="val" style="margin-top:4px">
        ${{defendTags.map(t => `<span class="defend-tag">${{t}}</span>`).join(" ")}}
      </div>
    </div>
    <div class="modal-section">
      <h4>üîß Mitigation Actions</h4>
      <ul class="hardening-list">
        ${{hardenSteps.map(s => `<li>${{s.replace(/</g,"&lt;")}}</li>`).join("")}}
      </ul>
    </div>
    <div class="modal-section full">
      <h4>üìä Remediation Metadata</h4>
      <div class="val">
        <strong>Priority:</strong> ${{r.Remediation_Priority||"?"}} &nbsp;&nbsp;
        <strong>Fix Available:</strong> ${{r.Fix_Available||r.Patch_Available||"Unknown"}} &nbsp;&nbsp;
        <strong>Timestamp:</strong> ${{r.Timestamp||"N/A"}}<br>
        <strong>GreyNoise:</strong> ${{r.GreyNoise_Context||"N/A"}}<br>
        <strong>Intel URL:</strong> ${{r.Intel_URL&&r.Intel_URL!=="NONE"?`<a href="${{r.Intel_URL}}" target="_blank">${{r.Intel_URL.slice(0,60)}}</a>`:"N/A"}}
      </div>
    </div>
  `;

  switchTab("info");
  ovl.classList.add("open");
  document.body.style.overflow = "hidden";
}}

function switchTab(tab) {{
  ["info","red","blue"].forEach(t => {{
    document.getElementById("tab-"+t).classList.toggle("active", t===tab);
    document.getElementById("tab-"+t).classList.toggle(t, t===tab);
    document.getElementById("pane-"+t).classList.toggle("active", t===tab);
  }});
}}

function closeModal(ev) {{
  if (ev.target === document.getElementById("modalOverlay")) closeModalDirect();
}}

function closeModalDirect() {{
  document.getElementById("modalOverlay").classList.remove("open");
  document.body.style.overflow = "";
}}

document.addEventListener("keydown", ev => {{ if (ev.key === "Escape") closeModalDirect(); }});

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// TTP SIMULATION ‚Äî derives from live data
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
const TTP_DB = (function() {{
  // Build top-5 TTPs from actual data
  const tacticMap = {{
    "T1190":"Initial Access","T1566":"Initial Access","T1133":"Initial Access",
    "T1059":"Execution","T1203":"Execution","T1106":"Execution",
    "T1552":"Cred Access","T1110":"Cred Access","T1003":"Cred Access",
    "T1071":"C2","T1090":"C2","T1568":"C2",
    "T1486":"Impact","T1490":"Impact","T1499":"Impact",
  }};
  const techCount = {{}};
  ALL_DATA.forEach(r => {{
    const m = (r.MITRE_Techniques||"").match(/T\\d{{4}}(?:\\.\\d{{3}})?/g)||[];
    m.forEach(t => {{ techCount[t]=(techCount[t]||0)+1; }});
  }});
  // CVE lookup by technique
  const techToCVEs = {{}};
  ALL_DATA.forEach(r => {{
    if (!r.ID || !r.ID.startsWith("CVE")) return;
    const m = (r.MITRE_Techniques||"").match(/T\\d{{4}}(?:\\.\\d{{3}})?/g)||[];
    m.forEach(t => {{
      if (!techToCVEs[t]) techToCVEs[t]=[];
      if (techToCVEs[t].length<3) techToCVEs[t].push(r.ID);
    }});
  }});
  return {{techCount, techToCVEs, tacticMap}};
}})();

const TTP_STEPS = [
  {{ tactic:"Initial Access", tid:"T1190", tech:"Exploit Public-Facing App", icon:"üåê",
    desc:"Adversary exploits a vulnerability in an internet-facing application. This dataset has {j_tactic_initial_access} threats mapped to Initial Access ‚Äî the dominant attack vector.",
    sigma:`title: Exploit Attempt on Public App\ndetection:\n  http:\n    StatusCode: [500,400,403]\n    RequestMethod: POST\n    URI|contains: ["SELECT","UNION","../","eval(","<script"]\n  condition: http`,
    red:"Target CISA KEV CVEs in this dataset ‚Äî confirmed weaponized exploits. P1 + KEV = exploit within 24h.",
    blue:"WAF rules updated within 2h of new KEV entry. Monitor for anomalous POST body patterns at web gateways." }},
  {{ tactic:"Credential Access", tid:"T1552", tech:"Unsecured Credentials", icon:"üîë",
    desc:"Hardcoded, leaked, or default credentials. {j_tactic_cred_access} threats map here ‚Äî highest tactic after Initial Access. Hardcoded credentials are especially dangerous in IoT/OT environments.",
    sigma:`title: Default Credential Login Success\ndetection:\n  auth:\n    Username|in: ["admin","root","guest","administrator","test"]\n    EventID: 4624\n    LogonType: 3\n  condition: auth`,
    red:"Search dataset for KEV+CRITICAL entries ‚Äî many involve hardcoded creds. Dell RecoverPoint is a confirmed example.",
    blue:"Credential rotation SOP: rotate default creds on any system matching KEV affected products within 4h of advisory." }},
  {{ tactic:"Execution", tid:"T1059", tech:"Command & Script Interpreter", icon:"üíª",
    desc:"Post-exploitation command execution. {j_tactic_execution} threats map here ‚Äî typically chained after Initial Access via RCE vulnerabilities mapped from CWE-78/94/502.",
    sigma:`title: Web Shell Command Execution\ndetection:\n  process:\n    ParentImage|endswith: ["\\\\w3wp.exe","\\\\nginx.exe","\\\\apache2"]\n    Image|endswith: ["\\\\cmd.exe","\\\\powershell.exe","\\\\sh"]\n  condition: process`,
    red:"Use SOLIDWORKS eDrawings chain (OOB-read ‚Üí OOB-write ‚Üí RCE) ‚Äî enterprise CAD software, wide enterprise footprint.",
    blue:"Process tree alerting: any web server ‚Üí cmd/powershell child is almost never legitimate. Fire P1 SIEM alert." }},
  {{ tactic:"C2", tid:"T1071", tech:"App Layer Protocol (HTTP/DNS)", icon:"üì°",
    desc:"Command & Control via legitimate app protocols to evade detection. {j_tactic_c2} threats map here ‚Äî primarily TALOS_IP, FEODO tracker, and TOR exit nodes representing active C2 infrastructure.",
    sigma:`title: Suspicious Beacon to Known Bad IP\ndetection:\n  network:\n    DestinationIP|in: $TalosBadActors\n    Frequency|gte: 20  # per hour\n  condition: network`,
    red:"30 TOR exit nodes + 100 TALOS IPs in this dataset are live C2/pivot infrastructure. Use for red team anonymization.",
    blue:"Feed Talos IPs from this dataset into SIEM/SOAR blocklist. Alert on any connection to TOR exit nodes at perimeter." }},
  {{ tactic:"Impact", tid:"T1486", tech:"Data Encrypted for Impact", icon:"üíÄ",
    desc:"Final-stage ransomware or data destruction. {j_tactic_impact} threats here. Ransomware-linked CVEs carry double-extortion risk. Chain: Initial Access ‚Üí Cred Dump ‚Üí Lateral Move ‚Üí Encrypt.",
    sigma:`title: Mass File Encryption (Ransomware)\ndetection:\n  file:\n    TargetFilename|endswith: [".locked",".encrypted",".enc",".ryk",".ryuk"]\n  timeframe: 30s\n  condition: file | count() > 50`,
    red:"Full chain: exploit CVE with KEV flag ‚Üí dump creds from affected product ‚Üí encrypt shares ‚Üí ransom note. < 2h end-to-end.",
    blue:"VSS deletion = immediate IR trigger. Isolate host within 5 min. Restore from air-gapped backup. Engage IR." }}
];

function buildTTPSimulation() {{
  const chain = document.getElementById("ttpChain");
  if (!chain) return;
  chain.innerHTML = TTP_STEPS.map((s,i) =>
    `<div class="ttp-step ${{i===0?'active':''}}" onclick="selectTTP(${{i}})" id="ttpStep${{i}}">
      <div class="ttp-tactic">${{s.tactic}}</div>
      <div class="ttp-tech">${{s.icon}} ${{s.tech}}</div>
      <div class="ttp-tid">${{s.tid}}</div>
      <div class="ttp-heat"></div>
    </div>`
  ).join('');
  selectTTP(0);
}}

function selectTTP(idx) {{
  document.querySelectorAll('.ttp-step').forEach((el,i)=>el.classList.toggle('active',i===idx));
  const s = TTP_STEPS[idx];
  const detail = document.getElementById("ttpDetail");
  const cves = TTP_DB.techToCVEs[s.tid]||[];
  const cveHtml = cves.length
    ? cves.map(c=>`<span class="ttp-cvetag" onclick="document.getElementById('searchBox').value='${{c}}';applyFilters();document.getElementById('filterBar').scrollIntoView({{behavior:'smooth'}})">${{c}}</span>`).join('')
    : '<span style="color:#555;font-size:.7rem">IP/IOC-based ‚Äî no CVE link</span>';
  const count = TTP_DB.techCount[s.tid]||0;
  detail.className="ttp-detail open";
  detail.innerHTML=`
    <div class="ttp-detail-card">
      <h5>üìñ What Happens ‚Äî ${{s.icon}} ${{s.tactic}}</h5>
      <p>${{s.desc}}</p>
      <p style="margin-top:8px;font-size:.72rem;color:#888">Coverage: <strong style="color:var(--accent)">${{count.toLocaleString()}}</strong> threats in dataset map to ${{s.tid}}</p>
      <div class="ttp-cvelist" style="margin-top:6px">${{cveHtml}}</div>
    </div>
    <div class="ttp-detail-card">
      <h5>üìã Sigma Detection Rule</h5>
      <span class="code">${{s.sigma}}</span>
    </div>
    <div class="ttp-detail-card">
      <h5>üî¥ Red Team</h5>
      <p style="color:#ff8080">${{s.red}}</p>
    </div>
    <div class="ttp-detail-card">
      <h5>üîµ Blue Team</h5>
      <p style="color:#5dade2">${{s.blue}}</p>
    </div>
  `;
}}

// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
// INIT ‚Äî defer to requestAnimationFrame so CSS grid finishes layout
// ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
requestAnimationFrame(() => {{
  applyFilters();
  drawAllCharts();
  // EPSS coverage badge
  const epssNote = document.getElementById("epssNote");
  if (epssNote) {{
    const ev = {j_epss};
    const total_epss = ev.reduce((a,b)=>a+b,0);
    const enriched_epss = ev.slice(1).reduce((a,b)=>a+b,0);
    if (enriched_epss === 0) {{
      epssNote.textContent = "‚ö† No enrichment this run";
      epssNote.style.color = "#e67e22";
    }} else {{
      const pct = ((enriched_epss/total_epss)*100).toFixed(1);
      epssNote.textContent = `‚úì ${{pct}}% coverage`;
      epssNote.style.color = "#27ae60";
    }}
  }}
}});
window.addEventListener("resize", drawAllCharts);
</script>
</body>
</html>"""

    try:
        with open(output_path, "w", encoding="utf-8") as fh:
            fh.write(html)
        print(f"  ‚úì AnubisX v6.0 HTML dashboard written: {output_path} ({len(html)//1024}KB)")
    except Exception as e:
        print(f"  ‚úó HTML dashboard write failed: {e}")
    return output_path





def add_powerbi_export_sheet(wb, df):
    """
    v5.7 NEW: Adds a "PowerBI_Export" sheet to the workbook.
    Rules followed for clean Power BI import:
      - No merged cells
      - No emoji in column headers
      - ISO-8601 dates only (YYYY-MM-DD HH:MM)
      - All numeric columns cast to float/int
      - String sentinel 'NONE' preserved (not converted to NaN)
      - Sheet name: PowerBI_Export (no special chars)
    """
    from openpyxl.styles import Font, PatternFill, Alignment
    if "PowerBI_Export" in wb.sheetnames:
        del wb["PowerBI_Export"]
    ws = wb.create_sheet("PowerBI_Export")

    pbi_cols = [
        "Type","ID","Description","CVSS","Severity","Likelihood","Impact",
        "Risk_Level","Final_Score","CISA_KEV","Timestamp","Patch_Available",
        "Affected_Products","Remediation_Priority","GreyNoise_Context",
        "EPSS_Score","EPSS_Percentile","MITRE_Techniques","Source_Count",
        "Confidence_Score","Exploit_Status","Fix_Available","Intel_URL",
        "ZDI_Advisory","AttackerKB_Score","News_Coverage","Link"
    ]
    avail_cols = [c for c in pbi_cols if c in df.columns]

    hdr_fill = PatternFill("solid", fgColor="1F497D")
    for ci, col in enumerate(avail_cols, 1):
        cell = ws.cell(row=1, column=ci, value=col)
        cell.font      = Font(bold=True, color="FFFFFF", size=10)
        cell.fill      = hdr_fill
        cell.alignment = Alignment(horizontal="center")

    for ri, (_, row) in enumerate(df[avail_cols].iterrows(), 2):
        for ci, col in enumerate(avail_cols, 1):
            val = row[col]
            if pd.isna(val):
                val = ""
            elif col in ("CVSS","EPSS_Score","EPSS_Percentile","AttackerKB_Score","Final_Score"):
                try:
                    val = float(val)
                except:
                    val = 0.0
            elif col in ("Source_Count","Likelihood","Impact"):
                try:
                    val = int(val)
                except:
                    val = 0
            else:
                val = str(val)
            ws.cell(row=ri, column=ci, value=val)

    for ci, col in enumerate(avail_cols, 1):
        ws.column_dimensions[ws.cell(row=1, column=ci).column_letter].width = max(12, min(40, len(col)+4))

    ws.sheet_properties.tabColor = "1F497D"
    print(f"  ‚úì PowerBI_Export sheet added ({len(df)} rows √ó {len(avail_cols)} cols)")
    return ws


def main():
    print("=" * 70)
    print("üê∫ ANUBIS THREATHUNTER v6.0")
    print("=" * 70)
    print("üëë Created by: Ramiz Alsafi")
    print("‚öñÔ∏è  Judge Every Threat, Protect Every Soul")
    print("üéØ PharaonX RedTeam")
    print("=" * 70)
    print(f"‚è∞ Started: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"üìä Lookback: {LOOKBACK_HOURS} hours")

    # v5.3: API Key Health Check ‚Äî show what's configured vs missing upfront
    print('\nüîë API KEY STATUS:')
    api_keys = {
        'Zoho Cliq Webhook': bool(CLIQ_WEBHOOK_URL),
        'Zoho API Key':      bool(ZOHO_API_KEY),
        'AbuseIPDB':         bool(ABUSEIPDB_API_KEY),
        'GreyNoise':         bool(GREYNOISE_API_KEY),
        'Shodan':            bool(SHODAN_API_KEY),
        'Vulners':           bool(VULNERS_API_KEY),
        'AlienVault OTX':    bool(ALIENVAULT_API_KEY),
        'Censys ID':         bool(CENSYS_API_ID),
        'AttackerKB':        bool(ATTACKERKB_API_KEY),
        'VulnCheck':         bool(VULNCHECK_API_KEY),
    }
    configured = [k for k,v in api_keys.items() if v]
    missing    = [k for k,v in api_keys.items() if not v]
    for k in configured: print(f'  ‚úÖ {k}')
    for k in missing:    print(f'  ‚ùå {k} ‚Äî not set (source will be skipped or fail silently)')
    print(f'  ‚Üí {len(configured)} keys active | {len(missing)} missing')


    if not should_run_now():
        print("\n‚è≠Ô∏è  Skipping - already ran recently")
        print("=" * 70)
        return

    print("‚úì Proceeding with COMPLETE threat intelligence collection...\n")

    r = fetch_all_concurrent()

    # ‚îÄ‚îÄ v6.2 NEW: Comprehensive per-source resource health report ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    print_resource_report(r, {
        'cves':fetch_cves,'kev':get_cisa_kev_list,'github':fetch_github_advisories,
        'urlhaus':fetch_urlhaus,'phish':fetch_phishtank,'exploits':fetch_exploits,
        'malware':fetch_malware,'msrc':fetch_microsoft_security_updates,
        'windows_cves':fetch_windows_cves_from_nvd,'patch_tuesday':fetch_patch_tuesday_info,
        'vulners':fetch_vulners_data,'otx':fetch_alienvault_otx,'threatfox':fetch_threatfox_iocs,
        'osv':fetch_osv_dev,'threatminer':fetch_threatminer,'cve_trends':fetch_cve_trends,
        'shodan':fetch_shodan,'abuseip':fetch_abuseipdb,'hibp':fetch_hibp,
        'cisa_ics':fetch_cisa_ics_advisories,'mitre':fetch_mitre_attack,
        'feodo':fetch_feodo_tracker,'spamhaus':fetch_spamhaus_drop,
        'ubuntu':fetch_ubuntu_security,'tor':fetch_tor_exit_nodes,'blocklist':fetch_blocklist_de,
        'gn_threats':fetch_greynoise_mass_scan,'gn_benign':fetch_greynoise_riot,
        'censys_vuln':fetch_censys_vulnerable_hosts,'censys_rdp':lambda:None,
        'intel_feed':fetch_snyk_vulnerabilities,'redhat':fetch_redhat_cves,'talos':fetch_talos_blacklist,
        'emerging':fetch_emerging_threats_ips,'packetstorm':fetch_packetstorm_rss,
        'vulncheck_kev':fetch_vulncheck_kev,'cisa_ransomware':fetch_cisa_ransomware,
        'fw_fortinet':fetch_fortinet_advisories,'fw_paloalto':fetch_palo_alto_advisories,
        'fw_cisco':fetch_cisco_advisories,'fw_juniper':fetch_juniper_advisories,
        'fw_f5':fetch_f5_advisories,'fw_citrix':fetch_citrix_advisories,
        'fw_sonicwall':fetch_sonicwall_advisories,'fw_checkpoint':fetch_checkpoint_advisories,
        'fw_watchguard':fetch_watchguard_advisories,'fw_sophos':fetch_sophos_advisories,
        'fw_aruba':fetch_aruba_advisories,'fw_zyxel':fetch_zyxel_advisories,
        'fw_barracuda':fetch_barracuda_advisories,'fw_pfsense':fetch_pfsense_advisories,
        'zdi':fetch_zdi_advisories,'attackerkb':fetch_attackerkb,'sans_isc':fetch_sans_isc,
        'security_news':fetch_security_news,'sslbl':fetch_abuse_sslbl,'certeu':fetch_certeu_reports,
    })

    fw_keys       = [k for k in r.keys() if k.startswith('fw_')]
    fw_advisories = []
    for k in fw_keys:
        fw_advisories.extend(r.get(k, []))
    print(f"üõ°Ô∏è  Total firewall advisories collected: {len(fw_advisories)}")
    print(f"üéØ ZDI advisories collected:             {len(r.get('zdi', []))}")
    print(f"üî¨ NVD CVE enrichment active:          {len(r.get('attackerkb', []))}")
    print(f"üì° SANS ISC diary entries:                {len(r.get('sans_isc', []))}")
    print(f"üì∞ Security news items:                   {len(r.get('security_news', []))}")

    if r.get('threatfox'):
        r['threatfox'] = enrich_iocs_with_greynoise(r['threatfox'])

    all_threats = process_threats(
        r.get('cves', []),
        r.get('exploits', []),
        r.get('malware', []),
        r.get('github', []),
        r.get('urlhaus', []),
        r.get('phish', []),
        r.get('kev', set()),
        r.get('vulners', []),
        r.get('otx', []),
        r.get('threatfox', []),
        r.get('osv', []),
        r.get('threatminer', []),
        r.get('cve_trends', []),
        [],
        r.get('shodan', []),
        r.get('abuseip', []),
        r.get('hibp', []),
        r.get('cisa_ics', []),
        r.get('mitre', []),
        r.get('feodo', []),
        r.get('spamhaus', []),
        r.get('ubuntu', []),
        r.get('tor', []),
        r.get('blocklist', []),
        r.get('gn_threats', []),
        r.get('gn_benign', []),
        r.get('censys_vuln', []),
        r.get('censys_rdp', []),
        r.get('intel_feed', []),   # v5.8 FIX: was r.get('snyk',[]) ‚Äî task key is 'intel_feed'
        r.get('redhat', []),
        r.get('msrc', []),
        r.get('windows_cves', []),
        r.get('patch_tuesday', []),
        talos_ips=r.get('talos', []),
        emerging_ips=r.get('emerging', []),
        packetstorm=r.get('packetstorm', []),
        vulncheck_kev=r.get('vulncheck_kev', []),
        cisa_ransomware=r.get('cisa_ransomware', []),
        firewall_advisories=fw_advisories,
        zdi_vulns=r.get('zdi', []),
        atkb_topics=r.get('attackerkb', []),
        sans_isc=r.get('sans_isc', []),
        security_news=r.get('security_news', []),
    )

    if not all_threats:
        print("\n‚è≠Ô∏è  No new threats found")
        update_last_run()
        return

    new_df = pd.DataFrame(all_threats)

    if os.path.exists(EXCEL_FILE):
        existing_df = pd.read_excel(EXCEL_FILE, keep_default_na=False, na_values=[''])
        # Schema guard: if the file is from an old/different version and missing the ID
        # column (or other critical columns), treat it as a fresh start rather than crashing.
        required_cols = {'ID', 'Type', 'Description'}
        missing_critical = required_cols - set(existing_df.columns)
        if missing_critical:
            print(f"\n‚ö†Ô∏è  Existing file is missing columns {missing_critical} ‚Äî schema mismatch.")
            print("    Backing up old file and starting fresh database.")
            backup_path = EXCEL_FILE.replace('.xlsx', f'_backup_{datetime.now().strftime("%Y%m%d_%H%M%S")}.xlsx')
            os.rename(EXCEL_FILE, backup_path)
            print(f"    Backup saved: {backup_path}")
            unique_new = new_df
            final_df   = new_df
        else:
            # Fill any new columns that didn't exist in the old file
            col_defaults = {
                'Source_Count':    1,
                'Confidence_Score':'LOW (40%)',
                'ZDI_Advisory':    'NONE',
                'AttackerKB_Score':0.0,
                'News_Coverage':   '',
                'Intel_URL':        'NONE',
                'Exploit_Status': 'NONE',
                'Fix_Available':    'NONE',
                'EPSS_Score':      0.0,
                'EPSS_Percentile': 0.0,
            }
            for col, default in col_defaults.items():
                if col not in existing_df.columns:
                    existing_df[col] = default
            print(f"\n‚úì Loaded existing database with {len(existing_df)} entries")
            unique_new = new_df[~new_df['ID'].isin(existing_df['ID'])]
            print(f"‚úì Found {len(unique_new)} new unique threats")
            final_df = pd.concat([existing_df, unique_new], ignore_index=True)
    else:
        print("\n‚úì Creating new threat intelligence database")
        unique_new = new_df
        final_df   = new_df

    final_df.to_excel(EXCEL_FILE, index=False)
    print(f"‚úì Database updated: {EXCEL_FILE}")
    print(f"‚úì Total entries: {len(final_df)}")

    # v5.2: Apply AutoFilter + Dashboard to the saved Excel file
    apply_excel_formatting(EXCEL_FILE)

    # v5.7 NEW: Add Power BI-optimised sheet to the Excel file
    print("\nüîµ Adding PowerBI_Export sheet...")
    try:
        from openpyxl import load_workbook as _lw
        _wb = _lw(EXCEL_FILE)
        add_powerbi_export_sheet(_wb, final_df)
        _wb.save(EXCEL_FILE)
        print("  ‚úì PowerBI_Export sheet saved")
    except Exception as _e:
        print(f"  ‚úó PowerBI_Export failed: {_e}")

    # v5.7 NEW: Generate interactive HTML dashboard
    generate_html_dashboard(final_df, HTML_DASHBOARD_FILE)
    print(f"  ‚úì Dashboard: {HTML_DASHBOARD_FILE} ‚Äî open in browser or import into Power BI via Get Data ‚Üí Web")

    if not unique_new.empty:
        print("\nüì§ Sending alerts to Zoho Cliq...")
        alert = create_threat_alert(unique_new.to_dict('records'))
        send_text_to_cliq(alert)
        time.sleep(2)
        print("üìé Uploading Excel report...")
        upload_file_to_cliq(EXCEL_FILE)
        time.sleep(2)
        print("üåê Uploading HTML dashboard...")
        upload_file_to_cliq(HTML_DASHBOARD_FILE)
    else:
        no_new = (
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"üê∫ ANUBIS THREATHUNTER v6.0\n"
            f"üëë PharaonX RedTeam\n"
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"‚úÖ THREAT INTELLIGENCE CHECK\n"
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"üìä Status: All Clear\n"
            f"üîç Checked: {len(all_threats)} threats\n"
            f"‚ú® New Threats: 0\n"
            f"üìö Database: {len(final_df)} total\n"
            f"‚è∞ {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M')}\n"
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n"
            f"üíö No new threats - all tracked\n"
            f"üê∫ Guardian stands watch\n"
            f"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
        )
        send_text_to_cliq(no_new)
        print("‚úì 'All clear' alert sent")

    update_last_run()
    print("\n" + "=" * 70)
    print("‚úÖ Process completed successfully!")
    print(f"‚è∞ Finished: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M:%S')}")
    print("üê∫ ANUBIS has judged all threats")
    print("=" * 70)


if __name__ == "__main__":
    main()
